module.exports=[{"_id":"6280520a94a546001c2bcc7e","title":"*Realm Series","published_at":"2022-05-15T01:07:10.542Z","seriesEntry":[{"__component":"article-info.strapi-new-article","_id":"6280520a94a546001c2bcc7f","__v":0,"new_article":{"awaiting_editorial_review":false,"awaiting_technical_review":false,"editorial_review_LGTM":false,"technical_review_LGTM":false,"authors":["60b8f85e5817c1001ce8c3ad"],"_id":"6244b4fd7a304f0ca6c4d956","type":"HowTo","name":"*Realm Data Types","slug":"/realm-data-types","content":"## Introduction\n\nA key feature of Realm is you don’t have to think about converting data to/from JSON, or using ORMs. Just create your objects using the data types your language natively supports. We’re adding new supported types to all our SDKs, here is a refresher and a taste of the new supported types.\n\n## Swift: Already supported types\n\nThe complete reference of supported data types for iOS can be found [here](https://docs.mongodb.com/realm/sdk/ios/data-types/supported-property-types/).\n\n| Type Name | Code Sample |\n| --------- | ----------- |\n| [Bool](https://developer.apple.com/documentation/swift/bool)<br>A value type whose instances are either true or false. | `// Declaring as Required`<br>`@objc dynamic var value = false`<br><br>`// Declaring as Optional`<br>`let value = RealmProperty()` |\n| [Int](https://developer.apple.com/documentation/swift/int), Int8, Int16, Int32, Int64<br>A signed integer value type. | `// Declaring as Required`<br>`@objc dynamic var value = 0`<br><br>`// Declaring as Optional`<br>`let value = RealmProperty()` |\n| [Float](https://developer.apple.com/documentation/swift/float)<br>A single-precision, floating-point value type. | `// Declaring as Required` <br>`@objc dynamic var value: Float = 0.0`<br><br>`// Declaring as Optional` `let value = RealmProperty()` |\n| [Double](https://developer.apple.com/documentation/swift/double)<br>A double-precision, floating-point value type. | `// Declaring as Required`<br>`@objc dynamic var value: Double = 0.0`<br><br>`// Declaring as Optional`<br>`let value = RealmProperty()` |\n| [String](https://developer.apple.com/documentation/swift/string)<br>A Unicode string value that is a collection of characters. | `// Declaring as Required`<br>`@objc dynamic var value = \"\"`<br><br>`// Declaring as Optional`<br>`@objc dynamic var value: String? = nil` |\n| [Data](https://developer.apple.com/documentation/foundation/data)<br>A byte buffer in memory. | `// Declaring as Required`<br>`@objc dynamic var value = Data()`<br><br>`// Declaring as Optional`<br>`@objc dynamic var value: Data? = nil` |\n| [Date](https://developer.apple.com/documentation/foundation/date)<br>A specific point in time, independent of any calendar or time zone. | `// Declaring as Required`<br>`@objc dynamic var value = Date()`<br><br>`// Declaring as Optional`<br>`@objc dynamic var value: Date? = nil` |\n| [Decimal128](https://developer.apple.com/documentation/foundation/decimal)<br>A structure representing a base-10 number. | `// Declaring as Required`<br>`@objc dynamic var decimal: Decimal128 = 0`<br><br>`// Declaring as Optional`<br>`@objc dynamic var decimal: Decimal128? = nil` |\n| [List](https://docs.mongodb.com/realm-sdks/swift/latest/Classes/List.html)<br>List is the container type in Realm used to define to-many relationships. | `let value = List()` |\n| [ObjectId](https://docs.mongodb.com/realm-sdks/swift/latest/Classes/ObjectId.html)<br>A 12-byte (probably) unique object identifier. Compatible with the ObjectId type used in the MongoDB database. | `// Declaring as Required`<br>`@objc dynamic var objectId = ObjectId.generate()`<br><br>`// Declaring as Optional`<br>`@objc dynamic var objectId: ObjectId? = nil` |\n| User-defined Object Your own classes. | `// Declaring as Optional`<br>`@objc dynamic var value: MyClass? = nil` |\n\n<br/><br/>\n\n## Swift: New Realm Supported Data Types\n\nStarting with **Realm iOS 10.8.0**\n\n| Type Name | Code Sample |\n| --------- | ----------- |\n| [Maps](https://docs.mongodb.com/realm/sdk/ios/data-types/collections/#map) <br>Store data in arbitrary key-value pairs. They’re used when a developer wants to add flexibility to data models that may evolve over time, or handle unstructured data from a remote endpoint. | `class Player: Object {` <br>&emsp;`@objc dynamic var name = String?`<br>&emsp;`@objc dynamic var email: String?`<br>&emsp;`@objc dynamic var playerHandle: String?`<br>&emsp;`let gameplayStats = Map()`<br>&emsp;`let competitionStats = Map()`<br>`}`<br>`try! realm.write {`<br>&emsp;`let player = Player()`<br>&emsp;`player.name = \"iDubs\"`<br><br>&emsp;`// get the RealmDictionary field from the object we just created and add stats`<br>&emsp;`let statsDictionary = player.gameplayStats`<br>&emsp;`statsDictioanry[\"mostCommonRole\"] = \"Medic\"`<br>&emsp;`statsDictioanry[\"clan\"] = \"Realmers\"`<br>&emsp;`statsDictioanry[\"favoriteMap\"] = \"Scorpian bay\"`<br>&emsp;`statsDictioanry[\"tagLine\"] = \"Always Be Healin\"`<br>&emsp;`statsDictioanry[\"nemesisHandle\"] = \"snakeCase4Life\"`<br>&emsp;`let competitionStats = player.comeptitionStats`<br><br>&emsp;`competitionStats[\"EastCoastInvitational\"] = \"2nd Place\"`<br>&emsp;`competitionStats[\"TransAtlanticOpen\"] = \"4th Place\"`<br>`}` |\n| [MutableSet](https://docs.mongodb.com/realm-sdks/swift/10.8.0-beta.0/Classes/MutableSet.html) <br>MutableSet is the container type in Realm used to define to-many relationships with distinct values as objects. | `// MutableSet declaring as required` <br>`let value = MutableSet()`<br><br>`// Declaring as Optional`<br>`let value: MutableSet? = nil `|\n| [AnyRealmValue](https://docs.mongodb.com/realm/sdk/ios/data-types/supported-property-types/#mixed-data-type) <br>AnyRealmValue is a Realm property type that can hold different data types. | `// Declaring as Required` <br>`let value = RealmProperty()`<br><br>`// Declaring as Optional`<br>`let value: RealmProperty? = nil` |\n| [UUID](https://docs.mongodb.com/realm/sdk/ios/data-types/supported-property-types/#unique-identifiers) <br>UUID is a 16-byte globally-unique value. | `// Declaring as Required` <br>`@objc dynamic var uuid = UUID()`<br><br>`// Declaring as Optional`<br>`@objc dynamic var uuidOpt: UUID? = nil` |\n\n<br/><br/>\n\n## Android/Kotlin: Already supported types\n\nYou can use these types in your RealmObject subclasses. The complete reference of supported data types for Kotlin can be found [here](https://docs.mongodb.com/realm/sdk/android/data-types/field-types/).\n\n| Type Name | Code Sample |\n| --------- | ----------- |\n| [Boolean](https://kotlinlang.org/docs/basic-types.html#booleans) or boolean<br>Represents boolean objects that can have two values: true and false. | `// Declaring as Required` <br>`var visited = false`<br><br>`// Declaring as Optional`<br>`var visited = false` |\n| [Integer](https://kotlinlang.org/docs/basic-types.html#integer-types) or int<br>A 32-bit signed number. | `// Declaring as Required` <br>`var number: Int = 0`<br><br>`// Declaring as Optional`<br>`var number: Int? = 0` |\n| [Short](https://kotlinlang.org/docs/basic-types.html#integer-types) or short<br>A 16-bit signed number. | `// Declaring as Required` <br>`var number: Short = 0`<br><br>`// Declaring as Optional`<br>`var number: Short? = 0` |\n| [Long](https://kotlinlang.org/docs/basic-types.html#integer-types) or long<br>A 64-bit signed number. | `// Declaring as Required` <br>`var number: Long = 0`<br><br>`// Declaring as Optional`<br>`var number: Long? = 0` |\n| [Byte](https://kotlinlang.org/docs/basic-types.html#integer-types) or byte[]<br>A 8-bit signed number. | `// Declaring as Required` <br>`var number: Byte = 0`<br><br>`// Declaring as Optional`<br>`var number: Byte? = 0` |\n| [Double](https://kotlinlang.org/docs/basic-types.html#floating-point-types) or double<br>Floating point number(IEEE 754 double precision) | `// Declaring as Required` <br>`var number: Double = 0`<br><br>`// Declaring as Optional`<br>`var number: Double? = 0.0` |\n| [Float](https://kotlinlang.org/docs/basic-types.html#floating-point-types) or float<br>Floating point number(IEEE 754 single precision) | `// Declaring as Required` <br>`var number: Float = 0`<br><br>`// Declaring as Optional`<br>`var number: Float? = 0.0` |\n| [String](https://kotlinlang.org/docs/basic-types.html#strings) | `// Declaring as Required` <br>`var sdkName: String = \"Realm\"`<br><br>`// Declaring as Optional`<br>`var sdkName: String? = \"Realm\"` |\n| [Date](https://kotlinlang.org/api/latest/jvm/stdlib/kotlin.js/-date/) | `// Declaring as Required` <br>`var visited: Date = Date()`<br><br>`// Declaring as Optional`<br>`var visited: Date? = null` |\n| [Decimal128](https://mongodb.github.io/mongo-java-driver/3.9/javadoc/org/bson/types/Decimal128.html) from org.bson.types<br>A binary integer decimal representation of a 128-bit decimal value | `var number: Decimal128 = Decimal128.POSITIVE_INFINITY` |\n| [ObjectId](http://mongodb.github.io/mongo-java-driver/3.4/javadoc/org/bson/types/ObjectId.html) from org.bson.types<br>A globally unique identifier for objects. | `var oId = ObjectId()` |\n| Any RealmObject subclass | `// Define an embedded object` <br>`@RealmClass(embedded = true)`<br>`open class Address(`<br>&emsp;`var street: String? = null,`<br>&emsp;`var city: String? = null,`<br>&emsp;`var country: String? = null,`<br>&emsp;`var postalCode: String? = null`<br>`): RealmObject() {}`<br>`// Define an object containing one embedded object`<br>`open class Contact(_name: String = \"\", _address: Address? = null) : RealmObject() {`<br>&emsp;`@PrimaryKey var _id: ObjectId = ObjectId()`<br>&emsp;`var name: String = _name`<br><br>&emsp;`// Embed a single object.`<br>&emsp;`// Embedded object properties must be marked optional`<br>&emsp;`var address: Address? = _address`<br>`}` |\n| [RealmList](https://docs.mongodb.com/realm/sdk/android/data-types/collections/) <br>RealmList is used to model one-to-many relationships in a RealmObject. | `var favoriteColors : RealmList? = null` |\n\n<br/><br/>\n\n## Android/Kotlin: New Realm Supported Data Types\nStarting with **Realm Android 10.6.0**\n\n| Type Name | Code Sample |\n| --------- | ----------- |\n| [RealmDictionary](https://docs.mongodb.com/realm/sdk/android/data-types/realmdictionary/) <br>Manages a collection of unique String keys paired with values. | `import io.realm.RealmDictionary` <br>`import io.realm.RealmObject`<br><br>`open class Frog: RealmObject() {`<br>&emsp;`var name: String? = null`<br>&emsp;`var nicknamesToFriends: RealmDictionary = RealmDictionary()`<br>`}` |\n| [RealmSet](https://docs.mongodb.com/realm/sdk/android/data-types/realmset/) <br>You can use the RealmSet data type to manage a collection of unique keys. | `import io.realm.RealmObject` <br>`import io.realm.RealmSet`<br><br>`open class Frog: RealmObject() {`<br>&emsp;`var name: String = \"\"`<br>&emsp;`var favoriteSnacks: RealmSet = RealmSet();`<br>`}` |\n| Mixed<br>[RealmAny](https://docs.mongodb.com/realm/sdk/android/data-types/realmany/)<br>You can use the RealmAny data type to create Realm object fields that can contain any of several underlying types. | `import io.realm.RealmAny` <br>`import io.realm.RealmObject`<br><br>`open class Frog(var bestFriend: RealmAny? = RealmAny.nullValue()) : RealmObject() {`<br>&emsp;`var name: String? = null`<br>&emsp;`open fun bestFriendToString(): String {`<br>&emsp;&emsp;`if (bestFriend == null) {`<br>&emsp;&emsp;&emsp;`return \"null\"`<br>&emsp;&emsp;`}`<br>&emsp;&emsp;`return when (bestFriend!!.type) {`<br>&emsp;&emsp;&emsp;`RealmAny.Type.NULL -> {`<br>&emsp;&emsp;&emsp;&emsp;`\"no best friend\"`<br>&emsp;&emsp;&emsp;`}`<br>&emsp;&emsp;&emsp;`RealmAny.Type.STRING -> {`<br>&emsp;&emsp;&emsp;&emsp;`bestFriend!!.asString()`<br>&emsp;&emsp;&emsp;`}`<br>&emsp;&emsp;&emsp;`RealmAny.Type.OBJECT -> {`<br>&emsp;&emsp;&emsp;&emsp;`if (bestFriend!!.valueClass == Person::class.java) {`<br>&emsp;&emsp;&emsp;&emsp;&emsp;`val person = bestFriend!!.asRealmModel(Person::class.java)`<br>&emsp;&emsp;&emsp;&emsp;&emsp;`person.name`<br>&emsp;&emsp;&emsp;&emsp;`}`<br>&emsp;&emsp;&emsp;&emsp;`\"unknown type\"`<br>&emsp;&emsp;&emsp;`}`<br>&emsp;&emsp;&emsp;`else -> {`<br>&emsp;&emsp;&emsp;&emsp;`\"unknown type\"`<br>&emsp;&emsp;&emsp;`}`<br>&emsp;&emsp;`}`<br>&emsp;`}`<br>`}` |\n| [UUID](https://docs.oracle.com/javase/8/docs/api/java/util/class-use/UUID.html) from java.util.UUID | `var id = UUID.randomUUID()` |\n\n<br/><br/>\n\n## JavaScript - React Native SDK: : Already supported types\n\nThe complete reference of supported data types for JavaScript Node.js can be found [here](https://docs.mongodb.com/realm/sdk/node/data-types/field-types/).\n\n| Type Name | Code Sample |\n| --------- | ----------- |\n| `bool` maps to the JavaScript [Boolean](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Boolean) type | `var x = new Boolean(false);` |\n| `int` maps to the JavaScript [Number](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Number) type. Internally, Realm Database stores int with 64 bits. | `Number('123')` |\n| `float` maps to the JavaScript [Number](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Number) type. Internally, Realm Database stores float with 32 bits. | `Number('123.0')` |\n| `double` maps to the JavaScript [Number](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Number) type. Internally, Realm Database stores double with 64 bits. | `Number('123.0')` |\n| `string` `maps` to the JavaScript [String](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Boolean) type. | `const string1 = \"A string primitive\";` |\n| `decimal128` for high precision numbers. |  |\n| `objectId` maps to BSON [`ObjectId`](https://docs.mongodb.com/manual/reference/method/ObjectId/) type. | `ObjectId(\"507f1f77bcf86cd799439011\")` |\n| `data` maps to the JavaScript [ArrayBuffer](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/ArrayBuffer) type. | `const buffer = new ArrayBuffer(8);` |\n| `date` maps to the JavaScript [Date](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Date) type. | `new Date()` |\n| `list` maps to the JavaScript [Array](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array) type. You can also specify that a field contains a list of primitive value type by appending [] to the type name. | `let fruits = ['Apple', 'Banana']` |\n| `linkingObjects` is a special type used to define an inverse relationship. |  |\n\n<br/><br/>\n\n## JavaScript - React Native SDK: New Realm supported types\n\nStarting with __Realm JS 10.5.0__\n\n| Type Name | Code Sample |\n| --------- | ----------- |\n| [dictionary](https://docs.mongodb.com/realm/sdk/react-native/data-types/dictionaries/) used to manage a collection of unique String keys paired with values. | `let johnDoe;` <br>`let janeSmith;`<br>`realm.write(() => {`<br>&emsp;`johnDoe = realm.create(\"Person\", {`<br>&emsp;&emsp;`name: \"John Doe\",`<br>&emsp;&emsp;`home: {`<br>&emsp;&emsp;&emsp;`windows: 5,`<br>&emsp;&emsp;&emsp;`doors: 3,`<br>&emsp;&emsp;&emsp;`color: \"red\",`<br>&emsp;&emsp;&emsp;`address: \"Summerhill St.\",`<br>&emsp;&emsp;&emsp;`price: 400123,`<br>&emsp;&emsp;`},`<br>&emsp;`});`<br>&emsp;`janeSmith = realm.create(\"Person\", {`<br>&emsp;&emsp;`name: \"Jane Smith\",`<br>&emsp;&emsp;`home: {`<br>&emsp;&emsp;&emsp;`address: \"100 northroad st.\",`<br>&emsp;&emsp;&emsp;`yearBuilt: 1990,`<br>&emsp;&emsp;`},`<br>&emsp;`});`<br>`});` |\n| [set](https://docs.mongodb.com/realm/sdk/react-native/data-types/sets/) is based on the JavaScript Set type.<br>A Realm Set is a special object that allows you to store a collection of unique values. Realm Sets are based on JavaScript sets, but can only contain values of a single type and can only be modified within a write transaction. | `let characterOne, characterTwo;` <br>`realm.write(() => {`<br>&emsp;`characterOne = realm.create(\"Character\", {`<br>&emsp;&emsp;`_id: new BSON.ObjectId(),`<br>&emsp;&emsp;`name: \"CharacterOne\",`<br>&emsp;&emsp;`inventory: [\"elixir\", \"compass\", \"glowing shield\"],`<br>&emsp;&emsp;`levelsCompleted: [4, 9],`<br>&emsp;`});`<br>`characterTwo = realm.create(\"Character\", {`<br>&emsp;&emsp;`_id: new BSON.ObjectId(),`<br>&emsp;`name: \"CharacterTwo\",`<br>&emsp;&emsp;`inventory: [\"estus flask\", \"gloves\", \"rune\"],`<br>&emsp;&emsp;`levelsCompleted: [1, 2, 5, 24],`<br>&emsp;`});`<br>`});` |\n| [mixed](https://docs.mongodb.com/realm/sdk/react-native/data-types/mixed/) is a property type that can hold different data types.<br>The mixed data type is a realm property type that can hold any valid Realm data type except a collection. You can create collections (lists, sets, and dictionaries) of type mixed, but a mixed itself cannot be a collection. Properties using the mixed data type can also hold null values. | `realm.write(() => {` <br>&emsp;`// create a Dog with a birthDate value of type string`<br>&emsp;`realm.create(\"Dog\", { name: \"Euler\", birthDate: \"December 25th, 2017\" });`<br>&emsp;`// create a Dog with a birthDate value of type date`<br>`realm.create(\"Dog\", {`<br>&emsp;&emsp;`name: \"Blaise\",`<br>&emsp;&emsp;`birthDate: new Date(\"August 17, 2020\"),`<br>&emsp;`});`<br>&emsp;`// create a Dog with a birthDate value of type int`<br>&emsp;`realm.create(\"Dog\", {`<br>&emsp;&emsp;`name: \"Euclid\",`<br>&emsp;&emsp;`birthDate: 10152021,`<br>&emsp;`});`<br>&emsp;`// create a Dog with a birthDate value of type null`<br>&emsp;&emsp;`realm.create(\"Dog\", {`<br>&emsp;&emsp;`name: \"Pythagoras\",`<br>&emsp;&emsp;`birthDate: null,`<br>&emsp;`});`<br>`});` |\n| [uuid](https://docs.mongodb.com/realm/sdk/react-native/data-types/uuid/) is a universally unique identifier from Realm.BSON.<br>UUID (Universal Unique Identifier) is a 16-byte unique value. You can use UUID as an identifier for objects. UUID is indexable and you can use it as a primary key. | `const { UUID } = Realm.BSON;` <br>`const ProfileSchema = {`<br>&emsp;`name: \"Profile\",`<br>&emsp;`primaryKey: \"_id\",`<br>&emsp;`properties: {`<br>&emsp;&emsp;`_id: \"uuid\",`<br>&emsp;&emsp;`name: \"string\",`<br>&emsp;`},`<br>`};`<br>`const realm = await Realm.open({`<br>&emsp;`schema: [ProfileSchema],`<br>`});`<br>`realm.write(() => {`<br>&emsp;`realm.create(\"Profile\", {`<br>&emsp;&emsp;`name: \"John Doe.\",`<br>&emsp;&emsp;`_id: new UUID(), // create a _id with a randomly generated UUID`<br>&emsp;`});`<br>`realm.create(\"Profile\", {`<br>&emsp;&emsp;`name: \"Tim Doe.\",`<br>&emsp;&emsp;`_id: new UUID(\"882dd631-bc6e-4e0e-a9e8-f07b685fec8c\"), // create a _id with a specific UUID value`<br>&emsp;`});`<br>`});` |\n\n<br/><br/>\n\n## .NET Field Types \n The complete reference of supported data types for .Net/C# can be found [here](https://docs.mongodb.com/realm/sdk/dotnet/data-types/field-types/).\n\n| Type Name | Code Sample |\n| --- | --- |\n| Realm Database supports the following .NET data types and their nullable counterparts:<br>bool<br>byte<br>short<br>int<br>long<br>float<br>double<br>decimal<br>char<br>string<br>byte[]<br>DateTimeOffset<br>Guid<br>IList, where T is any of the supported data types | Regular C# code, nothing special to see here! |\n| ObjectId maps to [BSON](https://docs.mongodb.com/manual/reference/bson-types/) [`ObjectId`](https://docs.mongodb.com/manual/reference/method/ObjectId/) type. |  |\n\n<br/><br/>\n\n## .Net Field Types: New supported types\n\nStarting with __.NET SDK 10.2.0__\n\n| Type Name | Code Sample |\n| --------- | ----------- |\n| [Dictionary](https://docs.mongodb.com/realm/sdk/dotnet/data-types/dictionaries/) <br>A Realm dictionary is an implementation of IDictionary that has keys of type String and supports values of any Realm type except collections. To define a dictionary, use a getter-only IDictionary property, where TValue is any of the supported types. | `public class Inventory : RealmObject` <br>`{`<br>&emsp;`// The key must be of type string; the value can be`<br>&emsp;`// of any Realm-supported type, including objects`<br>&emsp;`// that inherit from RealmObject or EmbeddedObject`<br>&emsp;`public IDictionary PlantDict { get; }`<br>&emsp;`public IDictionary BooleansDict { get; }`<br>&emsp;`// Nullable types are supported in local-only`<br>&emsp;`// Realms, but not with Sync`<br>&emsp;`public IDictionary NullableIntDict { get; }`<br>&emsp;`// For C# types that are implicitly nullable, you can`<br>&emsp;`// use the [Required] attribute to prevent storing null values`<br>&emsp;`[Required]`<br>&emsp;`public IDictionary RequiredStringsDict { get; }`<br>`}` |\n| [Sets](https://docs.mongodb.com/realm/sdk/dotnet/data-types/sets/) <br>A Realm set, like the C# [HashSet<>](https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic.hashset-1?view=net-5.0), is an implementation of [ICollection<>](https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic.icollection-1?view=net-5.0) and [IEnumerable<>](https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic.ienumerable-1?view=net-5.0). It supports values of any [Realm type](https://docs.mongodb.com/realm/sdk/dotnet/fundamentals/object-models-and-schemas/#std-label-dotnet-objects) except collections. To define a set, use a getter-only ISet property, where TValue is any of the supported types. | `public class Inventory : RealmObject` <br>`{`<br>&emsp;`// A Set can contain any Realm-supported type, including`<br>&emsp;`// objects that inherit from RealmObject or EmbeddedObject`<br>&emsp;`public ISet PlantSet { get; }<br>public ISet DoubleSet { get; }`<br>&emsp;`// Nullable types are supported in local-only`<br>&emsp;`// Realms, but not with Sync`<br>&emsp;`public ISet NullableIntsSet { get; }`<br>&emsp;`// For C# types that are implicitly nullable, you can`<br>&emsp;`// use the [Required] attribute to prevent storing null values`<br>&emsp;`[Required]`<br>&emsp;`public ISet RequiredStrings { get; }`<br>`}` |\n| [RealmValue](https://docs.mongodb.com/realm/sdk/dotnet/data-types/field-types/#realmvalue--beta-) <br>The RealmValue data type is a mixed data type, and can represent any other valid Realm data type except a collection. You can create collections (lists, sets and dictionaries) of type RealmValue, but a RealmValue itself cannot be a collection. | `public class MyRealmValueObject : RealmObject` <br>`{`<br>&emsp;`[PrimaryKey]`<br>&emsp;`[MapTo(\"_id\")]`<br>&emsp;`public Guid Id { get; set; }`<br>&emsp;`public RealmValue MyValue { get; set; }`<br>&emsp;`// A nullable RealmValue preoprtrty is *not supported*`<br>&emsp;`// public RealmValue? NullableRealmValueNotAllowed { get; set; }`<br>`}`<br>`private void TestRealmValue()`<br>`{`<br>&emsp;`var obj = new MyRealmValueObject();`<br>&emsp;`// set the value to null:`<br>&emsp;`obj.MyValue = RealmValue.Null;`<br>&emsp;`// or an int...`<br>&emsp;`obj.MyValue = 1;`<br>&emsp;`// or a string...`<br>&emsp;`obj.MyValue = \"abc\";`<br>&emsp;`// Use RealmValueType to check the type:`<br>&emsp;`if (obj.MyValue.Type == RealmValueType.String)`<br>&emsp;`{`<br>&emsp;&emsp;`var myString = obj.MyValue.AsString();`<br>&emsp;`}`<br>`}` |\n| [Guid and ObjectId Properties](https://docs.mongodb.com/realm/sdk/dotnet/data-types/field-types/#guid-and-objectid-properties) <br>MongoDB.Bson.ObjectId is a MongoDB-specific 12-byte unique value, while the built-in .NET type Guid is a 16-byte universally-unique value. Both types are indexable, and either can be used as a [Primary Key](https://docs.mongodb.com/realm/sdk/dotnet/fundamentals/object-models-and-schemas/#primary-key). |  |","originalPublishDate":"2021-06-14T12:03:49.608Z","SEO":null,"related_content":[],"createdAt":"2021-06-03T15:48:03.452Z","originalUpdatedAt":"2021-11-02T16:44:14.699Z","image":{"_id":"60c76e5b1ef87b001cc8c995","name":"*realm-logo.jpg","alternativeText":"","caption":"","hash":"realm_logo_02dfd80d31","ext":".jpg","mime":"image/jpeg","size":12.68,"width":360,"height":360,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/realm_logo_02dfd80d31.jpg","formats":{"thumbnail":{"name":"*thumbnail_realm-logo.jpg","hash":"thumbnail_realm_logo_02dfd80d31","ext":".jpg","mime":"image/jpeg","width":156,"height":156,"size":3.49,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/thumbnail_realm_logo_02dfd80d31.jpg"}},"provider":"aws-s3","related":["60b8f9b35817c1001ce8c3af","60cb454c1ef87b001cc8c9c9"],"createdAt":"2021-06-14T14:57:31.045Z","updatedAt":"2021-06-17T12:51:24.211Z","__v":0,"id":"60c76e5b1ef87b001cc8c995"},"description":"Review of existing and supported Realm Data Types for the different SDKs.","__v":3,"other_tags":[{"__component":"other-tag-info.other-tag-info","id":"627162d453b13d001c33b436"}],"primary_tag":[{"__component":"primary-tag-info.l1-product","id":"627162d453b13d001c33b434"}],"updatedAt":"2022-05-09T19:20:03.778Z","calculated_slug":"/products/realm/realm-data-types","published_at":"2022-05-09T19:20:03.719Z","id":"6244b4fd7a304f0ca6c4d956"},"id":"6280520a94a546001c2bcc7f"},{"__component":"article-info.strapi-new-article","_id":"628062205b0afa001d0d2431","__v":0,"new_article":{"awaiting_editorial_review":false,"awaiting_technical_review":false,"editorial_review_LGTM":true,"technical_review_LGTM":true,"authors":["60941892abd8026382043001"],"_id":"6244b4fd7a304f0ca6c4d94f","type":"HowTo","name":"*Realm GraphQL Demo: Custom Resolvers","slug":"/realm-graphql-demo-custom-resolvers","content":"## Motivation\n\nRealm offers several simple ways to provide third-party access to our data. One of them can be through the so-called [Webhooks](https://docs.mongodb.com/realm/services/configure/service-webhooks/). Through these, we could offer in a controlled way different endpoints to access our services and therefore our data.\n\nA real example would be to provide such webhooks to customers or partners so that they can access certain information necessary for the business logic existing within that particular use case.\n\nHowever, this way of solving this problem has certain disadvantages. The most important ones include:\n\n1. **Fixed-size for the response payload**: The size of the response cannot exceed **4 MB**. This limitation would prevent us from being able to query aggregated data that would require a response larger than 4 MB.\n2. **Creation of different endpoints for each business logic requirement**. This would not only pose a management problem, but also a maintenance problem: what if we make changes in the future? How do we manage the different versions? This model becomes more complex if we want to send parameters in the request to tailor the response to the requirements.\n\n***So what could be a more efficient solution?***\n\nRealm offers the possibility to use its GraphQL API to cover this and other needs. The advantages of using GraphQL for this use case could be listed as:\n\n1. An easier and simpler method to execute accurate endpoint calls.\n2. Easier to choose what we need in the response, alleviating the size of the response by not requiring unnecessary fields.\n3. Simpler maintenance.\n4. Avoid versioning.\n\n## What are we going to build?\n\nMaking use of the [sample available datasets in MongoDB](https://docs.atlas.mongodb.com/sample-data/available-sample-datasets/). We will build a filter to be able to return those movies that meet a set of requirements. These requirements are:\n\n1. Having a given IMDB rating.\n2. Belonging to a set of genres.\n3. Being a certain rate.\n4. Being in several available languages.\n\nThe filtering parameters will be dynamic so that we can return those that best fit our criteria.\n\nFor this, we will use a **GraphQL Custom Resolver** and an external client application to execute our queries.\n\n## Prerequisites\n\nThis tutorial will provide a step-by-step guide to run the demo. To do this we must follow these prerequisites:\n\n1. Have a Cloud MongoDB account.\n2. Create a Free Tier Cluster.\n3. Configure `realm-cli` .\n4. Add an API-Key to be able to access using `realm-cli`.\n5. Load initial data into the Cluster.\n\n### Create an Atlas Account\n\nTo begin, you’ll need a MongoDB Atlas account. If you’ve already got an existing MongoDB Atlas Account, you can skip this step and jump to [**Install the Realm CLI section**](#install-the-realm-cli). If you don’t have an Atlas account, follow the steps below to create one:\n\n1. Navigate to the [MongoDB Atlas login page](https://account.mongodb.com/account/register).\n2. Click Login.\n3. Either enter a new set of user credentials or click the Sign Up with Google button.\n4. Click Sign Up to create your account.\n5. Follow the prompts to create an organization and project in your Atlas account. You can use the default suggested names or enter your own.\n\n![Account startup screenshot](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/0_A_Du4xd_Ay_MD_Ak_N3_B6_37497a6abc)\n\nWhen you finish creating your organization and project, you should end up on a screen that prompts you to create an Atlas cluster:\n\n![Free Tier Cluster screenshot](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/0_tt_Wrkz45j_WO_Xag7_af1456d227)\n\n## Create a Free Atlas Cluster\n\nNext, you’ll need a MongoDB Atlas cluster running MongoDB 4.4 or higher. If you’ve already created a free cluster in your Atlas project running a version of MongoDB other than 4.4, you can [create a new project in Atlas](https://docs.atlas.mongodb.com/tutorial/manage-projects/#procedure) and then create a new cluster running MongoDB 4.4 in that project using the instructions below. If you haven’t created any clusters yet, follow the instructions below to create your first free cluster:\n\n1. Log into your MongoDB Atlas account at [cloud.mongodb.com](https://cloud.mongodb.com/).\n2. Once you’re logged into your account, Atlas should prompt you to create your first cluster. In the Shared Clusters category, click Create a Cluster. Alternatively, you can click Build a Cluster from the project view in your Atlas account.\n3. Under Cloud Provider & Region, select AWS and N. Virginia (us-east-1).\n4. Under Additional Settings, select MongoDB 4.4 from the Select a Version dropdown.\n5. Under Cluster Name, enter the name Cluster0 for your new cluster.\n6. Click the Create Cluster button at the bottom of the page.\n\nAfter creating your cluster, Atlas should launch the project view for your Atlas account. In this view, you’ll see Atlas’s progress as it initializes your new cluster:\n\n![Screenshot of a recently created cluster](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/0_f9_B_Zh_Cw7_V7_XVR_8d_O_06a5e01c6c)\n\n## Install the Realm CLI\n\nNow that you’ve created a cluster to use as the data source for your Realm app, we need some way to create the app itself. In most cases, you’d use the Realm UI, which you can access through the Atlas UI. However, for this tutorial, we’re going to use the [Realm Command Line Interface](https://docs.mongodb.com/realm/deploy/realm-cli-reference/#std-label-realm-cli), also known as `realm-cli`.\n\nWe’re using the Realm CLI because it allows you to manage your Realm apps programmatically using JSON configuration files instead of the Realm UI.\n\nThis lets you get started with a pre-prepared app configuration faster. Follow the instructions below to install the Realm CLI in your development environment using either a package manager or the `realm-cli` binary:\n\nRealm CLI is available on npm. To install it on your system, ensure that you have [Node.js](https://nodejs.org/en/download/) installed and then run the following command in your shell:\n\n```\nnpm install -g mongodb-realm-cli@beta\n```\n\nAfter installing the `realm-cli`, you can run the following command to confirm that your installation was successful:\n\n```\nrealm-cli --version\n```\n\nIf you see output containing a version number such as `2.0.0-beta.4`, your `realm-cli` installation was successful.\n\n## Add an API Key to Your Atlas Project & Log into the Realm CLI\n\nNow that you’ve got `realm-cli`installed to your development environment, you’ll need a way to authenticate using `realm-cli`. For security reasons, `realm-cli`only allows login using a programmatic API key, so we’ll begin by creating a programmatic API Key that you can use to administrate your new Atlas project:\n\n* Click **Access Manager** at the top of the Atlas UI. Select the **Project Access** option from the dropdown.\n* Navigate to the **API Keys** tab.\n* Click the **Create API** Key button.\n* In the **Description** text box, enter “API Key for the MongoDB Realm CLI”.\n\n![Create API key screenshot in Realm UI](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/0_GTFJ_7z_FF_2q_D_c_Zpd_935dddcc53)\n\n* In the **Project Permissions** dropdown, select “Project Owner” and deselect “Project Read Only”.\n\n![Project Permissions screenshot](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/0_vr1_F4_D5e_Vhq_3we_efc619b9df)\n\n* Copy your Public API Key and save it somewhere.\n* Click **Next**.\n* Copy your Private API Key and save it somewhere; after leaving this page, you will no longer be able to view it via the Realm UI.\n* Click the **Add Access List Entry** button.\n* Click **Use Current IP Address**.\n* Click **Save**.\n* When you have safely recorded your private API key, click **Done** to navigate back to the Project Access Manager page.\n* Use the following command in your terminal to authenticate with the Realm CLI:\n\n``` bash\nrealm-cli login --api-key <public API key> --private-api-key <private API key>\n```\n\nIf `realm-cli` produces output like the following, you have successfully authenticated:\n\n```\nyou have successfully logged in as <public API key>\n```\n\n## Load sample dataset to the Cluster\n\nOnce we have deployed the Cluster, we can make use of the sample collections that MongoDB provides. To do this, we must click on “…” and “Load Sample Dataset”.\n\n![Load Sample Dataset screenshot](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/0_7_T7_Ifl_Cl_Qr_BLYFDQ_bac2090539)\n\nThis process may take a few minutes due to the size of the sample collections. They are approximate \\~**350 MB**. Once it has finished, we can verify, by clicking on collections, that the [`sample_mflix.movies`](https://docs.atlas.mongodb.com/sample-data/sample-mflix/) the collection has been loaded successfully.\n\n![One document of Movie collection screenshot](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/0_Eg4_Iaz_Vr_ELU_9p_CL_8_22cc39b57e)\n\nAnother way to check that the data has been loaded into our Cluster and interact with it can be by installing[ MongoDB Compass](https://www.mongodb.com/products/compass) or accessing it through a terminal and [Mongo shell](https://docs.mongodb.com/manual/mongo/).\n\n## Adding Rules to our collections\n\nTo use GraphQL, we need to configure rules for the collections that we are going to use, to do so we go to **DATA ACCESS** and **RULES** in Realm UI.\n\nWe then need to select the newest imported `sample_mflix.movies`collection and click on “**Configure Collection**”. We can configure it without selecting any Template (in the future we can make changes to it).\n\n![Rules section in Realm UI](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/0_ky_Pqx_V0v_Ltossbn_R_a471fd8610)\n\nOnce the collection is selected and after clicking “**Configure Collection**”, we must select the “**All Additional Fields**” option and check the “**Read**” box. At this point, this will allow any authenticated user to read the data in this collection. This will be necessary to be able to later make requests through external clients such as Postman.\n\n![Rules section in Realm UI](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/0_Hbqfhn_Rf_I_Ut_Kboco_311418b5df)\n\nAfter this step, we can configure the **Schema**. To do this and once in the “**Schema**” tab, we can use the documents already loaded in the collection for Realm to generate a schema from them.\n\n![Generate Schema in Realm UI](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/0_u_Iqel7_Yf_V40_LY_5_V_b8e8601a29)\n\nAfter waiting a few minutes, we will be able to consult the Schema created on this same screen.\n\n![Schema generated for the movies collection](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/0_O_Dpul_PC_Rs_Oe_Rip6l_b9d9631bef)\n\n## Add an authentication provider\n\nAll the requests that we are going to make through our GraphQL client must be authenticated. For this, we can activate any of the authentication providers available in Realm.\n\nFor this example, we will use **API Keys**, this way we could create an API Key for each of our clients/partners and disable access in the future if needed.\n\nOnce the authentication provider has been activated, we generate a new key and copy the value provided by the interface.\n\n![API Key Authentication Provider](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/0_nl_S_Jvk_Cak0_Lz_Zc_H_ee0c35e7ba)\n\n## Testing GraphQL with GraphiQL\n\nRealm provides an embedded GraphiQL interface to test requests directly.\n\nThese requests do not need to be authenticated and allow you to test the requests before making them in a real scenario.\n\nTo check that everything is configured correctly, we can perform the following Query.\n\n```\nquery {\n  movie {\n    _id\n  }\n}\n```\n\nThis request is a simple Query to the movies collection where we are requesting to return just the `_id`. From a MongoDB point of view, this request could be equated to the following `mongoshell` method:\n\n``` javascript\ndb.movies.findOne({},{\"_id\" : 1})\n```\n\nOne of the advantages of using the GraphQL API in Realm is that it generates the Schema automatically for the configured collections. We can check this by navigating to the “**Schema**” tab in GraphQL and verifying that indeed the schema for the “**movies**” collection is generated. At this point, we can download the Schema for later use in a third-party GraphQL client such as Postman.\n\n## Create a custom resolver\n\nInthe description of our problem, we talk about how we need to detect in our dataset movies that correspond to a set of predefined filters. Up to this point, we could get all the movies from the dataset and perform some processing in a client application, but fortunately, we can make use of the *aggregation* *pipeline* in MongoDB to perform this transformation on the server through a custom resolver.\n\nIf we want to test the syntax needed to get all movies that match our filter we must perform this *aggregation*:\n\n``` javascript\n[{\"$match\": {\n  \"imdb.rating\": { \"$gte\": 7 },\n  \"genres\": { \"$nin\": [ \"Crime\", \"Horror\" ] } ,\n  \"rated\": { \"$in\": [\"PG\", \"G\" ] },\n  \"languages\": { \"$all\": [ \"English\", \"Japanese\" ] }\n  }\n}]\n```\n\nThe first step to perform is to “**Add a Custom Resolver**” in GraphQL.\n\n![Screenshot of Add Custom Resolver Screen in Realm](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/0_CB_Gypxk_Nh_Hr_U_Ev63_4045da240d)\n\nThe fields to be filled in are the following:\n\n* **GraphQL Field Name**: This corresponds to the name we want to use when we refer to this custom resolver in our queries.\n* **Parent Type**: Type of custom resolver we are creating, in our case, being a read request, we will select Query.\n* **Function**: Here we create the function that will be called every time a call to our custom resolver is executed. You can link an existing function or create it here.\n\nThe code of the function would be the following:\n\n``` javascript\nexports = async function() {\n  const request = context.services.get('mongodb-atlas').db('sample_mflix').collection(\"movies\");\n\n  const pipeline = [\n  {\n    \"$match\": {\n      \"imdb.rating\": { \"$gte\": 7 },\n      \"genres\": { \"$nin\": [ \"Crime\", \"Horror\" ] } ,\n      \"rated\": { \"$in\": [\"PG\", \"G\" ] },\n      \"languages\": { \"$all\": [ \"English\", \"Japanese\" ] }\n    }\n  }];\n\n  return await request.aggregate(pipeline).toArray()\n  .then(data => {\n    console.log(data.length);\n    return data;\n  })\n  .catch(err => {\n    console.log(err.toString());\n    return err.toString();\n  });\n};\n```\n\n![Screenshot of the Custom Resolver editor in Realm UI](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/0_o_C_Hp9rkfhqd_Uj_Y_dc7a616c22)\n\n* **Input Type (Recommended)**: At the moment we will leave it at **None**. Later we will explain what we can do with it and what it is used for.\n* **Payload Type (Recommended)**: Type of object of the response. In our case, our *aggregate* will return a set of movies, therefore we choose **Existing Type (List)** and type **[Movie]**.\n\nAt this point, we can test our new **custom resolver** directly in Realm. To do this, in the same GraphiQL section we can write our query as follows:\n\n```\nquery {\n  oneTitleMovies {\n    title\n  }\n}\n```\n\nAfter clicking the Play button we should see the results of our query.\n\n![](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/0_2_Og_Ewm_Vo_T_Mw_GR_8_YE_3a6eca2987)\n\n## Testing our newest created **Custom Resolver** in Postman\n\nTo test our query in an external client we will use Postman. There is a [tutorial](https://learning.postman.com/docs/sending-requests/supported-api-frameworks/graphql/) to make queries in Postman with an API/Schema. In this example, we will make a simple query without a schema and therefore we will not use it (but it is worth a look).\n\nTo test this query in Postman, we will create a new POST request where the URL is provided by Realm (GraphQL Endpoint). In the body of the request, we will select GraphQL and write:\n\n```\nquery {\n  oneTitleMovies {\n    title\n    cast\n  }\n}\n```\n\nWhen working with Realm and an external GraphQL client, we need to add some kind of **authentication.** In a previous step, we created an API Key as an authentication provider, although we can use any of them.\n\nIn the request headers, we should add:\n\n``` javascript\n{\"apiKey\",\"{{api_key}}\"}\n```\n\nWhere we replace “*{{api\\_key}}*” with the value obtained previously.\n\nA general idea of what Postman’s cURL for this request would look like is:\n\n``` bash\ncurl --location --request POST '[your_graphql_endpoint]' \\\n --header 'apiKey: [your_api_key]' \\\n --header 'Content-Type: application/json' \\\n --data-raw '{\"query\": \"query {\"query oneTitleMovies {\"title\" {\"cast\", \"variables\":{}}'\n```\n\n![Postman request for a GraphQL query](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/0_Mu_P4o_Gnc1g660_Z1_F_33761d1369)\n\n## Add an **Input Type** to our **Custom Resolver**\n\nWhen we created our custom resolver, we associated it to a function. This function had some preset parameters:\n\n1. “imdb.rating”: { $gte: 7 }\n2. genres: { $nin: [ “Crime”, “Horror” ] } ,\n3. rated: { $in: [ “PG”, “G” ] },\n4. languages: { $all: [ “English”, “Japanese” ] } }\n\nWe can create an **Input Type** of type **Custom Type** so that those values that are fixed for the moment can be sent by parameters. **Custom Types** must be defined as a Schema in a JSON object. For our use case, our Schema will be the following:\n\n``` json\n{\n  \"bsonType\": \"object\",\n  \"title\": \"Filter\",\n  \"required\" : [\n      \"imdbRating\",\n      \"genres\",\n      \"rated\"],\n  \"properties\": {\n    \"imdbRating\": {\n      \"bsonType\": \"int\"\n    },\n    \"genres\": {\n      \"bsonType\": \"array\",\n      \"items\": {\n        \"bsonType\": \"string\"\n      }\n    },\n    \"rated\": {\n      \"bsonType\": \"array\",\n      \"items\": {\n        \"bsonType\": \"string\"\n      }\n    },\n    \"languages\": {\n      \"bsonType\": \"array\",\n      \"items\": {\n        \"bsonType\": \"string\"\n      }\n    }\n  }\n}\n```\n\nWe will make the “IMDB.rating”, “genres” and “rated” fields mandatory so that they have to be always sent and the “languages” field will be optional.\n\n![Input Type of Custom Type in Custom Resolver](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/0_R7_PGJ_98l_L4_C2x_Nlx_68abb12e92)\n\nTo be able to use the data sent by our new **Input Type**,we must modify the linked function so that we can receive them by parameters.\n\n``` javascript\nexports = async function({imdbRating, genres, rated, languages}) {\n\n  const request = context.services.get('mongodb-atlas').db('sample_mflix').collection('movies');\n\n  const lang = languages === undefined ? [\"English\", \"Japanese\"] : languages;\n\n  const pipeline = [\n  {\n    $match: {\n      \"imdb.rating\": { \"$gte\": imdbRating },\n      \"genres\": { \"$nin\": genres } ,\n      \"rated\": { \"$in\": rated },\n      \"languages\": { \"$all\": lang }\n    }\n  }];\n\n  return await request.aggregate(pipeline).toArray()\n  .then(data => {\n    console.log(data.length);\n    return data;\n  })\n  .catch(err => {\n    console.log(err.toString());\n    return err.toString();\n  });\n};\n```\n\nSince we know that “imdbRating”, “genres” and “rated” are mandatory, we can assume that they will always come as parameters and therefore we assign them directly to our *aggregation*. For the “languages” field as it is optional, we will have to verify that there is indeed an associated value and if not we will send default values.\n\nNow we can test this query in our external GraphQL client. The query would look like this (to get the same results as at the beginning):\n\n```\nquery {\n  oneTitleMovies(input: {\n      imdbRating: 7\n      genres: [\n          \"Crime\"\n          \"Horror\"\n      ]\n      rated: [\n          \"PG\"\n          \"G\"\n      ]\n      languages: [\n          \"English\"\n          \"Japanese\"\n      ]\n  }) {\n      title\n  }\n}\n```\n\nFrom here we can play with the different fields of our input to filter our results. One of the advantages of using GraphQL as a replacement for a Rest API is that the fields or response values can be selected in advance. In our example above, we are only returning the “title” field, but we could return a subset of all the fields in the “Movies” collection.\n\n## Wrapping up\n\nRealm GraphQL is a powerful tool to create serverless applications that can easily cover all your basic and complex use cases. Using Realm as a BaaS can help you build and deploy applications faster than ever.\n\nIn this tutorial, we have learned how to create a custom resolver linked to a function to resolve an aggregation pipeline. You can simply adapt this example to your own complex use case.\n\nQuestions? Comments? We'd love to connect with you. Join the conversation on the [MongoDB Community Forums.](https://developer.mongodb.com/community/forums/c/realm/9)\n\n## Download example code from GitHub\n\nYou can download the sample code from [here](https://github.com/josmanperez/realmGraphQLCustomResolverDemo) and [import](https://docs.mongodb.com/realm/deploy/realm-cli-reference/) it into your Realm application with\n\n``` bash\nrealm-cli import \\\n  --app-id=myapp-abcde \\\n  --path=./path/to/app/dir \\\n  --strategy=merge \\\n  --include-hosting \\\n  --include-dependencies\n```","originalPublishDate":"2021-05-25T14:26:19.333Z","SEO":"60941f03abd802638204300e","related_content":[],"createdAt":"2021-05-06T15:35:44.648Z","originalUpdatedAt":"2021-05-25T19:57:50.570Z","image":{"_id":"609945d0b4522964e193dbd4","name":"*realm-logo.jpeg","alternativeText":"MongoDB Realm Logo","caption":"","hash":"realm_logo_df21d716eb","ext":".jpeg","mime":"image/jpeg","size":12.68,"width":360,"height":360,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/realm_logo_df21d716eb.jpeg","formats":{"thumbnail":{"name":"*thumbnail_realm-logo.jpeg","hash":"thumbnail_realm_logo_df21d716eb","ext":".jpeg","mime":"image/jpeg","width":156,"height":156,"size":3.49,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/thumbnail_realm_logo_df21d716eb.jpeg"}},"provider":"aws-s3","related":["60940cd0abd8026382042fc9","60b8c64f73611914a1215bcf","61852fc1f08d85001c0415b9"],"createdAt":"2021-05-10T14:40:16.340Z","updatedAt":"2022-02-02T09:38:59.831Z","__v":0,"id":"609945d0b4522964e193dbd4"},"description":"The aim of this tutorial is to learn how to use Custom Resolvers for complex use cases.","__v":3,"other_tags":[{"__component":"other-tag-info.other-tag-info","id":"6271b24153b13d001c33b48b"}],"primary_tag":[{"__component":"primary-tag-info.l1-product","id":"6271b24153b13d001c33b489"}],"updatedAt":"2022-07-19T16:19:21.975Z","calculated_slug":"/products/realm/realm-graphql-demo-custom-resolvers","published_at":"2022-05-09T19:25:21.291Z","id":"6244b4fd7a304f0ca6c4d94f"},"id":"628062205b0afa001d0d2431"}],"createdAt":"2022-05-15T01:06:18.497Z","updatedAt":"2022-05-15T02:15:25.964Z","__v":1,"id":"6280520a94a546001c2bcc7e"},{"_id":"6300e491e50177001c2bf430","title":"*Fullstack Web App with MongoDB Atlas App Services, GraphQL, and React","published_at":"2022-08-24T07:04:40.178Z","seriesEntry":[{"__component":"article-info.strapi-new-article","_id":"6300e491e50177001c2bf431","__v":0,"new_article":{"awaiting_editorial_review":false,"awaiting_technical_review":false,"editorial_review_LGTM":true,"technical_review_LGTM":true,"authors":["6300d5347ff846001c45beb1"],"_id":"6300d5397ff846001c45beb3","published_at":"2022-08-24T07:04:07.203Z","content":"# Configure Email/Password Authentication in MongoDB Atlas App Services\n\nOne of the things I like the most is building full-stack apps using Node.js, React, and MongoDB. Every time I get a billion-dollar idea, I immediately start building it using this tech stack. No matter what app I’m working on, there are a few features that are common:\n\n- Authentication and authorization: login, signup, and access controls.\n- Basic CRUD (Create, Read, Update, and Delete) operations.\n- Data analytics.\n- Web application deployment.\n\nAnd without a doubt, all of them play an essential role in any full-stack application. But still, they take a lot of time and energy to build and are mostly repetitive in nature. Therefore, we are left with significantly less time to build the features that our customers are waiting for.\nIn an ideal scenario, your time as a developer should be spent on implementing features and not reinventing the wheel. With [MongoDB Atlas App Services](https://www.mongodb.com/atlas/app-services), you don’t have to worry about that. All you have to do is connect your client app to the service you need and you’re ready to rock!\nThroughout this series, you will learn how to build a full stack web application with MongoDB Atlas App Services, GraphQL, and React. We will be building an expense manager application called Expengo.\n\n## Authentication\n\nImplementing authentication in your app usually requires you to create and deploy a server while making sure that emails are unique, passwords are encrypted, and sessions/tokens are managed securely.\nIn this blog, we’ll configure email/password authentication on Atlas App Services. In the subsequent part of this series, we’ll integrate this with our React app.\n\n![Expengo app walkthrough](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/walkthrough_a085dddc6a.gif)\n\n## MongoDB Atlas App Services authentication providers\nMongoDB Atlas is a developer data platform integrating a multi-cloud database service with a set of data services. Atlas App Services provide secure serverless backend services and APIs to save you hours of coding.\nFor authentication, you can choose from many different providers such as email/password, API key, Google, Apple, and Facebook. For this tutorial, we’ll use the email/password authentication provider.\n\n## Deploy your free tier Atlas cluster\nIf you haven’t already, [deploy a free tier](https://www.mongodb.com/docs/atlas/tutorial/deploy-free-tier-cluster/) MongoDB Atlas cluster. This will allow us to store and retrieve data from our database deployment. You will be asked to add your IP to the IP access list and create a username/password to access your database. Once a cluster is created, you can create an App Service and link to it.\n\n## Set up your App Service\nNow, click on the “App Services” tab as highlighted in the image below:\n\n![Database Deployments screen highlighting App Services tab](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/App_Services_tab_5d34a6032b.png)\n\nThere are a variety of templates one can choose from. For this tutorial, we will continue with the “Build your own App” template and click “Next.”\n\n![Atlas App Services welcome page highlighting the Build Your Own App feature](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/Select_a_template_06356e9eb4.png)\n\nAdd application information in the next pop-up and click on “Create App Service.”\n\n![Connecting data to Atlas App Services](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/Create_App_Services_Dialog_4c6ddcdc76.png)\n\nClick on “Close Guides” in the next pop-up screen.\n\n![Application guides for Atlas App Services](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/Close_guides_54b8ce39f3.png)\n\nNow click on “Authentication” in the side-bar. Then, click on the “Edit” button on the right side of Email/Password in the list of Authentication Providers.\n\n![Authentication providers for Atlas App Services](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/Turn_on_authentication_d4528fa3b6.png)\n\nMake sure the Provider Enabled toggle is set to On.\n\nOn this page, we may also configure the user confirmation settings and the password reset settings for our application.  For the sake of simplicity of this tutorial, we will choose:\n\n1. User confirmation method: “Automatically confirm users.”\n2. Password reset method: “Send a password reset email.”\n3. Placeholder password reset URL: http://localhost:3000/resetPassword.\n    > We're not going to implement a password reset functionality in our client application. With that said, the URL you enter here doesn't really matter. If you want to learn how to reset passwords with App Services, check out the [dedicated documentation](https://www.mongodb.com/docs/atlas/app-services/authentication/email-password/#password-resets).\n4. Click “Save Draft.”\n\n![Defining authentication settings within Atlas App Services](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/Authentication_provider_06d7d94eee.png)\n\nOnce your Draft has been saved, you will see a blue pop-up at the top, with a “Review Draft & Deploy” button. Click on it and wait for a few moments.\n\n![Review Draft & Deploy button in App Services](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/Review_Draft_and_Deploy_115d03c3ef.png)\n\nYou will see a pop-up displaying all the changes you made in this draft. Click on “Deploy” to deploy these changes:\n\n![Deployment draft in Atlas App Services](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/Deploy_Draft_9cafaa3f80.png)\n\nYou will see a “Deployment was successful” message in green at the top if everything goes fine. Yay!\n\n![Successful deployment notification](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/Deployment_was_successful_ffc92d6da9.png)\n\n## Conclusion\n\nPlease note that all the screenshots were last updated in August 2022. Some UX details may have changed in more recent releases.\nIn the next article of the series, we will learn how we can utilize this email/password authentication provider in our React app.\n","slug":"/email-password-authentication-app-services","description":"In less than 6 steps, learn how to set up authentication and allow your users to log in and sign up to your app without writing a single line of server code.","name":"*Configure Email/Password Authentication in MongoDB Atlas App Services","SEO":"6300d5397ff846001c45beb4","related_content":[],"primary_tag":[{"__component":"primary-tag-info.l1-product","id":"6300d5397ff846001c45beb8"}],"other_tags":[{"__component":"other-tag-info.other-tag-info","id":"6300d5397ff846001c45beba"}],"createdAt":"2022-08-20T12:36:09.230Z","updatedAt":"2023-01-11T12:45:25.097Z","__v":3,"image":{"_id":"6300d3f6e50177001c2bf410","name":"*fullstack-app-react-app-services-graphql.png","alternativeText":"","caption":"","hash":"fullstack_app_react_app_services_graphql_c6f56d5635","ext":".png","mime":"image/png","size":158.1,"width":1400,"height":815,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/fullstack_app_react_app_services_graphql_c6f56d5635.png","formats":{"thumbnail":{"name":"*thumbnail_fullstack-app-react-app-services-graphql.png","hash":"thumbnail_fullstack_app_react_app_services_graphql_c6f56d5635","ext":".png","mime":"image/png","width":245,"height":143,"size":26.61,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/thumbnail_fullstack_app_react_app_services_graphql_c6f56d5635.png"},"large":{"name":"*large_fullstack-app-react-app-services-graphql.png","hash":"large_fullstack_app_react_app_services_graphql_c6f56d5635","ext":".png","mime":"image/png","width":1000,"height":582,"size":133.9,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/large_fullstack_app_react_app_services_graphql_c6f56d5635.png"},"medium":{"name":"*medium_fullstack-app-react-app-services-graphql.png","hash":"medium_fullstack_app_react_app_services_graphql_c6f56d5635","ext":".png","mime":"image/png","width":750,"height":437,"size":94.9,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/medium_fullstack_app_react_app_services_graphql_c6f56d5635.png"},"small":{"name":"*small_fullstack-app-react-app-services-graphql.png","hash":"small_fullstack_app_react_app_services_graphql_c6f56d5635","ext":".png","mime":"image/png","width":500,"height":291,"size":61.51,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/small_fullstack_app_react_app_services_graphql_c6f56d5635.png"}},"provider":"aws-s3","related":["6300d5397ff846001c45beb3","6300dcc6e50177001c2bf414","6300e3c6e50177001c2bf426","632df417bddb9d001ec48f7e","632dd957494dd3001e03710d","632dea6d494dd3001e037142"],"createdAt":"2022-08-20T12:30:46.302Z","updatedAt":"2022-11-01T16:46:50.729Z","__v":0,"id":"6300d3f6e50177001c2bf410"},"calculated_slug":"/products/atlas/email-password-authentication-app-services","expiry_date":"2023-08-20T12:36:09.230Z","id":"6300d5397ff846001c45beb3"},"id":"6300e491e50177001c2bf431"},{"__component":"article-info.strapi-new-article","_id":"6300e491e50177001c2bf432","__v":0,"new_article":{"awaiting_editorial_review":false,"awaiting_technical_review":false,"editorial_review_LGTM":true,"technical_review_LGTM":true,"authors":["6300d5347ff846001c45beb1"],"_id":"6300dcc6e50177001c2bf414","published_at":"2022-08-24T07:04:20.448Z","content":"# Implement Email/Password Authentication in React\nWelcome back to our journey building a full stack web application with MongoDB Atlas App Services, GraphQL, and React!\n\nIn the [first part of the series](https://www.mongodb.com/developer/products/atlas/email-password-authentication-app-services), we configured the email/password authentication provider in our backend App Service. In this second article, we will integrate the authentication into a web application built with React. We will write only a single line of server-side code and let the App Service handle the rest!\n\nWe will also build the front end of our expense management application, Expengo, using React. By the end of today’s tutorial, we will have the following web application:\n\n![Expengo application walkthrough](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/0_Hn_2_D_Mk_Z778_Ry6oz_1_06ebd7bc2f.gif)\n\n## Set up your React web application\n\nMake sure you have [Node.js and npm installed](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm) on your machine. You can check if they’re correctly set up by running the following commands in your terminal emulator:\n\n```sh\nnode -v\nnpm -v\n```\n\n### Create the React app\nLet’s create a brand new React app. Launch your terminal and execute the following command, where “expengo” will be the name of our app:\n\n```sh\nnpx create-react-app expengo -y\n```\n\nThe process may take up to a minute to complete. After it’s finished, navigate to your new project:\n\n```sh\ncd expengo\n```\n\n### Add required dependencies\nNext, we’ll install the [Realm Web SDK](https://www.mongodb.com/docs/realm/web/). The SDK enables browser-based applications to access data stored in MongoDB Atlas and interact with Atlas App Services like Functions, authentication, and GraphQL.\n\n```\nnpm install realm-web\n```\n\nWe’ll also install a few other npm packages to make our lives easier:\n\n1. [React-router-dom](https://reactrouter.com/docs/en/v6) to manage navigation in our app:\n\n    ```\n    npm install react-router-dom\n    ```\n   \n1. [Material UI](https://mui.com/) to help us build beautiful components without writing a lot of CSS:\n\n    ```\n    npm install @mui/material @emotion/styled @emotion/react\n    ```\n\n### Scaffold the application structure\nFinally, let’s create three new directories with a few files in them. To do that, we’ll use the shell. Feel free to use a GUI or your code editor if you prefer.\n\n```sh\n(cd src/ && mkdir pages/ contexts/ realm/)\n(cd src/pages && touch Home.page.js PrivateRoute.page.js Login.page.js Signup.page.js)\n(cd src/contexts && touch user.context.js)\n(cd src/realm && touch constants.js)\n```\n\nOpen the expengo directory in your code editor. The project directory should have the following structure:\n\n```\n├── README.md\n└──node_modules/\n├── …\n├── package-lock.json\n├── package.json\n└── public/\n ├── …\n└──src/\n └──contexts/\n  ├──user.context.js\n └──pages/\n  ├──Home.page.js\n  ├──PrivateRoute.page.js\n  ├──Login.page.js\n  ├──Signup.page.js\n └── realm/\n  ├──constants.js\n ├── App.css\n ├── App.js\n ├── App.test.js\n ├── index.css\n ├── index.js\n ├── logo.svg\n ├── reportWebVitals.js\n └── setupTests.js\n```\n\n## Connect your React app with App Services and handle user management\n\nIn this section, we will be creating functions and React components in our app to give our users the ability to log in, sign up, and log out.\n\n* Start by copying your App Services App ID:\n\n![Atlas App Services Screen highlight the Copy App ID button.](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/Copy_App_ID_53e06faff4.png)\n\nNow open this file: `./src/realm/constants.js`\n\nPaste the following code and replace the placeholder with your app Id:\n\n```js\nexport const APP_ID = \"<-- Your App ID -->\";\n```\n\n\n### Create a React Context for user management\nNow we will add a new React Context on top of all our routes to get access to our user’s details, such as their profile and access tokens. Whenever we need to call a function on a user’s behalf, we can easily do that by consuming this React Context through child components.\nThe following code also implements functions that will do all the interactions with our Realm Server to perform authentication. Please take a look at the comments for a function-specific description.\n\n**./src/contexts/user.context.js**\n\n```js\nimport { createContext, useState } from \"react\";\nimport { App, Credentials } from \"realm-web\";\nimport { APP_ID } from \"../realm/constants\";\n \n// Creating a Realm App Instance\nconst app = new App(APP_ID);\n \n// Creating a user context to manage and access all the user related functions\n// across different components and pages.\nexport const UserContext = createContext();\n \nexport const UserProvider = ({ children }) => {\n const [user, setUser] = useState(null);\n \n // Function to log in user into our App Service app using their email & password\n const emailPasswordLogin = async (email, password) => {\n   const credentials = Credentials.emailPassword(email, password);\n   const authenticatedUser = await app.logIn(credentials);\n   setUser(authenticatedUser);\n   return authenticatedUser;\n };\n \n // Function to sign up user into our App Service app using their email & password\n const emailPasswordSignup = async (email, password) => {\n   try {\n     await app.emailPasswordAuth.registerUser(email, password);\n     // Since we are automatically confirming our users, we are going to log in\n     // the user using the same credentials once the signup is complete.\n     return emailPasswordLogin(email, password);\n   } catch (error) {\n     throw error;\n   }\n };\n \n // Function to fetch the user (if the user is already logged in) from local storage\n const fetchUser = async () => {\n   if (!app.currentUser) return false;\n   try {\n     await app.currentUser.refreshCustomData();\n     // Now, if we have a user, we are setting it to our user context\n     // so that we can use it in our app across different components.\n     setUser(app.currentUser);\n     return app.currentUser;\n   } catch (error) {\n     throw error;\n   }\n }\n \n // Function to logout user from our App Services app\n const logOutUser = async () => {\n   if (!app.currentUser) return false;\n   try {\n     await app.currentUser.logOut();\n     // Setting the user to null once loggedOut.\n     setUser(null);\n     return true;\n   } catch (error) {\n     throw error\n   }\n }\n \n return <UserContext.Provider value={{ user, setUser, fetchUser, emailPasswordLogin, emailPasswordSignup, logOutUser }}>\n   {children}\n </UserContext.Provider>;\n}\n```\n\n## Create a PrivateRoute page\nThis is a wrapper page that will only allow authenticated users to access our app’s private pages. We will see it in action in our ./src/App.js file.\n\n**./src/pages/PrivateRoute.page.js**\n\n```js\nimport { useContext } from \"react\";\nimport { Navigate, Outlet, useLocation } from \"react-router-dom\";\nimport { UserContext } from \"../contexts/user.context\";\n \nconst PrivateRoute = () => {\n \n // Fetching the user from the user context.\n const { user } = useContext(UserContext);\n const location = useLocation();\n const redirectLoginUrl = `/login?redirectTo=${encodeURI(location.pathname)}`;\n \n // If the user is not logged in we are redirecting them\n // to the login page. Otherwise we are letting them to\n // continue to the page as per the URL using <Outlet />.\n return !user ? <Navigate to={redirectLoginUrl} /> : <Outlet /> ;\n}\n \nexport default PrivateRoute;\n```\n\n\n## Create a login page\nNext, let’s add a login page.\n\n**./src/pages/Login.page.js**\n\n```js\nimport { Button, TextField } from \"@mui/material\";\nimport { useContext, useEffect, useState } from \"react\";\nimport { Link, useLocation, useNavigate } from \"react-router-dom\";\nimport { UserContext } from \"../contexts/user.context\";\n \nconst Login = () => {\n const navigate = useNavigate();\n const location = useLocation();\n \n // We are consuming our user-management context to\n // get & set the user details here\n const { user, fetchUser, emailPasswordLogin } = useContext(UserContext);\n \n // We are using React's \"useState\" hook to keep track\n //  of the form values.\n const [form, setForm] = useState({\n   email: \"\",\n   password: \"\"\n });\n \n // This function will be called whenever the user edits the form.\n const onFormInputChange = (event) => {\n   const { name, value } = event.target;\n   setForm({ ...form, [name]: value });\n };\n \n // This function will redirect the user to the\n // appropriate page once the authentication is done.\n const redirectNow = () => {\n   const redirectTo = location.search.replace(\"?redirectTo=\", \"\");\n   navigate(redirectTo ? redirectTo : \"/\");\n }\n \n // Once a user logs in to our app, we don’t want to ask them for their\n // credentials again every time the user refreshes or revisits our app, \n // so we are checking if the user is already logged in and\n // if so we are redirecting the user to the home page.\n // Otherwise we will do nothing and let the user to login.\n const loadUser = async () => {\n   if (!user) {\n     const fetchedUser = await fetchUser();\n     if (fetchedUser) {\n       // Redirecting them once fetched.\n       redirectNow();\n     }\n   }\n }\n \n // This useEffect will run only once when the component is mounted.\n // Hence this is helping us in verifying whether the user is already logged in\n // or not.\n useEffect(() => {\n   loadUser(); // eslint-disable-next-line react-hooks/exhaustive-deps\n }, []);\n \n // This function gets fired when the user clicks on the \"Login\" button.\n const onSubmit = async (event) => {\n   try {\n     // Here we are passing user details to our emailPasswordLogin\n     // function that we imported from our realm/authentication.js\n     // to validate the user credentials and log in the user into our App.\n     const user = await emailPasswordLogin(form.email, form.password);\n     if (user) {\n       redirectNow();\n     }\n   } catch (error) {\n       if (error.statusCode === 401) {\n          alert(\"Invalid username/password. Try again!\");\n      } else {\n          alert(error);\n      }\n \n   }\n };\n \n return <form style={{ display: \"flex\", flexDirection: \"column\", maxWidth: \"300px\", margin: \"auto\" }}>\n   <h1>Login</h1>\n   <TextField\n     label=\"Email\"\n     type=\"email\"\n     variant=\"outlined\"\n     name=\"email\"\n     value={form.email}\n     onChange={onFormInputChange}\n     style={{ marginBottom: \"1rem\" }}\n   />\n   <TextField\n     label=\"Password\"\n     type=\"password\"\n     variant=\"outlined\"\n     name=\"password\"\n     value={form.password}\n     onChange={onFormInputChange}\n     style={{ marginBottom: \"1rem\" }}\n   />\n   <Button variant=\"contained\" color=\"primary\" onClick={onSubmit}>\n     Login\n   </Button>\n   <p>Don't have an account? <Link to=\"/signup\">Signup</Link></p>\n </form>\n}\n \nexport default Login;\n```\n\n\n## Create a signup page\nNow our users can log into the application, but how do they sign up? Time to add a signup page!\n\n**./src/pages/Signup.page.js**\n\n```js\nimport { Button, TextField } from \"@mui/material\";\nimport { useContext, useState } from \"react\";\nimport { Link, useLocation, useNavigate } from \"react-router-dom\";\nimport { UserContext } from \"../contexts/user.context\";\n \nconst Signup = () => {\n const navigate = useNavigate();\n const location = useLocation();\n \n // As explained in the Login page.\n const { emailPasswordSignup } = useContext(UserContext);\n const [form, setForm] = useState({\n   email: \"\",\n   password: \"\"\n });\n \n // As explained in the Login page.\n const onFormInputChange = (event) => {\n   const { name, value } = event.target;\n   setForm({ ...form, [name]: value });\n };\n \n \n // As explained in the Login page.\n const redirectNow = () => {\n   const redirectTo = location.search.replace(\"?redirectTo=\", \"\");\n   navigate(redirectTo ? redirectTo : \"/\");\n }\n \n // As explained in the Login page.\n const onSubmit = async () => {\n   try {\n     const user = await emailPasswordSignup(form.email, form.password);\n     if (user) {\n       redirectNow();\n     }\n   } catch (error) {\n     alert(error);\n   }\n };\n \n return <form style={{ display: \"flex\", flexDirection: \"column\", maxWidth: \"300px\", margin: \"auto\" }}>\n   <h1>Signup</h1>\n   <TextField\n     label=\"Email\"\n     type=\"email\"\n     variant=\"outlined\"\n     name=\"email\"\n     value={form.email}\n     onInput={onFormInputChange}\n     style={{ marginBottom: \"1rem\" }}\n   />\n   <TextField\n     label=\"Password\"\n     type=\"password\"\n     variant=\"outlined\"\n     name=\"password\"\n     value={form.password}\n     onInput={onFormInputChange}\n     style={{ marginBottom: \"1rem\" }}\n   />\n   <Button variant=\"contained\" color=\"primary\" onClick={onSubmit}>\n     Signup\n   </Button>\n   <p>Have an account already? <Link to=\"/login\">Login</Link></p>\n </form>\n}\n \nexport default Signup;\n```\n\n\n## Create a homepage\nOur homepage will be a basic page with a title and logout button.\n\n**./src/pages/Home.page.js:**\n\n```js\nimport { Button } from '@mui/material'\nimport { useContext } from 'react';\nimport { UserContext } from '../contexts/user.context';\n \nexport default function Home() {\n const { logOutUser } = useContext(UserContext);\n \n // This function is called when the user clicks the \"Logout\" button.\n const logOut = async () => {\n   try {\n     // Calling the logOutUser function from the user context.\n     const loggedOut = await logOutUser();\n     // Now we will refresh the page, and the user will be logged out and\n     // redirected to the login page because of the <PrivateRoute /> component.\n     if (loggedOut) {\n       window.location.reload(true);\n     }\n   } catch (error) {\n     alert(error)\n   }\n }\n \n return (\n   <>\n     <h1>Welcome to Expengo</h1>\n     <Button variant=\"contained\" onClick={logOut}>Logout</Button>\n   </>\n )\n}\n```\n\n\n## Putting it all together in App.js\nLet’s connect all of our pages in the root React component—App.\n\n**./src/App.js**\n\n```js\nimport { BrowserRouter, Route, Routes } from \"react-router-dom\";\nimport { UserProvider } from \"./contexts/user.context\";\nimport Home from \"./pages/Home.page\";\nimport Login from \"./pages/Login.page\";\nimport PrivateRoute from \"./pages/PrivateRoute.page\";\nimport Signup from \"./pages/Signup.page\";\n \nfunction App() {\n return (\n   <BrowserRouter>\n     {/* We are wrapping our whole app with UserProvider so that */}\n     {/* our user is accessible through out the app from any page*/}\n     <UserProvider>\n       <Routes>\n         <Route exact path=\"/login\" element={<Login />} />\n         <Route exact path=\"/signup\" element={<Signup />} />\n         {/* We are protecting our Home Page from unauthenticated */}\n         {/* users by wrapping it with PrivateRoute here. */}\n         <Route element={<PrivateRoute />}>\n           <Route exact path=\"/\" element={<Home />} />\n         </Route>\n       </Routes>\n     </UserProvider>\n   </BrowserRouter>\n );\n}\n \nexport default App;\n```\n\n\n## Launch your React app\nAll have to do now is run the following command from your project directory:\n\n```\nnpm start\n```\n\nOnce the compilation is complete, you will be able to access your app from your browser at http://localhost:3000/. You should be able to sign up and log into your app now.\n\n## Conclusion\nWoah! We have made a tremendous amount of progress. Authentication is a very crucial part of any app and once that’s done, we can focus on features that will make our users’ lives easier. In the next part of this blog series, we’ll be leveraging App Services GraphQL to perform CRUD operations. I’m excited about that because the basic setup is already over.\n\nIf you have any doubts or concerns, please feel free to reach out to us on the MongoDB Community Forums. I have created a [dedicated forum topic](https://www.mongodb.com/community/forums/t/build-a-full-stack-app-using-mongodb-realm-graphql-without-worrying-about-servers-at-all/156840) for this blog where we can discuss anything related to this blog series.\n\nAnd before you ask, here’s the [GitHub repository](https://github.com/sourabhbagrecha/expengo), as well!\n","slug":"/email-password-authentication-react","description":"Configuring signup and login authentication is a common step for nearly every web application. Learn how to set up email/password authentication in React using MongoDB Atlas App Services.","name":"*Implement Email/Password Authentication in React","SEO":"6300dcc6e50177001c2bf415","related_content":[],"primary_tag":[{"__component":"primary-tag-info.l1-product","id":"6300dcc6e50177001c2bf419"}],"other_tags":[{"__component":"other-tag-info.other-tag-info","id":"6300dcc6e50177001c2bf41b"}],"createdAt":"2022-08-20T13:08:22.447Z","updatedAt":"2022-08-24T07:04:20.526Z","__v":3,"image":{"_id":"6300d3f6e50177001c2bf410","name":"*fullstack-app-react-app-services-graphql.png","alternativeText":"","caption":"","hash":"fullstack_app_react_app_services_graphql_c6f56d5635","ext":".png","mime":"image/png","size":158.1,"width":1400,"height":815,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/fullstack_app_react_app_services_graphql_c6f56d5635.png","formats":{"thumbnail":{"name":"*thumbnail_fullstack-app-react-app-services-graphql.png","hash":"thumbnail_fullstack_app_react_app_services_graphql_c6f56d5635","ext":".png","mime":"image/png","width":245,"height":143,"size":26.61,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/thumbnail_fullstack_app_react_app_services_graphql_c6f56d5635.png"},"large":{"name":"*large_fullstack-app-react-app-services-graphql.png","hash":"large_fullstack_app_react_app_services_graphql_c6f56d5635","ext":".png","mime":"image/png","width":1000,"height":582,"size":133.9,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/large_fullstack_app_react_app_services_graphql_c6f56d5635.png"},"medium":{"name":"*medium_fullstack-app-react-app-services-graphql.png","hash":"medium_fullstack_app_react_app_services_graphql_c6f56d5635","ext":".png","mime":"image/png","width":750,"height":437,"size":94.9,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/medium_fullstack_app_react_app_services_graphql_c6f56d5635.png"},"small":{"name":"*small_fullstack-app-react-app-services-graphql.png","hash":"small_fullstack_app_react_app_services_graphql_c6f56d5635","ext":".png","mime":"image/png","width":500,"height":291,"size":61.51,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/small_fullstack_app_react_app_services_graphql_c6f56d5635.png"}},"provider":"aws-s3","related":["6300d5397ff846001c45beb3","6300dcc6e50177001c2bf414","6300e3c6e50177001c2bf426","632df417bddb9d001ec48f7e","632dd957494dd3001e03710d","632dea6d494dd3001e037142"],"createdAt":"2022-08-20T12:30:46.302Z","updatedAt":"2022-11-01T16:46:50.729Z","__v":0,"id":"6300d3f6e50177001c2bf410"},"calculated_slug":"/products/atlas/email-password-authentication-react","expiry_date":"2023-08-20T13:08:22.447Z","id":"6300dcc6e50177001c2bf414"},"id":"6300e491e50177001c2bf432"},{"__component":"article-info.strapi-new-article","_id":"6300e491e50177001c2bf433","__v":0,"new_article":{"awaiting_editorial_review":false,"awaiting_technical_review":false,"editorial_review_LGTM":true,"technical_review_LGTM":true,"authors":["6300d5347ff846001c45beb1"],"_id":"6300e3c6e50177001c2bf426","published_at":"2022-08-24T07:04:36.031Z","content":"# CRUD Operations with GraphQL Using Atlas App Services\nOne of the things I enjoy the most is building full-stack apps using React.js, Node.js, and MongoDB. And no matter what kind of app I am building, CRUD—Create, Read, Update, and Delete—operations are the backbone of any application.\n\nAdding the ability to perform CRUD operations on your application’s data requires you to create and expose APIs that your client will consume to interact with the data stored in your database.\n\n## Why GraphQL?\nGraphQL gives clients (mobile/desktop/web apps) the ability to request the exact data they need, nothing more and nothing less. GraphQL is an alternative to REST APIs and the main difference is in the way in which client and server applications interact with each other.\n\nGraphQL, on the back end, defines a schema that describes all the possible data that the client can request. On the other hand, the frontend app can request the exact data that’s needed.\n\n## What does the Atlas GraphQL API provide?\nUsually, to provide this flexibility to the clients, the server side of things becomes very complex. We have to create and maintain a lot of resolvers so that we can fetch the requested data from the database on our server and then respond to the client with the data received from the database.\n\nBut today, we won’t be writing a single line of server-side code and yet we will be creating a fully functional GraphQL API allowing CRUD operations. All that with the Atlas GraphQL API!\n\nIn this part of the blog series, we will be configuring our MongoDB Atlas App Services to make sure that our GraphQL APIs do what they are intended to do in a secure and predictable manner.\n## Data model\nSince authorization and user management are handled by Atlas App Services out of the box, we don’t need to worry about managing user data on our own. All we need to do is store and manage expense data in a collection and give our users the ability to access the expenses created by them.\n\nAn expense document in our app would have the following fields:\n\n![Expengo app data model- representing the Expense schema.\nEvery expense in our collection will have\u001can _id, category, mode, title, amount, author id, and a createdAt timestamp.](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/expengo_data_model_d4a92fac05.png)\n\nFor example, a single expense document in the collection should look something like this:\n\n```json\n{\n \"_id\": { \"$oid\": \"61dbca296ce5d97556e52b18\" },\n \"category\": \"Entertainment\",\n \"mode\": \"Axis CC\",\n \"title\": \"Netflix\",\n \"amount\": { \"$numberInt\": \"149\" },\n \"author\": { \"$oid\": \"61d85eae766161a4497a6dd6\" },\n \"createdAt\": { \"$date\": { \"$numberLong\": \"1641795749000\" } }\n}\n```\n\n## Add sample data to your collections\nBefore building our GraphQL API, we’ll add sample data to our Atlas cluster.\n\n>  If you don’t have an Atlas cluster and an App Services app yet, check out the previous articles in this blog post series.\n\n\n1. Make sure you are on the “Atlas” tab, and then on “Browse Collections” on the cluster linked to your Atlas App Services’ app.\n\n    ![Atlas Database Deployment screen highlighting the \"Browse Collections\" button](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/browse_collections_9c55069e61.png)\n\n1. Now click on the “Add My Own Data” button, and hit “Create” once you enter the following information in the form:\n\n    1. Database name: “expengo”\n    2. Collection name: “expenses”\n\n    ![Demonstrating how to create a new Database and how to create a new collection in that database from the \"Collections\" tab.](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/add_my_own_data_cdc352035d.png)\n    \n1. Once done, click on “Insert Document” on the next screen.\n\n    ![Collections screen highlighting the \"Insert Document\" button](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/insert_document_b5eb01ba59.png)\n\n    ![\"Insert to Collection\" pop-up highlighting the JSON view button](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/insert_as_json_b398027a01.png)\n    \n1. Replace the content in the opened modal with the following:\n\n    ```json\n    {\n     \"_id\": { \"$oid\": \"61dbca296ce5d97556e52b18\" },\n     \"category\": \"Entertainment\",\n     \"mode\": \"Axis CC\",\n     \"title\": \"Netflix\",\n     \"amount\": { \"$numberInt\": \"149\" },\n     \"author\": { \"$oid\": \"61d85eae766161a4497a6dd6\" },\n     \"createdAt\": { \"$date\": { \"$numberLong\": \"1641795749000\" } }\n    }\n    ```\n\n    And hit “Insert” once done:\n\n    ![\"Insert to Collection\" pop-up having the data to be inserted and highlighting the \"Insert Button\".](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/insert_document_to_collection_351dc9aa32.png)\n    \n## Generate Schema in your App Services based on your data stored in Atlas\n\n[Schemas](https://www.mongodb.com/docs/atlas/app-services/schemas/) are your application's data model specification. Once you've defined a schema, App Services provides you with additional tools and services to work with data that conforms to the schema.\n\n[Atlas GraphQL API](https://www.mongodb.com/docs/atlas/app-services/graphql/) uses schemas to automatically generate a GraphQL schema, including types, queries, and mutations. You can extend your app's API with custom resolvers that reference the types defined by your schemas.\n\nNow, we’ll generate a schema from the data stored in our collection. Click on the buttons in the same sequence as mentioned in the image below:\nStep 1: Click on the “App Services” tab on the top and select the app that you created as part of the Authentication step of this blog series.\n\nStep 2: Click on the “Schema” link in the left navigation panel.\n\nStep 3: Select the “expenses” collection under “expengo.”\n\nStep 4: Click on the “Generate Schema” button.\n\n![App Services Screen highlighting the 4 steps mentioned above.](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/configure_schema_31f6e555ab.png)\n\nStep 5: Click on “Generate schema from sampling.”\n\n![\"Generate Schema from expenses\" screen highlighting the \"Generate Schema from sampling\" button.](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/generate_schema_from_sample_0dd8f85af5.png)\n\n\nStep 6: If everything goes fine, you will get the following JSON schema. Once confirmed, click on “Save Draft.”\n\nSchemas represent types of data rather than specific values. App Services supports many [built-in schema types](https://www.mongodb.com/docs/atlas/app-services/schemas/types/#std-label-schema-types). These include primitives, like strings and numbers, as well as structural types, like objects and arrays, which you can combine to create schemas that represent custom object types.\n\n![Schema screen highlighting our JSON Schema and the \"Save\" button on the top.](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/review_schema_and_deploy_8d860813e1.png)\n\n## Set up roles and configure permissions\nWe want to give our users the ability to create and access their own expenses and no one else should be able to access them. To make sure that the privacy of our users is maintained, we will need to set up roles and configure permissions to their expense data by following the steps outlined below:\n\nStep 1: Click on the “Rules” tab in the left navigation panel of the screen.\nStep 2: Select the expenses collection under the “expengo” database.\nStep 3: Click on the “Skip(start from scratch)” button since we want to add custom permissions to our users, which we will explore in the next screen.\n\n![Rules screen highlighting the step mentioned above.](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/set_up_rules_with_preset_role_954e411c9f.png)\n\nSince we want our users to CRUD (Create, Read, Update, and Delete) their own expenses, we will create a new role that will allow them to do the same and also protect their expenses from any unauthorized access.\n\nTherefore, we are going to create a new role with the name of “ExpenseOwner” as shown in the image below.\n\nStep 1: Enter name of the role as “ExpenseOwner.”\n\nStep 2: In the previous blog post, we implemented authentication in our app using MongoDB’s Atlas App Services. Now, whenever an authenticated user is making a request to App Services, you will be able to fetch their unique user id from the request.\n\nThe expression “`%%user.id`” will evaluate the ID of the user that is making the request.\nThe following JSON expression will make sure that any user who is making the request will only be able to create and access the expenses on their own behalf. \nIn the Apply When input, paste the following code:\n\n```json\n{\n  \"author\": {\n    \"%stringToOid\": \"%%user.id\"\n  }\n}\n```\n\nStep 3: Since we want to give our users the ability to insert, delete, and search their own expenses, we will allow all document permissions for this role.\n\nStep 4: Under the field permissions section, we will select “Read and Write” all fields so that our user will have full control over their expense data.\n\nStep 5: Click on the “Save Draft” button.\n\n![Rules screen highlighting the 5 steps to create a new role named \"ExpenseOwner\" as mentioned above.](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/set_up_rules_df4c71f576.png)\n\nAfter your draft is saved successfully, you will see the “ExpenseOwner” role appear on the Rules screen. Now, click on the “Review Draft and Deploy” button as shown below, and you are all set to utilize the Atlas GraphQL APIs in your application.\n\n![Rules screen highlighting the newly created ExpenseOwner Role and \"Review Draft & Deployment\" button.](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/review_and_deploy_rules_18ea33d0c3.png)\n\n## Conclusion\nAwesome! That’s all we needed to do to configure our app to perform CRUD operations.\n\nIf you have any doubts or concerns, please feel free to reach out to us on Community Forums. I have created a [dedicated forum topic](https://www.mongodb.com/community/forums/t/build-a-full-stack-app-using-mongodb-realm-graphql-without-worrying-about-servers-at-all/156840) for this blog where you can discuss anything related to this blog series.\n\nAnd before you ask, here’s the [GitHub Repository](https://github.com/sourabhbagrecha/expengo) for this tutorial series.\n\n","slug":"/crud-operations-with-graphql","description":"GraphQL gives clients the ability to request exactly the data they need, nothing more and nothing less. Learn how to perform CRUD operations using Atlas GraphQL API.","name":"*CRUD Operations with GraphQL Using Atlas App Services","SEO":"6300e3c6e50177001c2bf427","related_content":[],"primary_tag":[{"__component":"primary-tag-info.l1-product","id":"6300e3c6e50177001c2bf42b"}],"other_tags":[{"__component":"other-tag-info.other-tag-info","id":"6300e3c6e50177001c2bf42d"}],"createdAt":"2022-08-20T13:38:14.609Z","updatedAt":"2022-08-24T07:04:36.168Z","__v":3,"image":{"_id":"6300d3f6e50177001c2bf410","name":"*fullstack-app-react-app-services-graphql.png","alternativeText":"","caption":"","hash":"fullstack_app_react_app_services_graphql_c6f56d5635","ext":".png","mime":"image/png","size":158.1,"width":1400,"height":815,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/fullstack_app_react_app_services_graphql_c6f56d5635.png","formats":{"thumbnail":{"name":"*thumbnail_fullstack-app-react-app-services-graphql.png","hash":"thumbnail_fullstack_app_react_app_services_graphql_c6f56d5635","ext":".png","mime":"image/png","width":245,"height":143,"size":26.61,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/thumbnail_fullstack_app_react_app_services_graphql_c6f56d5635.png"},"large":{"name":"*large_fullstack-app-react-app-services-graphql.png","hash":"large_fullstack_app_react_app_services_graphql_c6f56d5635","ext":".png","mime":"image/png","width":1000,"height":582,"size":133.9,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/large_fullstack_app_react_app_services_graphql_c6f56d5635.png"},"medium":{"name":"*medium_fullstack-app-react-app-services-graphql.png","hash":"medium_fullstack_app_react_app_services_graphql_c6f56d5635","ext":".png","mime":"image/png","width":750,"height":437,"size":94.9,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/medium_fullstack_app_react_app_services_graphql_c6f56d5635.png"},"small":{"name":"*small_fullstack-app-react-app-services-graphql.png","hash":"small_fullstack_app_react_app_services_graphql_c6f56d5635","ext":".png","mime":"image/png","width":500,"height":291,"size":61.51,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/small_fullstack_app_react_app_services_graphql_c6f56d5635.png"}},"provider":"aws-s3","related":["6300d5397ff846001c45beb3","6300dcc6e50177001c2bf414","6300e3c6e50177001c2bf426","632df417bddb9d001ec48f7e","632dd957494dd3001e03710d","632dea6d494dd3001e037142"],"createdAt":"2022-08-20T12:30:46.302Z","updatedAt":"2022-11-01T16:46:50.729Z","__v":0,"id":"6300d3f6e50177001c2bf410"},"calculated_slug":"/products/atlas/crud-operations-with-graphql","expiry_date":"2023-08-20T13:38:14.609Z","id":"6300e3c6e50177001c2bf426"},"id":"6300e491e50177001c2bf433"}],"createdAt":"2022-08-20T13:41:37.077Z","updatedAt":"2022-08-24T07:04:40.213Z","__v":1,"id":"6300e491e50177001c2bf430"},{"_id":"63b80ded2fb860001caa7546","title":"*Deploying MongoDB Across Multiple Kubernetes Clusters","published_at":"2023-01-06T12:39:51.456Z","seriesEntry":[{"__component":"article-info.strapi-new-article","_id":"63b80ded2fb860001caa7547","__v":0,"new_article":{"awaiting_editorial_review":false,"awaiting_technical_review":false,"editorial_review_LGTM":true,"technical_review_LGTM":true,"authors":["63b7ff622fb860001caa7533"],"_id":"63b80256ebdd6d001c0b9b3f","published_at":"2023-01-13T15:10:37.547Z","content":"This article is part of a three-parts series on deploying MongoDB across multiple Kubernetes clusters using the operators.\n\n-   Deploying the MongoDB Enterprise Kubernetes Operator on Google Cloud\n\n-   [Mastering MongoDB Ops Manager](https://www.mongodb.com/developer/products/connectors/mastering-ops-manager)\n\n-   [Deploying MongoDB Across Multiple Kubernetes Clusters With MongoDBMulti](https://www.mongodb.com/developer/products/connectors/deploying-across-multiple-kubernetes-clusters)\n\nDeploying and managing MongoDB on Kubernetes can be a daunting task. It requires creating and configuring various Kubernetes resources, such as persistent volumes, services, and deployments, which can be time-consuming and require a deep understanding of both Kubernetes and MongoDB products. Furthermore, tasks such as scaling, backups, and upgrades must be handled manually, which can be complex and error-prone. This can impact the reliability and availability of your MongoDB deployment and may require frequent manual intervention to keep it running smoothly. Additionally, it can be hard to ensure that your MongoDB deployment is running in the desired state and is able to recover automatically from failures.\n\nFortunately, MongoDB offers operators, which are software extensions to the Kubernetes API that use custom resources to manage applications and their components. The MongoDB Operator translates human knowledge of creating a MongoDB instance into a scalable, repeatable, and standardized method, and leverages Kubernetes features to operate MongoDB for you. This makes it easier to deploy and manage MongoDB on Kubernetes, providing advanced features and functionality for running MongoDB in cloud-native environments.\n\nThere are three main Kubernetes operators available for deploying and managing MongoDB smoothly and efficiently in Kubernetes environments:\n\n-   [The MongoDB Community Kubernetes Operator](https://github.com/mongodb/mongodb-kubernetes-operator) is an open-source operator that is available for free and can be used to deploy and manage MongoDB Replica Set on any Kubernetes cluster. It provides basic functionality for deploying and managing MongoDB but does not include some of the more advanced features available in the Enterprise and Atlas operators.\n\n-   [The MongoDB Enterprise Kubernetes Operator ](https://github.com/mongodb/mongodb-enterprise-kubernetes)is a commercial Kubernetes operator included with the MongoDB Enterprise subscription. It allows you to easily deploy and manage any type of MongoDB deployment (standalone, replica set, sharded cluster) on Kubernetes, providing advanced features and functionality for deploying and managing MongoDB in cloud-native environments.\n\n-   [The MongoDB Atlas Kubernetes Operator](https://github.com/mongodb/mongodb-atlas-kubernetes) is an operator that is available as part of the Atlas service. It allows you to quickly deploy and manage MongoDB on the Atlas cloud platform, providing features such as automatic provisioning and scaling of MongoDB clusters, integration with Atlas features and services, and automatic backups and restores. You can learn more about this operator in our blog post on [application deployment in Kubernetes](https://www.mongodb.com/developer/products/atlas/kubernetes-operator-application-deployment/).\n\nThis article will focus on the Enterprise Operator. [The MongoDB Enterprise Kubernetes Operator](https://www.mongodb.com/docs/kubernetes-operator/master/) seamlessly integrates with other MongoDB Enterprise features and services, such as MongoDB Ops Manager (which can also run on Kubernetes) and MongoDB Cloud Manager. This allows you to easily monitor, back up, upgrade, and manage your MongoDB deployments from a single, centralized location, and provides access to a range of tools and services for managing, securing, and optimizing your deployment.\n\n## MongoDB Enterprise Kubernetes Operator\n\nThe MongoDB Enterprise [Kubernetes Operator](https://kubernetes.io/docs/concepts/extend-kubernetes/operator/) automates the process of creating and managing MongoDB instances in a scalable, repeatable, and standardized manner. It uses the Kubernetes API and tools to handle the lifecycle events of a MongoDB cluster, including provisioning storage and computing resources, configuring network connections, setting up users, and making changes to these settings as needed. This helps to ease the burden of manually configuring and managing stateful applications, such as databases, within the Kubernetes environment.\n\n![The Kubernetes Operator manages the typical lifecycle events for a MongoDB cluster: provisioning storage and computing power, configuring network connections, setting up users, and changing these settings as needed](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/kubernetes_operator_bakedsvg_1c1a6d427b.svg)\n\n## Kubernetes Custom Resource Definitions\n\n[Kubernetes CRDs](https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/) (Custom Resource Definitions) is a feature in Kubernetes that allows users to create and manage custom resources in their Kubernetes clusters. [Custom resources](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/) are extensions of the Kubernetes API that allow users to define their own object types and associated behaviors. With CRDs, you can create custom resources that behave like built-in Kubernetes resources, such as StatefulSets, Deployments, Pods, and Services, and manage them using the same tools and interfaces. This allows you to extend the functionality of Kubernetes and tailor it to their specific needs and requirements.\n\nThe MongoDB Enterprise Operator currently provides the following custom resources for deploying MongoDB on Kubernetes:\n\n-   [MongoDBOpsManager Custom Resource](https://github.com/mongodb/mongodb-enterprise-kubernetes/tree/master/samples/ops-manager)\n\n-   [MongoDB Custom Resource](https://www.mongodb.com/docs/kubernetes-operator/master/tutorial/mdb-resources-arch/#the-mongodb-custom-resource-definition)\n\n    -   Standalone\n\n    -   ReplicaSet\n\n    -   ShardedCluster\n\n-   [MongoDBUser Custom Resource](https://www.mongodb.com/docs/kubernetes-operator/master/tutorial/mdb-resources-arch/#reconciling-the-mongodbuser-custom-resource)\n\n-   [MongoDBMulti](https://www.mongodb.com/docs/kubernetes-operator/master/multi-cluster-arch/#deployment-architecture-and-diagram)\n\n![The following diagram describes how the Kubernetes Operator behaves if you make changes to a sharded cluster's](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/Mongo_DB_2d08c18419.png)\n\n[Example of Ops Manager and MongoDB Custom Resources on Kubernetes](https://drive.google.com/file/d/1q7dvZ9PT9YU2EtJNyeYyl00DjKvQajl9/view)\n\n## Installing and configuring Enterprise Kubernetes Operator\n\nFor this tutorial, we will need the following tools: \n\n-   [gcloud](https://cloud.google.com/sdk/docs/install)[ ](https://go.dev/dl/)\n\n-   [gke-cloud-auth-plugin](https://cloud.google.com/blog/products/containers-kubernetes/kubectl-auth-changes-in-gke)\n\n-   [Helm](https://helm.sh/docs/intro/install/)\n\n-   [kubectl](https://kubernetes.io/docs/tasks/tools/)\n\n-   [kubectx](https://github.com/ahmetb/kubectx)\n\n-   [Git](https://git-scm.com/downloads)\n\n## GKE Kubernetes cluster creation \n\nTo start, let's create a Kubernetes cluster in a new [project](https://cloud.google.com/resource-manager/docs/creating-managing-projects). We will be using [GKE Kubernetes](https://cloud.google.com/kubernetes-engine). I use this script to create the cluster. The cluster will have four worker nodes and act as Ops Manager and MongoDB Enterprise Operators Kubernetes Cluster.\n\n```bash\nCLUSTER_NAME=master-operator\nZONE=us-south1-a\nK8S_VERSION=1.23\nMACHINE=n2-standard-2\ngcloud container clusters create \"${CLUSTER_NAME}\" \\\n  --zone \"${ZONE}\" \\\n  --machine-type \"${MACHINE}\" --cluster-version=\"${K8S_VERSION}\" \\\n  --disk-type=pd-standard --num-nodes 4\n```\n\nNow that the cluster has been created, we need to obtain the credentials.\n\n```bash\ngcloud container clusters get-credentials \"${CLUSTER_NAME}\" \\\n  --zone \"${ZONE}\"\n```\n\n\nDisplay the newly created cluster.\n\n```bash\ngcloud container clusters list\n\nNAME                LOCATION       MASTER_VERSION    NUM_NODES  STATUS\nmaster-operator     us-south1-a    1.23.14-gke.1800      4      RUNNING\n```\n\nWe can also display Kubernetes full cluster name using [`kubectx`](https://github.com/ahmetb/kubectx).\n\n```bash\nkubectx\n```\n\nYou should see your cluster listed here. Make sure your context is set to master cluster.\n\n```bash\nkubectx $(kubectx | grep \"master-operator\" | awk '{print $1}')\n```\n\n\nWe are able to start MongoDB Kubernetes Operator installation on our newly created Kubernetes cluster! \n\n## Enterprise Kubernetes Operator \n\nWe can install the MongoDB Enterprise Operator with a single line Helm command. The first step is to  add the [MongoDB Helm Charts for Kubernetes](https://mongodb.github.io/helm-charts/) repository to Helm.\n\n```bash\nhelm repo add mongodb https://mongodb.github.io/helm-charts\n```\n\n\nI want to create the operator in a separate, dedicated Kubernetes namespace (the operator uses `default` namespace by default). This will allow me to isolate the operator and any resources it creates from other resources in my cluster. The following command will install the CRDs and the Enterprise Operator in the `mongodb-operator`namespace. The operator will be watching only the `mongodb-operator` namespace. You can read more about [setting up the operator to watch more namespaces](https://www.mongodb.com/docs/kubernetes-operator/master/tutorial/set-scope-k8s-operator/#operator-uses-a-subset-of-namespaces) in the official MongoDB documentation.\n\nStart by creating the `mongodb-operator`namespace.\n\n```bash\nNAMESPACE=mongodb-operator\nkubectl create ns \"${NAMESPACE}\"\n```\n\n\nInstall the MongoDB Kubernetes Operator and set it to watch only the `mongodb-operator` namespace.\n\n```bash\nHELM_CHART_VERSION=1.16.3\nhelm install enterprise-operator mongodb/enterprise-operator \\\n  --namespace \"${NAMESPACE}\" \\\n  --version=\"${HELM_CHART_VERSION}\" \\\n  --set operator.watchNamespace=\"${NAMESPACE}\"\n```\n\n\nThe namespace has been created and the operator is running! You can see this by listing the pods in the newly created namespace.\n\n```bash\nkubectl get ns\n\nNAME               STATUS   AGE\ndefault            Active   4m9s\nkube-node-lease    Active   4m11s\nkube-public        Active   4m12s\nkube-system        Active   4m12s\nmongodb-operator   Active   75s\n```\n\n```bash\nkubectl get po -n \"${NAMESPACE}\"\n\nNAME                                    READY   STATUS   RESTARTS   AGE\nmongodb-enterprise-operator-649bbdddf5   1/1    Running   0         7m9s\n```\n\n\nYou can see that the helm chart is running with this command.\n\n```bash\nhelm list --namespace \"${NAMESPACE}\"\n\nNAME                NAMESPACE     REVISION       VERSION\nenterprise-operator mongodb-operator 1 deployed enterprise-operator-1.17.2\n```\n\n### Verify the installation\n\nYou can verify that the installation was successful and is currently running with the following command.\n\n```bash\nhelm get manifest enterprise-operator --namespace \"${NAMESPACE}\"\n```\n\nLet's display Custom Resource Definitions installed in the step above in the watched namespace.\n\n```bash\nkubectl -n \"${NAMESPACE}\" get crd | grep -E '^(mongo|ops)'\n\nmongodb.mongodb.com                              2022-12-30T16:17:07Z\nmongodbmulti.mongodb.com                         2022-12-30T16:17:08Z\nmongodbusers.mongodb.com                         2022-12-30T16:17:09Z\nopsmanagers.mongodb.com                          2022-12-30T16:17:09Z\n```\n\n\nAll required service accounts has been created in watched namespace.\n\n```bash\nkubectl -n \"${NAMESPACE}\" get sa | grep -E '^(mongo)'\n\nmongodb-enterprise-appdb           1         36s\nmongodb-enterprise-database-pods   1         36s\nmongodb-enterprise-operator        1         36s\nmongodb-enterprise-ops-manager     1         36s\n```\n\nValidate if the Kubernetes Operator was installed correctly by running the following command and verify the output.\n\n```bash\nkubectl describe deployments mongodb-enterprise-operator -n \\\n  \"${NAMESPACE}\"\n```\n\n\nFinally, double-check watched namespaces.\n\n```bash\nkubectl describe deploy mongodb-enterprise-operator -n \"${NAMESPACE}\" | grep WATCH\n\n      WATCH_NAMESPACE:               mongodb-operator\n```\n\n\nThe MongoDB Enterprise Operator is now running in your GKE cluster.\n\n## MongoDB Atlas Kubernetes Operator\n\nIt's worth mentioning another operator here --- a new service that integrates Atlas resources with your Kubernetes cluster. Atlas can be deployed in multi-cloud environments including Google Cloud. The Atlas Kubernetes Operator allows you to deploy and manage cloud-native applications that require data services in a single control plane with secure enterprise platform integration.\n\nThis operator is responsible for managing resources in Atlas using Kubernetes custom resources, ensuring that the configurations of projects, database deployments, and database users in Atlas are consistent with each other. The Atlas Kubernetes Operator uses the `AtlasProject`, `AtlasDeployment`, and `AtlasDatabaseUser` Custom Resources that you create in your Kubernetes cluster to manage resources in Atlas.\n\nThese custom resources allow you to define and configure the desired state of your projects, database deployments, and database users in Atlas. To learn more, head over to our blog post on [application deployment in Kubernetes](https://www.mongodb.com/developer/products/atlas/kubernetes-operator-application-deployment/) with the MongoDB Atlas Operator.\n\n## Conclusion\n\nUpon the successful installation of the Kubernetes Operator, we are able to use the capabilities of the MongoDB Enterprise Kubernetes Operator to run MongoDB objects on our Kubernetes cluster. The Operator enables easy deploy of the following applications into Kubernetes clusters:\n\n-   MongoDB --- replica sets, sharded clusters, and standalones --- with authentication, TLS, and many more options.\n\n-   Ops Manager --- enterprise management, monitoring, and backup platform for MongoDB. The Operator can install and manage Ops Manager in Kubernetes for you. Ops Manager can manage MongoDB instances both inside and outside Kubernetes. Installing Ops Manager is covered in the [second article](https://www.mongodb.com/developer/products/connectors/mastering-ops-manager) of the series.\n\n-   MongoMulti --- Multi-Kubernetes-cluster deployments allow you to add MongoDB instances in global clusters that span multiple geographic regions for increased availability and global distribution of data. This is covered in the [final part](https://www.mongodb.com/developer/products/connectors/deploying-across-multiple-kubernetes-clusters) of this series.\n\nWant to see the MongoDB Enterprise Kubernetes Operator in action and discover all the benefits it can bring to your Kubernetes deployment? Continue reading the [next blog](https://www.mongodb.com/developer/products/connectors/mastering-ops-manager) of this series and we'll show you how to best utilize the Operator for your needs","slug":"/deploying-kubernetes-operator","description":"Learn how to deploy the MongoDB Enterprise Kubernetes Operator in this tutorial.","name":"*Deploying the MongoDB Enterprise Kubernetes Operator on Google Cloud","SEO":null,"related_content":[],"primary_tag":[{"__component":"primary-tag-info.l1-product","id":"63b80258ebdd6d001c0b9b40"}],"other_tags":[{"__component":"other-tag-info.other-tag-info","id":"63b80292ebdd6d001c0b9b44"}],"createdAt":"2023-01-06T11:13:26.973Z","updatedAt":"2023-01-13T15:10:37.814Z","__v":1,"image":{"_id":"63b7ffea2fb860001caa7535","name":"*Technical_CONTENT_Network_Spot_BS_Mist.png","alternativeText":"","caption":"","hash":"Technical_CONTENT_Network_Spot_BS_Mist_2f4642a987","ext":".png","mime":"image/png","size":55.44,"width":1392,"height":936,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/Technical_CONTENT_Network_Spot_BS_Mist_2f4642a987.png","formats":{"thumbnail":{"name":"*thumbnail_Technical_CONTENT_Network_Spot_BS_Mist.png","hash":"thumbnail_Technical_CONTENT_Network_Spot_BS_Mist_2f4642a987","ext":".png","mime":"image/png","width":232,"height":156,"size":18.08,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/thumbnail_Technical_CONTENT_Network_Spot_BS_Mist_2f4642a987.png"},"large":{"name":"*large_Technical_CONTENT_Network_Spot_BS_Mist.png","hash":"large_Technical_CONTENT_Network_Spot_BS_Mist_2f4642a987","ext":".png","mime":"image/png","width":1000,"height":672,"size":99.27,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/large_Technical_CONTENT_Network_Spot_BS_Mist_2f4642a987.png"},"medium":{"name":"*medium_Technical_CONTENT_Network_Spot_BS_Mist.png","hash":"medium_Technical_CONTENT_Network_Spot_BS_Mist_2f4642a987","ext":".png","mime":"image/png","width":750,"height":504,"size":68.92,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/medium_Technical_CONTENT_Network_Spot_BS_Mist_2f4642a987.png"},"small":{"name":"*small_Technical_CONTENT_Network_Spot_BS_Mist.png","hash":"small_Technical_CONTENT_Network_Spot_BS_Mist_2f4642a987","ext":".png","mime":"image/png","width":500,"height":336,"size":42.34,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/small_Technical_CONTENT_Network_Spot_BS_Mist_2f4642a987.png"}},"provider":"aws-s3","related":["63b80256ebdd6d001c0b9b3f"],"createdAt":"2023-01-06T11:03:06.914Z","updatedAt":"2023-01-06T11:13:29.957Z","__v":0,"id":"63b7ffea2fb860001caa7535"},"calculated_slug":"/products/connectors/deploying-kubernetes-operator","expiry_date":"2024-01-06T11:13:26.973Z","id":"63b80256ebdd6d001c0b9b3f"},"id":"63b80ded2fb860001caa7547"},{"__component":"article-info.strapi-new-article","_id":"63b80ded2fb860001caa7548","__v":0,"new_article":{"awaiting_editorial_review":false,"awaiting_technical_review":false,"editorial_review_LGTM":false,"technical_review_LGTM":false,"authors":["63b7ff622fb860001caa7533"],"_id":"63b80734ebdd6d001c0b9b53","published_at":"2023-01-13T15:10:33.296Z","content":"This article is part of a three-parts series on deploying MongoDB across multiple Kubernetes clusters using the operators.\n\n-   [Deploying the MongoDB Enterprise Kubernetes Operator on Google Cloud](https://www.mongodb.com/developer/products/connectors/deploying-kubernetes-operator)\n\n-   Mastering MongoDB Ops Manager\n\n-   [Deploying MongoDB Across Multiple Kubernetes Clusters With MongoDBMulti](https://www.mongodb.com/developer/products/connectors/deploying-across-multiple-kubernetes-clusters)\n\nManaging MongoDB deployments can be a rigorous task, particularly when working with large numbers of databases and servers. Without the right tools and processes in place, it can be time-consuming to ensure that these deployments are running smoothly and efficiently. One significant issue in managing MongoDB clusters at scale is the lack of automation, which can lead to time-consuming and error-prone tasks such as backups, recovery, and upgrades. These tasks are crucial for maintaining the availability and performance of your clusters.\n\nAdditionally, monitoring and alerting can be a challenge, as it may be difficult to identify and resolve issues with your deployments. To address these problems, it's essential to use software that offers monitoring and alerting capabilities. Optimizing the performance of your deployments also requires guidance and support from the right sources.\n\nFinally, it's critical for your deployments to be secure and compliant with industry standards. To achieve this, you need features that can help you determine if your deployments meet these standards.\n\n[MongoDB Ops Manager](https://www.mongodb.com/products/ops-manager) is a web-based application designed to assist with the management and monitoring of MongoDB deployments. It offers a range of features that make it easier to deploy, manage, and monitor MongoDB databases, such as:\n\n-   [Automated backups and recovery](https://www.mongodb.com/docs/ops-manager/current/application/#backup): Ops Manager can take automated backups of your MongoDB deployments and provide options for recovery in case of failure.\n\n-   [Monitoring and alerting](https://www.mongodb.com/docs/ops-manager/current/application/#monitoring): Ops Manager provides monitoring and alerting capabilities to help identify and resolve issues with your MongoDB deployments.\n\n-   [Performance optimization](https://www.mongodb.com/docs/ops-manager/current/tutorial/performance-advisor/): Ops Manager offers tools and recommendations to optimize the performance of your MongoDB deployments.\n\n-   [Upgrade management](https://www.mongodb.com/docs/ops-manager/current/tutorial/change-mongodb-version/): Ops Manager can help you manage and plan upgrades to your MongoDB deployments, including rolling upgrades and backups to ensure data availability during the upgrade process.\n\n-   [Security and compliance](https://www.mongodb.com/docs/ops-manager/current/tutorial/nav/security/): Ops Manager provides features to help you secure your MongoDB deployments and meet compliance requirements.\n\nHowever, managing Ops Manager can be a challenging task that requires a thorough understanding of its inner workings and how it interacts with the internal MongoDB databases. It is necessary to have the knowledge and expertise to perform upgrades, monitor it, audit it, and ensure its security. As Ops Manager is a crucial part of managing the operation of your MongoDB databases, its proper management is essential.\n\nFortunately, the MongoDB Enterprise Kubernetes Operator enables us to run Ops Manager on Kubernetes clusters, using native Kubernetes capabilities to manage Ops Manager for us, which makes it more convenient and efficient.\n\n## Kubernetes: MongoDBOpsManager custom resource\n\nThe [MongoDB Enterprise Kubernetes Operator](https://www.mongodb.com/docs/kubernetes-operator/master/) is software that can be used to deploy Ops Manager and MongoDB resources to a Kubernetes cluster, and it's responsible for managing the lifecycle of each of these deployments. It has been developed based on years of experience and expertise, and it's equipped with the necessary knowledge to properly install, upgrade, monitor, manage, and secure MongoDB objects on Kubernetes.\n\nThe Kubernetes Operator uses the [MongoDBOpsManager custom resource](https://github.com/mongodb/mongodb-enterprise-kubernetes/tree/master/samples/ops-manager) to manage Ops Manager objects. It constantly monitors the specification of the custom resource for any changes and, when changes are detected, the operator validates them and makes the necessary updates to the resources in the Kubernetes cluster.\n\nMongoDBOpsManager custom resources specification defines the following Ops Manager components:\n\n-   The [Application Database](https://www.mongodb.com/docs/kubernetes-operator/master/tutorial/om-arch/#application-database)\n\n-   The [Ops Manager application](https://www.mongodb.com/docs/kubernetes-operator/master/tutorial/om-arch/#application)\n\n-   The [Backup Daemon](https://www.mongodb.com/docs/kubernetes-operator/master/tutorial/om-arch/#backup-daemon)\n\n![MongoDBOpsManager custom resources specification defines the following Ops Manager components:\nthe Application Database,\nthe Ops Manager application, and\nthe Backup Daemon.](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/meko_arch_a94d843eaa.svg)\n\nWhen you use the Kubernetes Operator to create an instance of Ops Manager, the Ops Manager MongoDB Application Database will be deployed as a replica set. It's not possible to configure the Application Database as a standalone database or a sharded cluster.\n\nThe Kubernetes Operator automatically sets up Ops Manager to monitor the Application Database that powers the Ops Manager Application. It creates a project named  `<ops-manager-deployment-name>-db` to allow you to monitor the Application Database deployment. While Ops Manager monitors the Application Database deployment, it does not manage it.\n\nWhen you deploy Ops Manager, you need to configure it. This typically involves using the [configuration wizard](https://www.mongodb.com/docs/ops-manager/current/reference/config/ui-settings/). However, you can bypass the configuration wizard if you set certain essential settings in your object specification before deployment. I will demonstrate that in this post.\n\nThe Operator automatically enables backup. It deploys a StatefulSet, which consists of a single pod, to host the Backup Daemon Service and creates a Persistent Volume Claim and Persistent Volume for the Backup Daemon's head database. The operator uses the Ops Manager API to enable the Backup Daemon and configure the head database.\n\n## Getting started\n\nAlright, let's get started using the operator and build something! For this tutorial, we will need the following tools: \n\n-   [gcloud](https://cloud.google.com/sdk/docs/install)[ ](https://go.dev/dl/)\n\n-   [gke-cloud-auth-plugin](https://cloud.google.com/blog/products/containers-kubernetes/kubectl-auth-changes-in-gke)\n\n-   [Helm](https://helm.sh/docs/intro/install/)\n\n-   [kubectl](https://kubernetes.io/docs/tasks/tools/)\n\n-   [kubectx](https://github.com/ahmetb/kubectx)\n\n-   [git](https://git-scm.com/downloads)\n\nTo get started, we should first create a Kubernetes cluster and then install the MongoDB Kubernetes Operator on the cluster. [Part 1](https://www.mongodb.com/developer/products/connectors/deploying-kubernetes-operator) of this series provides instructions on how to do so.\n\n> **Note**\n> For the sake of simplicity, we are deploying Ops Manager in the same namespace as our MongoDB Operator. In a production environment, you should deploy Ops Manager in its own namespace.\n\n### Environment pre-checks \n\nUpon successful creation of a cluster and installation of the operator (described in [Part 1](https://www.mongodb.com/developer/products/connectors/deploying-kubernetes-operator)), it's essential to validate their readiness for use.\n\n```bash\ngcloud container clusters list\n\nNAME                LOCATION       MASTER_VERSION    NUM_NODES  STATUS\\\nmaster-operator     us-south1-a    1.23.14-gke.1800      4      RUNNING\n```\n\nDisplay our new Kubernetes full cluster name using `[kubectx](https://github.com/ahmetb/kubectx)`.\n\n```bash\nkubectx\n```\n\nYou should see your cluster listed here. Make sure your context is set to master cluster.\n\n```bash\nkubectx $(kubectx | grep \"master-operator\" | awk '{print $1}')\n```\n\nIn order to continue this tutorial, make sure that the operator is in the `running`state.\n\n```bash\nkubectl get po -n \"${NAMESPACE}\"\n\nNAME                                    READY   STATUS   RESTARTS   AGE\\\nmongodb-enterprise-operator-649bbdddf5   1/1    Running   0         7m9s\n```\n\n## Using the MongoDBOpsManager CRD\n\nCreate a secret containing the username and password on the master Kubernetes cluster for accessing the Ops Manager user interface after installation.\n\n```bash\nkubectl -n \"${NAMESPACE}\" create secret generic om-admin-secret \\\n  --from-literal=Username=\"opsmanager@example.com\" \\\n  --from-literal=Password=\"p@ssword123\" \\\n  --from-literal=FirstName=\"Ops\" \\\n  --from-literal=LastName=\"Manager\"\n```\n​​\n### Deploying Ops Manager \n\nThen, we can [deploy Ops Manger on the master Kubernetes](https://github.com/mongodb/mongodb-enterprise-kubernetes/tree/master/samples/ops-manager) cluster with the help of `opsmanagers`  Custom Resource, creating `MongoDBOpsManager` object, using the following manifest:\n\n```bash\nOM_VERSION=6.0.5\nAPPDB_VERSION=5.0.5-ent\nkubectl apply -f - <<EOF\napiVersion: mongodb.com/v1\nkind: MongoDBOpsManager\nmetadata:\n  name: ops-manager\n  namespace: \"${NAMESPACE}\"\nspec:\n  version: \"${OM_VERSION}\"\n  # the name of the secret containing admin user credentials.\n  adminCredentials: om-admin-secret\n  externalConnectivity:\n    type: LoadBalancer\n  configuration:\n    mms.ignoreInitialUiSetup: \"true\"\n    automation.versions.source: mongodb\n    mms.adminEmailAddr: support@example.com\n    mms.fromEmailAddr: support@example.com\n    mms.replyToEmailAddr: support@example.com\n    mms.mail.hostname: example.com\n    mms.mail.port: \"465\"\n    mms.mail.ssl: \"false\"\n    mms.mail.transport: smtp\n  # the Replica Set backing Ops Manager.\n  applicationDatabase:\n    members: 3\n    version: \"${APPDB_VERSION}\"\nEOF\n```\n \n After a few minutes, we should see our Ops Manager and Ops Manager MongoDB application database pods running.\n\n```​​bash\nkubectl -n \"${NAMESPACE}\" get pods\n\nNAME                                       READY      STATUS     RESTARTS\nops-manager-0                           1/1      Running      0\nops-manager-db-0                        3/3      Running      0\nops-manager-db-1                        3/3      Running      0\nops-manager-db-2                        3/3      Running      0\n```\n\nStorage part creation has been orchestrated by the operator. [Persistent Volumes Claims ](https://kubernetes.io/docs/concepts/storage/persistent-volumes/) are created and can be displayed via\n\n```bash\nkubectl -n \"${NAMESPACE}\" get pvc\n\nNAME       STATUS   VOLUME     CAPACITY  ACCESS MODES   STORAGE CLASS   AGE\ndata-ops-manager-db-0 Bound pvc-d5a1b385-6d1b  15Gi  RWO  standard  59m\ndata-ops-manager-db-1 Bound pvc-db0e89dc-d73a  15Gi  RWO  standard  58m\ndata-ops-manager-db-2 Bound pvc-c7e124a2-917   15Gi  RWO  standard  57m\n```\n\n[Kubernetes StatefulSets](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/) has also been created by the Operator.\n\n```bash\nkubectl -n \"${NAMESPACE}\" get sts\n\nNAME             READY   AGE\nops-manager      1/1     29m31s\nops-manager-db   3/3     30m29s\n```\n\nThe operator has created all required network services, including a Load Balancer service type for the Ops manager access, so we now have an external IP address and can log into the Ops Manager from outside the Kubernetes cluster. You can verify IPs by viewing the services.\n\n```bash\nkubectl -n \"${NAMESPACE}\" get svc\n\nNAME                  TYPE    CLUSTER-IP    EXTERNAL-IP  PORT(S)\nops-manager-db-svc  ClusterIP    None        <none>      27017/TCP\nops-manager-svc     ClusterIP    None        <none       8080/TCP,25999/TCP\nops-manager-svc-ext LoadBalancer 10.76.10.231 34.174.54.103 8080:32078/TCP ,25999:31961/TCP    \n```\n\nThe following diagram describes how the Kubernetes Operator reconciles changes to the  MongoDBOpsManager CustomResourceDefinition.\n\n![The following diagram describes how the Kubernetes Operator reconciles changes to the MongoDBOpsManager CustomResourceDefinition](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/Ops_Manager_objects_5e8862d468.png)\n\nTo generate Ops Manager URL address, execute:\n\n```bash\nURL=http://$(kubectl -n \"${NAMESPACE}\" get svc ops-manager-svc-ext -o jsonpath='{.status.loadBalancer.ingress[0].ip}:{.spec.ports[0].port}')\necho $URL\n```\n\nThe URL address will look similar to the example provided, but IP address may vary depending on the Kubernetes cluster.\n\n```bash\nhttp://34.174.54.105:8080\n```\n\nThe final step is to update the Ops Manager Kubernetes manifest to include an external IP address created by Load Balancer in `spec.configuration.mms.centralUrl`  via `kubectl patch`.\n\n```bash\nkubectl -n \"${NAMESPACE}\" patch om ops-manager --type=merge -p \"{\\\"spec\\\":{\\\"configuration\\\":{\\\"mms.centralUrl\\\":\\\"${URL}\\\"}}}\"\n```\n\nWe should wait a few minutes. The Ops Manager pod must be restarted, so wait until the `ops-manager-0` pod is in the `running` state again.\n\nUsing the username and password stored in the `om-admin-secret` (opsmanager@example.com : p@ssword123), we can log in to the Ops Manager User Interface using the address in the `$URL` variable.\n\n![Enter your username and password and click Login](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/Ops_Manager_c44549fd1e.png)\n\nThe Kubernetes Operator was in the Ops Manager `ops-manager-db` organization and the `ops-manager-db` project.\n\n![Select Ops Manager organization](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/Ops_Manager_UI_834b2820aa.png)\n\nIf we click on the project `ops-manager-db`, we will be redirected to the panel where we can see the database pods of the Ops Manager application. Ops Manager monitors this database.\n\n![Manage your MongoDB cluster from Ops Manager](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/Ops_Manager_App_DB_5f3ae3ae3e.png)\n\n## Basic troubleshooting\n\nIf you run through issues during the installation, here are some clues to help you investigate what went wrong.\n\nIf you want to display an Ops Manager cluster, use this command. It will show you a general overview of `om` objects, including internal database and Backup Daemon state.\n\n```bash\nkubectl -n \"${NAMESPACE}\" get om\n\nNAME REPLICAS VERSION STATE(OPSMANAGER) STATE(APPDB) STATE (BACKUP)   AGE\nops-manager     6.0.5     Running        Running     Pending          18m  \n```\n \n\nYou can use `describe` to get a detailed overview.\n\n```bash\nkubectl -n \"${NAMESPACE}\" describe om ops-manager\n```\n\nIt's always a good idea to check the Ops Manager logs\n\n```bash\nkubectl -n \"${NAMESPACE}\" logs -f po/ops-manager-0\n```\n\nor current `events` from the namespace.\n\n```bash\nkubectl -n \"${NAMESPACE}\" get events\n```\n\n## Summary\n\nWe have just installed Ops Manager on our Kubernetes cluster. This gives us many benefits. The operator has properly installed and configured the Ops Manager instance with the internal database, took care of the storage portion, and created network services, including a Load Balancer. We can now use Ops Manager and easily create any kind of MongoDB database on the Kubernetes cluster following the best practices, monitor instances of our databases, introduce query optimizations with the help of the Ops Manager performance advisor, and provide backup, restore, or rolling upgrades through automation.\n\nIn the [next part](https://www.mongodb.com/developer/products/connectors/deploying-across-multiple-kubernetes-clusters), I will demonstrate how to run the latest type of MongoDB Kubernetes Custom Resource, a Multi Cluster Replica Set. This replica set will be deployed across three separate Kubernetes clusters located in different regions, providing the ideal solution for critical applications that require continuous availability, even in the event of a Kubernetes cluster failure.\nWant to get started with the MongoDB Ops Manager on your own Kubernetes cluster? [Install  it now](https://github.com/mongodb/helm-charts/tree/main/charts/enterprise-operator) and see for yourself how it can simplify your operations. Make sure to visit the [MongoDB community forum](https://www.mongodb.com/community/forums/) for the latest discussions and resources","slug":"/mastering-ops-manager","description":"Learn how to deploy the MongoDB Ops Manager in a Kubernetes cluster with the MongoDB Kubernetes Operators.","name":"*Mastering MongoDB Ops Manager on Kubernetes","SEO":null,"related_content":[],"primary_tag":[{"__component":"primary-tag-info.l1-product","id":"63b80734ebdd6d001c0b9b54"}],"other_tags":[{"__component":"other-tag-info.other-tag-info","id":"63b80734ebdd6d001c0b9b56"}],"createdAt":"2023-01-06T11:34:12.826Z","updatedAt":"2023-01-13T15:10:33.374Z","__v":2,"image":{"_id":"63b804e8ebdd6d001c0b9b52","name":"*Technical_CONTENT_Network_Spot_BS_Lavender.png","alternativeText":"","caption":"","hash":"Technical_CONTENT_Network_Spot_BS_Lavender_1de0caf18c","ext":".png","mime":"image/png","size":55.38,"width":1392,"height":936,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/Technical_CONTENT_Network_Spot_BS_Lavender_1de0caf18c.png","formats":{"thumbnail":{"name":"*thumbnail_Technical_CONTENT_Network_Spot_BS_Lavender.png","hash":"thumbnail_Technical_CONTENT_Network_Spot_BS_Lavender_1de0caf18c","ext":".png","mime":"image/png","width":232,"height":156,"size":17.8,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/thumbnail_Technical_CONTENT_Network_Spot_BS_Lavender_1de0caf18c.png"},"large":{"name":"*large_Technical_CONTENT_Network_Spot_BS_Lavender.png","hash":"large_Technical_CONTENT_Network_Spot_BS_Lavender_1de0caf18c","ext":".png","mime":"image/png","width":1000,"height":672,"size":97.64,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/large_Technical_CONTENT_Network_Spot_BS_Lavender_1de0caf18c.png"},"medium":{"name":"*medium_Technical_CONTENT_Network_Spot_BS_Lavender.png","hash":"medium_Technical_CONTENT_Network_Spot_BS_Lavender_1de0caf18c","ext":".png","mime":"image/png","width":750,"height":504,"size":67.81,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/medium_Technical_CONTENT_Network_Spot_BS_Lavender_1de0caf18c.png"},"small":{"name":"*small_Technical_CONTENT_Network_Spot_BS_Lavender.png","hash":"small_Technical_CONTENT_Network_Spot_BS_Lavender_1de0caf18c","ext":".png","mime":"image/png","width":500,"height":336,"size":41.64,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/small_Technical_CONTENT_Network_Spot_BS_Lavender_1de0caf18c.png"}},"provider":"aws-s3","related":["63b80734ebdd6d001c0b9b53"],"createdAt":"2023-01-06T11:24:24.286Z","updatedAt":"2023-01-06T11:34:12.924Z","__v":0,"id":"63b804e8ebdd6d001c0b9b52"},"calculated_slug":"/products/connectors/mastering-ops-manager","expiry_date":"2024-01-06T11:34:12.826Z","id":"63b80734ebdd6d001c0b9b53"},"id":"63b80ded2fb860001caa7548"},{"__component":"article-info.strapi-new-article","_id":"63b80ded2fb860001caa7549","__v":0,"new_article":{"awaiting_editorial_review":false,"awaiting_technical_review":false,"editorial_review_LGTM":true,"technical_review_LGTM":true,"authors":["63b7ff622fb860001caa7533"],"_id":"63b80c55ebdd6d001c0b9b5a","published_at":"2023-01-13T15:10:26.769Z","content":"This article is part of a three-parts series on deploying MongoDB across multiple Kubernetes clusters using the operators.\n\n-   [Deploying the MongoDB Enterprise Kubernetes Operator on Google Cloud](https://www.mongodb.com/developer/products/connectors/deploying-kubernetes-operator)\n\n-   [Mastering MongoDB Ops Manager](https://www.mongodb.com/developer/products/connectors/mastering-ops-manager)\n\n-   Deploying MongoDB Across Multiple Kubernetes Clusters With MongoDBMulti\n\nWith the latest version of the MongoDB Enterprise Kubernetes Operator, you can deploy MongoDB resources across multiple Kubernetes clusters! By running your MongoDB replica set across different clusters, you can ensure that your deployment remains available even in the event of a failure or outage in one of them. The MongoDB Enterprise Kubernetes Operator's Custom Resource Definition (CRD), [MongoDBMulti](https://www.mongodb.com/docs/kubernetes-operator/master/multi-cluster-arch/), makes it easy to run MongoDB replica sets across different Kubernetes environments and provides a declarative approach to deploying MongoDB, allowing you to specify the desired state of your deployment and letting the operator handle the details of achieving that state.\n\n> ⚠️ Support for multi-Kubernetes-cluster deployments of MongoDB is a beta feature and not yet ready for Production use. The content of this article is meant to provide you with a way to experiment with this upcoming feature, but should not be used in production as breaking changes may still occur. Support for this feature during beta is direct with the engineering team and on a best-efforts basis, so please let us know if trying this out at [kubernetes-product@mongodb.com](mailto:kubernetes-product@mongodb.com). Also feel free to get in touch with any questions, or if this is something that may be of interest once fully released.\n\n\n## Overview of MongoDBMulti CRD\n\nDeveloped by MongoDB, [MongoDBMulti](https://github.com/mongodb/mongodb-enterprise-kubernetes/tree/master/samples/mongodb_multi) Custom Resource allows for the customization of resilience levels based on the needs of the enterprise application.\n\n-   Single region (Multi A-Z) consists of one or more Kubernetes clusters where each cluster has nodes deployed in different availability zones in the same region. This type of deployment protects MongoDB instances backing your enterprise applications against zone and Kubernetes cluster failures.\n\n-   Multi Region consists of one or more Kubernetes clusters where you deploy each cluster in a different region, and within each region, deploy cluster nodes in different availability zones. This gives your database resilience against the loss of a Kubernetes cluster, a zone, or an entire cloud region.\n\nBy leveraging the native capabilities of Kubernetes, the MongoDB Enterprise Kubernetes Operator performs the following tasks to deploy and operate a multi-cluster MongoDB replica set:\n\n-   Creates the necessary resources, such as Configmaps, secrets, service objects, and StatefulSet objects, in each member cluster. These resources are in line with the number of replica set members in the MongoDB cluster, ensuring that the cluster is properly configured and able to function.\n\n-   Identifies the clusters where the MongoDB replica set should be deployed using the corresponding MongoDBMulti Custom Resource spec. It then deploys the replica set on the identified clusters.\n\n-   Watches for the creation of the MongoDBMulti Custom Resource spec in the central cluster.\n\n-   Uses a mounted kubeconfig file to communicate with member clusters. This allows the operator to access the necessary information and resources on the member clusters in order to properly manage and configure the MongoDB cluster.\n\n-   Watches for events related to the CentralCluster and MemberCluster in order to confirm that the multi-Kubernetes-cluster deployment is in the desired state.\n\nYou should start by constructing a central cluster. This central cluster will host the Kubernetes Operator, MongoDBMulti Custom Resource spec, and act as the control plane for the multi-cluster deployment. If you deploy Ops Manager with the Kubernetes Operator, the central cluster may also host Ops Manager.\n\n![A high-level architecture of a multi-Kubernetes-cluster deployment across regions and availability zones](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/Multi_Cluster_62dcb284a4.png)\n\nYou will also need a service mesh. I will be using [Istio](https://istio.io/), but any service mesh that provides a [fully qualified domain name](https://en.wikipedia.org/wiki/Fully_qualified_domain_name) resolution between pods across clusters should work.\n\nCommunication between replica set members happens via the service mesh, which means that your MongoDB replica set doesn't need the central cluster to function. Keep in mind that if the central cluster goes down, you won't be able to use the Kubernetes Operator to modify your deployment until you regain access to this cluster.  \n\n## Using the MongoDBMulti CRD\n\nAlright, let's get started using the operator and build something! For this tutorial, we will need the following tools: \n\n-   [gcloud](https://cloud.google.com/sdk/docs/install)[ ](https://go.dev/dl/)\n\n-   [gke-cloud-auth-plugin](https://cloud.google.com/blog/products/containers-kubernetes/kubectl-auth-changes-in-gke)\n\n-   [Go](https://go.dev/dl/)  v1.17 or later\n\n-   [Helm](https://helm.sh/docs/intro/install/)\n\n-   [kubectl](https://kubernetes.io/docs/tasks/tools/)\n\n-   [kubectx](https://github.com/ahmetb/kubectx)\n\n-   [Git](https://git-scm.com/downloads).\n\nWe need to set up a master Kubernetes cluster to host the MongoDB Enterprise Multi-Cluster Kubernetes Operator and the Ops Manager. You will need to create a [GKE Kubernetes cluster by following](https://cloud.google.com/kubernetes-engine) the instructions in [Part 1](https://www.mongodb.com/developer/products/connectors/deploying-kubernetes-operator) of this series. Then, we should install the MongoDB Multi-Cluster Kubernetes Operator  in the `mongodb` namespace, along with the necessary CRDs. This will allow us to utilize the operator to effectively manage and operate our MongoDB multi cluster replica set. For instructions on how to do this, please refer to the relevant section of Part 1. Additionally, we will need to install the Ops Manager, as outlined in [Part 2](https://www.mongodb.com/developer/products/connectors/mastering-ops-manager) of this series.\n\n### Creating the clusters\n\nAfter master cluster creation and configuration, we need three additional GKE clusters, distributed across three different regions: `us-west2`, `us-central1`, and `us-east1`. Those clusters will host MongoDB replica set members. \n\n```bash\nCLUSTER_NAMES=(mdb-cluster-1 mdb-cluster-2 mdb-cluster-3)\nZONES=(us-west2-a us-central1-a us-east1-b)\n\nfor ((i=0; i<${#CLUSTER_NAMES[@]:0:1}; i++)); do\n  gcloud container clusters create \"${CLUSTER_NAMES[$i]}\" \\\n    --zone \"${ZONES[$i]}\" \\\n    --machine-type n2-standard-2 --cluster-version=\"${K8S_VERSION}\" \\\n    --disk-type=pd-standard --num-nodes 1\ndone\n```\n\nThe clusters have been created, and we need to obtain the credentials for them.\n\n```bash\nfor ((i=0; i<${#CLUSTER_NAMES[@]:0:1}; i++)); do\n  gcloud container clusters get-credentials \"${CLUSTER_NAMES[$i]}\" \\\n    --zone \"${ZONES[$i]}\"\ndone\n```\n\nAfter successfully creating the Kubernetes master and MongoDB replica set clusters, installing the Ops Manager and all required software on it, we can check them using `[kubectx](https://github.com/ahmetb/kubectx)`.\n\n```bash\nkubectx\n```\n\nYou should see all your Kubernetes clusters listed here. Make sure that you only have the clusters you just created and remove any other unnecessary clusters using `kubectx -d <cluster_name>` for the next script to work.\n\n```bash\ngke_lustrous-spirit-371620_us-central1-a_mdb-cluster-2\ngke_lustrous-spirit-371620_us-east1-b_mdb-cluster-3\ngke_lustrous-spirit-371620_us-south1-a_master-operator\ngke_lustrous-spirit-371620_us-west2-a_mdb-cluster-1\n```\n\nWe need to create the required variables: `MASTER` for a master Kubernetes cluster, and `MDB_1`, `MDB_2`, and `MDB_3` for clusters which will host MongoDB replica set members. Important note: These variables should contain the full Kubernetes cluster names.\n\n```bash\nKUBECTX_OUTPUT=($(kubectx))\nCLUSTER_NUMBER=0\nfor context in  \"${KUBECTX_OUTPUT[@]}\"; do\n if [[ $context == *\"master\"* ]]; then\n    MASTER=\"$context\"\n else\n    CLUSTER_NUMBER=$((CLUSTER_NUMBER+1))\n    eval  \"MDB_$CLUSTER_NUMBER=$context\"\n fi\ndone\n```\n\nYour clusters are now configured and ready to host the MongoDB Kubernetes Operator.\n\n### Installing Istio\n\nInstall [Istio](https://istio.io/) (I'm using v 1.16.1) in a [multi-primary mode on different networks](https://istio.io/latest/docs/setup/install/multicluster/multi-primary_multi-network/), using the [install_istio_separate_network](https://github.com/mongodb/mongodb-enterprise-kubernetes/blob/master/tools/multicluster/install_istio_separate_network.sh) script. To learn more about it, see the [Multicluster Istio](https://istio.io/latest/docs/setup/install/multicluster/) documentation. I have prepared a code that downloads and updates `install_istio_separate_network.sh` script variables to currently required ones, such as full K8s cluster names and the version of Istio.\n\n```bash\nREPO_URL=\"https://github.com/mongodb/mongodb-enterprise-kubernetes.git\"\nSUBDIR_PATH=\"mongodb-enterprise-kubernetes/tools/multicluster\"\nSCRIPT_NAME=\"install_istio_separate_network.sh\"\nISTIO_VERSION=\"1.16.1\"\ngit clone \"$REPO_URL\"\nfor ((i = 1; i <= ${#CLUSTER_NAMES[@]}; i++)); do\n  eval mdb=\"\\$MDB_${i}\"\n  eval k8s=\"CTX_CLUSTER${i}\"\n  sed -i'' -e \"s/export ${k8s}=.*/export CTX_CLUSTER${i}=${mdb}/\"  \"$SUBDIR_PATH/$SCRIPT_NAME\"\ndone\nsed -i'' -e \"s/export VERSION=.*/export VERSION=${ISTIO_VERSION}/\"  \"$SUBDIR_PATH/$SCRIPT_NAME\"\n```\n\nInstall Istio in a multi-primary mode on different Kubernetes clusters via the following command.\n\n```bash\nyes | \"$SUBDIR_PATH/$SCRIPT_NAME\"\n```\n\nExecute the[ multi-cluster kubeconfig creator tool](https://www.mongodb.com/docs/kubernetes-operator/master/multi-cluster-quick-start-procedure/#id2). By default, the Kubernetes Operator is scoped to the `mongodb` namespace, although it can be installed in a different namespace as well. Navigate to the directory where you cloned the Kubernetes Operator repository in an earlier step, and run the tool. Got to [Multi-Cluster CLI](https://www.mongodb.com/docs/kubernetes-operator/master/multi-cluster-cli-reference/#multi-cluster-cli-reference-ref) documentation to lean more about `multi cluster cli`.\n\n```bash\nCLUSTERS=$MDB_1,$MDB_2,$MDB_3\ncd  \"$SUBDIR_PATH\"\ngo run main.go setup \\\n  -central-cluster=\"${MASTER}\" \\\n  -member-clusters=\"${CLUSTERS}\" \\\n  -member-cluster-namespace=\"mongodb\" \\\n  -central-cluster-namespace=\"mongodb\"\n```\n### Verifying cluster configurations\n\nLet's check the configurations we have made so far. I will switch the context to cluster #2.\n\n```bash\nkubectx $MDB_2\n```\n\nYou should see something like this in your terminal.\n\n```bash\nSwitched to context \"gke_lustrous-spirit-371620_us-central1-a_mdb-cluster-2\"\n```\n\nWe can see `istio-system` and `mongodb` namespaces created by the scripts\n\n```bash\nkubectl get ns\n\nNAME              STATUS   AGE\ndefault           Active   62m\nistio-system      Active   7m45s\nkube-node-lease   Active   62m\nkube-public       Active   62m\nkube-system       Active   62m\nmongodb           Active   41s\n```\n\nand the MongoDB Kubernetes operator service account is ready.\n\n```bash\nkubectl -n mongodb get sa\n\ndefault                                     1         55s\nmongodb-enterprise-operator-multi-cluster   1         52s\n```\n\nNext, execute the following command on the clusters, specifying the context for each of the member clusters in the deployment. The command adds the label `istio-injection=enabled`' to the`'mongodb` namespace on each member cluster. This label [activates Istio's injection webhook](https://istio.io/latest/docs/setup/additional-setup/sidecar-injection/#automatic-sidecar-injection), which allows a sidecar to be added to any pods created in this namespace.\n\n```bash\nCLUSTER_ARRAY=($MDB_1 $MDB_2 $MDB_3)\nfor CLUSTER in \"${CLUSTER_ARRAY[@]}\"; do     \n  kubectl label --context=$CLUSTER namespace mongodb istio-injection=enabled\ndone\n```\n\n### Installing the MongoDB multi cluster Kubernetes operator\n\nNow the MongoDB Multi Cluster Kubernetes operator must be installed on the master-operator cluster and be aware of the all Kubernetes clusters which are part of the Multi Cluster. This step will add the multi cluster Kubernetes operator to each of our clusters. \n\nFirst, switch context to the master cluster.\n\n```bash\nkubectx $MASTER\n```\n\nThe `mongodb-operator-multi-cluster` operator needs to be made aware of the newly created Kubernetes clusters by updating the operator config through Helm. This procedure was tested with `mongodb-operator-multi-cluster` version `1.16.3`.\n\n```bash\nhelm upgrade --install mongodb-enterprise-operator-multi-cluster mongodb/enterprise-operator \\\n  --namespace mongodb \\\n  --set namespace=mongodb \\\n  --version=\"${HELM_CHART_VERSION}\" \\\n  --set operator.name=mongodb-enterprise-operator-multi-cluster \\\n  --set \"multiCluster.clusters={${CLUSTERS}}\" \\\n  --set operator.createOperatorServiceAccount=false \\\n  --set multiCluster.performFailover=false\n```\n\nCheck if the MongoDB Enterprise Operator multi cluster pod on the master cluster is running.\n\n```bash\nkubectl -n mongodb get pods\n```\n\n```bash\nNAME                                                   READY STATUS    RESTARTS   AGE\nmongodb-enterprise-operator-multi-cluster-688d48dfc6    1/1  Running 0  8s\n```\n\nIt's now time to link all those clusters together using the MongoDB Multi CRD. The Kubernetes API has already been extended with a MongoDB-specific object - `mongodbmulti`.\n\n```bash\nkubectl -n mongodb get crd | grep multi\n```\n\n```bash\nmongodbmulti.mongodb.com                         \n```\n\nYou should also review after the installation logs and ensure that there are no issues or errors.\n\n```bash\nPOD=$(kubectl -n mongodb get po|grep operator|awk '{ print $1 }')\nkubectl -n mongodb logs -f po/$POD\n```\n\nWe are almost ready to create a multi cluster MongoDB Kubernetes replica set! We need to configure the required service accounts for each member cluster.\n\n```bash\nfor CLUSTER in \"${CLUSTER_ARRAY[@]}\"; do\n  helm template --show-only templates/database-roles.yaml mongodb/enterprise-operator --namespace \"mongodb\" | kubectl apply -f - --context=${CLUSTER} --namespace mongodb; \ndone\n```\n\nAlso, let's generate Ops Manager API keys and add our IP addresses to the Ops Manager access list. Get the Ops Manager (created as described in [Part 2](https://www.mongodb.com/developer/products/connectors/mastering-ops-manager)) URL.  Make sure you switch the context to master. \n\n```bash\nkubectx $MASTER\nURL=http://$(kubectl -n \"${NAMESPACE}\" get svc ops-manager-svc-ext -o jsonpath='{.status.loadBalancer.ingress[0].ip}:{.spec.ports[0].port}')\necho $URL\n```\nLog in to Ops Manager, and generate public and private API keys. When you create API keys, don't forget to add your current IP address to API Access List.\n\nTo do so, log in to the Ops Manager and go to `ops-manager-db` organization.\n\n![Ops Manager provides a organizations and projects hierarchy to help you manage your Ops Manager deployments. In the organizations and projects hierarchy, an organization can contain many projects](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/Organization_91086b9d3b.png)\n\nClick `Access Manager` on the left-hand side, and choose Organization Access then choose `Create API KEY`  in the top right corner.\n\n![Create a Public Key and a Private Key.](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/Access_Manager_559c2c6342.png)\n\nThe key must have a name (I use `mongodb-blog`) and permissions must be set to `Organization Owner` .\n\n![Set Organization Owner rights](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/API_Key_9e0ab38dc4.png)\n\nWhen you click Next, you will see your `Public Key`and `Private Key`. Copy those values and save them --- you will not be able to see the private key again. Also, make sure you added your current IP address to the API access list.\n\n![To grant programmatic access to an organization or project using only the API, you can create an API keys pair](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/Keys_d9747578c4.png)\n\nGet the public and private keys generated by the API key creator and paste them into the Kubernetes secret.\n\n```bash\nkubectl apply -f - <<EOF\napiVersion: v1\nkind: Secret\nmetadata:\n  name: multi-organization-secret\n  namespace: mongodb\nstringData:\n  publicKey: <PUBLIC KEY>\n  privateKey: <PRIVATE_KEY>\nEOF\n```\n\nYou also need an  `Organization ID`. You can see the organization ID by clicking on the gear icon in the top left corner.\n\n![Get the organization ID](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/ORG_ID_bc6abe8531.png)\n\nCopy the `Organization ID` and paste to the Kubernetes config map below.\n\n```bash\nkubectl apply -f - <<EOF\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: multi-project\n  namespace: mongodb\ndata:\n  baseUrl: \"${URL}\"\n  orgId: <YOUR_ORG_ID>\nEOF\n```\n\nThe Ops Manager instance has been configured, and you have everything needed to add the MongoDBMultiCRD to your cluster.\n\n### Using the MongoDBMultiCRD\n\nFinally, we can create a MongoDB replica set that is distributed across three Kubernetes clusters in different regions. I have updated the Kubernetes manifest with the full names of the Kubernetes clusters. Let's apply it now!\n\n```bash\nMDB_VERSION=6.0.2-ent\nkubectl apply -f - <<EOF\napiVersion: mongodb.com/v1\nkind: MongoDBMulti\nmetadata:\n   name: multi-replica-set\n   namespace: mongodb\nspec:\n   version: \"${MDB_VERSION}\" \n   type: ReplicaSet\n   persistent: true \n   duplicateServiceObjects: true \n   credentials: multi-organization-secret \n   opsManager:\n     configMapRef:\n       name: multi-project \n   clusterSpecList:\n     clusterSpecs:\n     - clusterName: ${MDB_1} \n       members: 1\n     - clusterName: ${MDB_2}\n       members: 1\n     - clusterName: ${MDB_3}    \n       members: 1\nEOF\n```\n\nWe should check the operator pod logs. There is a possibility we will have to update Ops Manager API access list by additional IP address. Create a variable with the operator pod.\n\n```bash\nPOD=$(kubectl -n mongodb get po|grep operator|awk '{ print $1 }')\n```\n\nCheck if the operator pod is allowed to access Ops Manager REST API.\n\n```bash\nkubectl -n mongodb logs -f po/$POD|grep IP_ADDRESS_NOT_ON_ACCESS_LIST\n```\n\nIf we receive an error output similar to the following, we should add the displayed, additional IP address to the Ops Manager API access list, as we did in the previous step.\n\n`Status: 403 (Forbidden), ErrorCode: IP_ADDRESS_NOT_ON_ACCESS_LIST, Detail: IP address 10.206.15.226 is not allowed to access this resource.\",\"MultiReplicaSet\":\"mongodb/multi-cluster\"`\n\nAfter a few minutes, we should have our multi cluster ready for use! We can verify this by displaying the 'mongodb multi' object.\n\n```bash\nkubectl -n mongodb get mdbm\n```\n\n```bash\nNAME            PHASE     AGE\nmulti-cluster   Running   4m25s\n```\n\nWe can check that MongoDB replica set is running across different Kubernetes environments in different regions! The operator has performed all necessary configurations and changes to achieve the desired state of the multi cluster. The operator will also monitor our multi cluster and respond in case of any issues.\n\n```bash\nfor CLUSTER in \"${CLUSTER_ARRAY[@]}\"; do\n  kubectl -n mongodb --context=${CLUSTER}  get pods\ndone\n```\n\nOutput of the loop:\n\n```bash\ngke_lustrous-spirit-371620_us-central1-a_mdb-cluster-2\nNAME                READY   STATUS    RESTARTS      AGE\nmulti-cluster-0-0   2/2     Running   1 (13m ago)   13m\n\ngke_lustrous-spirit-371620_us-east1-b_mdb-cluster-3\nNAME                READY   STATUS    RESTARTS      AGE\nmulti-cluster-1-0   2/2     Running   1 (12m ago)   12m\n\ngke_lustrous-spirit-371620_us-west2-a_mdb-cluster-1\nNAME                READY   STATUS    RESTARTS      AGE\nmulti-cluster-2-0   2/2     Running   1 (12m ago)   12m\n```\n\nWe can also see that the MongoDB Kubernetes Operator has handled the storage part and created a StatefulSet and associated objects.\n\n```bash\nfor CLUSTER in \"${CLUSTER_ARRAY[@]}\"; do\n  kubectl -n mongodb --context=${CLUSTER}  get sts\ndone\n```\n\nOutput of the loop:\n\n```bash\ngke_lustrous-spirit-371620_us-central1-a_mdb-cluster-2\nNAME              READY   AGE\nmulti-cluster-0   1/1     16m\n\ngke_lustrous-spirit-371620_us-east1-b_mdb-cluster-3\nNAME              READY   AGE\nmulti-cluster-1   1/1     15m\n\ngke_lustrous-spirit-371620_us-west2-a_mdb-cluster-1\nNAME              READY   AGE\nmulti-cluster-2   1/1     15m\n```\n\nThe multi cluster replica set is also visible in the Ops Manager. The Ops Manager will now be responsible for backup, alerting, monitoring, rolling upgrades, and automation.\n\n![Ops Manager Multi-Kubernetes-Cluster Deployment view in Ops Manager ](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/Multi_Deployment_18fbb20e8e.png)\n\n## Basic troubleshooting\n\nIf something goes wrong, you can start an investigation by checking the MongoDB Kubernetes Operator logs on the master cluster. The most common problem is not including IP addresses in [the list of IP addresses for the API key](https://www.mongodb.com/docs/ops-manager/current/tutorial/manage-programmatic-api-keys/). You can see the error details by finding the name of the operator pod and listing the latest logs.\n\n```bash\nPOD=$(kubectl -n mongodb get po|grep operator-multi|awk '{ print $1 }') \nkubectl -n mongodb logs -f po/$POD\n```\nYou can use the kubectl command to view the logs of the database pods. The main container processes continually tail the Automation Agent and MongoDB logs and can be viewed using the following command:\n\n```bash\nkubectl logs $POD -n mongodb\n```\n\nA common technique for troubleshooting issues is to use ssh to connect to one of the containers running MongoDB. Once connected, you can use various Linux tools to view the processes, troubleshoot issues, and even check the MongoDB shell connections (which can be helpful in diagnosing network issues).\n\n```bash\nkubectl exec -it $POD -n mongodb -- /bin/bash\n```\n\n## Conclusion\n\nMongoDB Enterprise Kubernetes Operator's latest version allows users to deploy MongoDB resources across multiple Kubernetes clusters, improving reliability and reducing downtime. Developed by MongoDB, MongoDBMulti Custom Resource Definition (CRD) makes it easy to run MongoDB replica sets across multiple Kubernetes environments and provides a declarative approach to deploying MongoDB, allowing users to specify the desired state of their deployment and letting the operator handle the details.\n\nIn combination with Ops Manager, a multi-region cluster creates a highly available database system with enterprise-class tools for backup, monitoring, alerting, upgrades, and configuration.\n\nAs Kubernetes becomes increasingly popular, it's important to start leveraging its capabilities in your organization. Do you want to stay up-to-date on the latest developments in MongoDB on Kubernetes? Be sure to check out [MongoDB community forum](https://www.mongodb.com/community/forums/) for the latest discussions and resources.","slug":"/deploying-across-multiple-kubernetes-clusters","description":"Learn how to deploy MongoDB across multiple Kubernetes clusters using the operator and the MongoDBMulti CRD.","name":"*Deploying MongoDB Across Multiple Kubernetes Clusters With MongoDBMulti","SEO":null,"related_content":[],"primary_tag":[{"__component":"primary-tag-info.l1-product","id":"63b80c55ebdd6d001c0b9b5b"}],"other_tags":[{"__component":"other-tag-info.other-tag-info","id":"63b80c55ebdd6d001c0b9b5d"}],"createdAt":"2023-01-06T11:56:05.500Z","updatedAt":"2023-01-13T20:17:12.073Z","__v":2,"image":{"_id":"63b80958ebdd6d001c0b9b59","name":"*Technical_CONTENT_Network_Spot_BS_ForestGreen.png","alternativeText":"","caption":"","hash":"Technical_CONTENT_Network_Spot_BS_Forest_Green_fd092d873b","ext":".png","mime":"image/png","size":53.43,"width":1392,"height":936,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/Technical_CONTENT_Network_Spot_BS_Forest_Green_fd092d873b.png","formats":{"thumbnail":{"name":"*thumbnail_Technical_CONTENT_Network_Spot_BS_ForestGreen.png","hash":"thumbnail_Technical_CONTENT_Network_Spot_BS_Forest_Green_fd092d873b","ext":".png","mime":"image/png","width":232,"height":156,"size":16.05,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/thumbnail_Technical_CONTENT_Network_Spot_BS_Forest_Green_fd092d873b.png"},"large":{"name":"*large_Technical_CONTENT_Network_Spot_BS_ForestGreen.png","hash":"large_Technical_CONTENT_Network_Spot_BS_Forest_Green_fd092d873b","ext":".png","mime":"image/png","width":1000,"height":672,"size":88.8,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/large_Technical_CONTENT_Network_Spot_BS_Forest_Green_fd092d873b.png"},"medium":{"name":"*medium_Technical_CONTENT_Network_Spot_BS_ForestGreen.png","hash":"medium_Technical_CONTENT_Network_Spot_BS_Forest_Green_fd092d873b","ext":".png","mime":"image/png","width":750,"height":504,"size":61.59,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/medium_Technical_CONTENT_Network_Spot_BS_Forest_Green_fd092d873b.png"},"small":{"name":"*small_Technical_CONTENT_Network_Spot_BS_ForestGreen.png","hash":"small_Technical_CONTENT_Network_Spot_BS_Forest_Green_fd092d873b","ext":".png","mime":"image/png","width":500,"height":336,"size":37.95,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/small_Technical_CONTENT_Network_Spot_BS_Forest_Green_fd092d873b.png"}},"provider":"aws-s3","related":["63b80c55ebdd6d001c0b9b5a"],"createdAt":"2023-01-06T11:43:20.122Z","updatedAt":"2023-01-06T11:56:05.616Z","__v":0,"id":"63b80958ebdd6d001c0b9b59"},"calculated_slug":"/products/connectors/deploying-across-multiple-kubernetes-clusters","expiry_date":"2024-01-06T11:56:05.500Z","id":"63b80c55ebdd6d001c0b9b5a"},"id":"63b80ded2fb860001caa7549"}],"createdAt":"2023-01-06T12:02:53.352Z","updatedAt":"2023-01-06T12:39:51.496Z","__v":1,"id":"63b80ded2fb860001caa7546"}]