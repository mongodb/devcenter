module.exports={"_id":"62acaa8763f6f6001c80fa26","published_at":"2022-06-17T16:23:46.290Z","content":[{"__component":"featured-category.programming-language","articles":[{"awaiting_editorial_review":false,"awaiting_technical_review":false,"editorial_review_LGTM":true,"technical_review_LGTM":true,"authors":["60ec57b2ac2aef22719767ba"],"_id":"6244b4fd7a304f0ca6c4d98e","type":"Quickstart","name":"*PyMongoArrow: Bridging the Gap Between MongoDB and Your Data Analysis App","slug":"/pymongoarrow-and-data-analysis","content":"## Overview\n\nMongoDB has always been a great database for data science and data analysis, and that's because you can:\n\n* Import data without a fixed schema.\n* Clean it up within the database.\n* Listen in real-time for updates (a very handy feature that's used by our [MongoDB Kafka Connector](https://docs.mongodb.com/kafka-connector/current/)).\n* Query your data with the super-powerful and intuitive [Aggregation Framework](https://docs.mongodb.com/manual/aggregation/).\n\nBut MongoDB is a general-purpose database, and not a data analysis tool, so a common pattern when analysing data that's stored within MongoDB is to extract the results of a query into a Numpy array, or Pandas dataframe, and to run complex and potentially long running analyses using the toolkit those frameworks provide. Until recently, the performance hit of converting large amounts of BSON data, as provided by MongoDB into these data structures, has been slower than we'd like.\n\nFortunately, MongoDB recently released [PyMongoArrow](https://mongo-arrow.readthedocs.io/en/pymongoarrow-0.1.1/), a Python library for efficiently converting the result of a MongoDB query into the [Apache Arrow](https://arrow.apache.org/) data model. If you're not aware of Arrow, you may now be thinking, \"Mark, how does converting to Apache Arrow help me with my Numpy or Pandas analysis?\" The answer is: Conversion between Arrow, Numpy, and Pandas is super efficient, so it provides a useful intermediate format for your tabular data. This way, we get to focus on building a powerful tool for mapping between MongoDB and Arrow, and leverage the existing [PyArrow](https://arrow.apache.org/docs/python/) library for integration with Numpy and MongoDB\n\n## Prerequisites\n\nYou'll need a recent version of Python (I'm using 3.8) with pip available. You can use [conda](https://docs.conda.io/projects/conda/en/latest/index.html) if you like, but PyMongoArrow is released on PyPI, so you'll still need to use pip to install it into your conda Python environment.\n\nThis tutorial was written for PyMongoArrow v0.1.1.\n\n## Getting Started\n\nIn this tutorial, I'm going to be using a sample database you can install when creating a cluster hosted on MongoDB Atlas. The database I'll be using is the \"sample\\_weatherdata\" database. You'll access this with a `mongodb+srv` URI, so you'll need to install PyMongo with the \"srv\" extra, like this:\n\n``` shell\n$ python -m pip install jupyter pymongoarrow 'pymongo[srv]' pandas\n```\n\n> **Useful Tip**: If you just run `pip`, you may end up using a copy of `pip` that was installed for a different version of `python` than the one you're using. For some reason, the `PATH` getting messed up this way happens more often than you'd think. A solution to this is to run pip via Python, with the command `python -m pip`. That way, it'll always run the version of `pip` that's associated with the version of `python` in your `PATH`. This is now the [officially recommended](https://pip.pypa.io/en/stable/getting-started/#ensure-you-have-a-working-pip) way to run `pip`!\n\nYou'll also need a MongoDB cluster set up with the sample datasets imported. Follow these instructions to import them into your MongoDB cluster and then set an environment variable, `MDB_URI`, pointing to your database. It should look like the line below, but with the URI you copy out of the Atlas web interface. (Click the \"Connect\" button for your cluster.)\n\n``` shell\nexport MDB_URI=mongodb+srv://USERNAME:PASSWORD@CLUSTERID.azure.mongodb.net/sample_weatherdata?retryWrites=true&w=majority\n```\n\nA sample document from the \"data\" collection looks like this:\n\n``` json\n{'_id': ObjectId('5553a998e4b02cf7151190bf'),\n  'st': 'x+49700-055900',\n  'ts': datetime.datetime(1984, 3, 5, 15, 0),\n  'position': {'type': 'Point', 'coordinates': [-55.9, 49.7]},\n  'elevation': 9999,\n  'callLetters': 'SCGB',\n  'qualityControlProcess': 'V020',\n  'dataSource': '4',\n  'type': 'FM-13',\n  'airTemperature': {'value': -5.1, 'quality': '1'},\n  'dewPoint': {'value': 999.9, 'quality': '9'},\n  'pressure': {'value': 1020.8, 'quality': '1'},\n  'wind': {'direction': {'angle': 100, 'quality': '1'},\n   'type': 'N',\n   'speed': {'rate': 3.1, 'quality': '1'}},\n  'visibility': {'distance': {'value': 20000, 'quality': '1'},\n   'variability': {'value': 'N', 'quality': '9'}},\n  'skyCondition': {'ceilingHeight': {'value': 22000,\n    'quality': '1',\n    'determination': 'C'},\n   'cavok': 'N'},\n  'sections': ['AG1', 'AY1', 'GF1', 'MD1', 'MW1'],\n  'precipitationEstimatedObservation': {'discrepancy': '2',\n   'estimatedWaterDepth': 0},\n  'pastWeatherObservationManual': [{'atmosphericCondition': {'value': '0',\n     'quality': '1'},\n    'period': {'value': 3, 'quality': '1'}}],\n  'skyConditionObservation': {'totalCoverage': {'value': '01',\n    'opaque': '99',\n    'quality': '1'},\n   'lowestCloudCoverage': {'value': '01', 'quality': '1'},\n   'lowCloudGenus': {'value': '01', 'quality': '1'},\n   'lowestCloudBaseHeight': {'value': 800, 'quality': '1'},\n   'midCloudGenus': {'value': '00', 'quality': '1'},\n   'highCloudGenus': {'value': '00', 'quality': '1'}},\n  'atmosphericPressureChange': {'tendency': {'code': '8', 'quality': '1'},\n   'quantity3Hours': {'value': 0.5, 'quality': '1'},\n   'quantity24Hours': {'value': 99.9, 'quality': '9'}},\n  'presentWeatherObservationManual': [{'condition': '02', 'quality': '1'}]}\n```\n\nTo keep things simpler in this tutorial, I'll ignore all the fields except for \"ts,\" \"wind,\" and the \"\\_id\" field.\n\nI set the `MDB_URI` environment variable, installed the dependencies above, and then fired up a new Python 3 Jupyter Notebook. I've put the notebook [on GitHub](https://github.com/mongodb-developer/pymongoarrow-sample-code/blob/main/PyMongoArrow%20Demo.ipynb), if you want to follow along, or run it yourself.\n\nI added the following code to a cell at the top of the file to import the necessary modules, and to connect to my database:\n\n``` python\nimport os\nimport pyarrow\nimport pymongo\nimport bson\nimport pymongoarrow.monkey\nfrom pymongoarrow.api import Schema\n\nMDB_URI = os.environ['MDB_URI']\n\n\n# Add extra find_* methods to pymongo collection objects:\npymongoarrow.monkey.patch_all()\n\nclient = pymongo.MongoClient(MDB_URI)\ndatabase = client.get_default_database()\ncollection = database.get_collection(\"data\")\n```\n\n## Working With Flat Data\n\nIf the data you wish to convert to Arrow, Pandas, or Numpy data tables is already flat—i.e., the fields are all at the top level of your documents—you can use the methods `find\\_arrow\\_all`, `find\\_pandas\\_all`, and `find\\_numpy\\_all` to query your collection and return the appropriate data structure.\n\n``` python\ncollection.find_pandas_all(\n    {},\n    schema=Schema({\n        'ts': pyarrow.timestamp('ms'),\n    })\n)\n```\n\n|  | ts |\n| --- | ---: |\n| 0 | 1984-03-05 15:00:00 |\n| 1 | 1984-03-05 18:00:00 |\n| 2 | 1984-03-05 18:00:00 |\n| 3 | 1984-03-05 18:00:00 |\n| 4 | 1984-03-05 18:00:00 |\n| ... | ... |\n| 9995 | 1984-03-13 06:00:00 |\n| 9996 | 1984-03-13 06:00:00 |\n| 9997 | 1984-03-13 06:00:00 |\n| 9998 | 1984-03-12 09:00:00 |\n| 9999 | 1984-03-12 12:00:00 |\n\n10000 rows × 1 columns\n\nThe first argument to find\\_pandas\\_all is the `filter` argument. I'm interested in all the documents in the collection, so I've left it empty. The documents in the data collection are quite nested, so the only real value I can access with a find query is the timestamp of when the data was recorded, the \"ts\" field. Don't worry—I'll show you how to access the rest of the data in a moment!\n\nBecause Arrow tables (and the other data types) are strongly typed, you'll also need to provide a Schema to map from MongoDB's permissive dynamic schema into the types you want to handle in your in-memory data structure.\n\nThe `Schema` is a mapping of the field name, to the appropriate type to be used by Arrow, Pandas, or Numpy. At the current time, these types are 64-bit ints, 64-bit floating point numbers, and datetimes. The easiest way to specify these is with the native python types `int` and `float`, and with `pyarrow.datetime`. Any fields in the document that aren't listed in the schema will be ignored.\n\nPyMongoArrow currently hijacks the `projection` parameter to the `find_*_all` methods, so unfortunately, you can't write a projection to flatten the structure at the moment.\n\n## Convert Your Documents to Tabular Data\nMongoDB documents are very flexible, and can support nested arrays and documents. Although Apache Arrow also supports nested lists, structs, and dictionaries, Numpy arrays and Pandas dataframes, in contrast, are tabular or columnar data structures. There are plans to support mapping to the nested Arrow data types in future, but at the moment, only scalar values are supported with all three libraries. So in all these cases, it will be necessary to flatten the data you are exporting from your documents.\n\nTo project your documents into a flat structure, you'll need to use the more powerful `aggregate_*_all` methods that PyMongoArrow adds to your PyMongo Collection objects.\n\nIn an aggregation pipeline, you can add a `$project` stage to your query to project the nested fields you want in your table to top level fields in the aggregation result.\n\nIn order to test my `$project` stage, I first ran it with the standard PyMongo aggregate function. I converted it to a `list` so that Jupyter would display the results.\n\n``` python\nlist(collection.aggregate([\n    {'$match': {'_id': bson.ObjectId(\"5553a998e4b02cf7151190bf\")}},\n    {'$project': {\n        'windDirection': '$wind.direction.angle',\n        'windSpeed': '$wind.speed.rate',\n    }}\n]))\n\n[{'_id': ObjectId('5553a998e4b02cf7151190bf'),\n  'windDirection': 100,\n  'windSpeed': 3.1}]\n```\n\nBecause I've matched a single document by \"\\_id,\" only one document is returned, but you can see that the `$project` stage has mapped `$wind.direction.angle` to the top-level \"windDirection\" field in the result, and the same with `$wind.speed.rate` and \"windSpeed\" in the result.\n\nI can take this `$project` stage and use it to flatten all the results from an aggregation query, and then provide a schema to identify \"windDirection\" as an integer value, and \"windSpeed\" as a floating point number, like this:\n\n``` python\ncollection.aggregate_pandas_all([\n        {'$project': {\n            'windDirection': '$wind.direction.angle',\n            'windSpeed': '$wind.speed.rate',\n        }}\n    ],\n    schema=Schema({'windDirection': int, 'windSpeed': float})\n)\n```\n\n| A | B | C |\n| --- | --- | --- |\n|  | windDirection | windSpeed |\n| 0 | 100 | 3.1 |\n| 1 | 50 | 9.0 |\n| 2 | 30 | 7.7 |\n| 3 | 270 | 19.0 |\n| 4 | 50 | 8.2 |\n| ... | ... | ... |\n| 9995 | 10 | 7.0 |\n| 9996 | 60 | 5.7 |\n| 9997 | 330 | 3.0 |\n| 9998 | 140 | 7.7 |\n| 9999 | 80 | 8.2 |\n\n10000 rows × 2 columns\n\nThere are only 10000 documents in this collection, but some basic benchmarks I wrote show this to be around 20% faster than working directly with `DataFrame.from_records` and `PyMongo`. With larger datasets, I'd expect the difference in performance to be more significant. It's early days for the PyMongoArrow library, and so there are some limitations at the moment, such as the ones I've mentioned above, but the future looks bright for this library in providing fast mappings between your rich, flexible MongoDB collections and any in-memory analysis requirements you might have with Arrow, Pandas, or Numpy.\n\n## Next Steps\n\nIf you're planning to do lots of analysis of data that's stored in MongoDB, then make sure you're up on the latest features of MongoDB's powerful [aggregation framework](https://docs.mongodb.com/manual/aggregation/). You can do many things within the database so you may not need to export your data at all. You can connect to secondary servers in your cluster to reduce load on the primary for analytics queries, or even have [dedicated analytics nodes](https://www.mongodb.com/blog/post/atlas-mapped-analytics-nodes-to-power-your-bi-are-now-available) for running these kinds of queries.\nCheck out MongoDB 5.0's new [window functions](https://docs.mongodb.com/manual/reference/operator/aggregation/setWindowFields/) and if you're working with time series data, you'll definitely want to know about MongoDB 5.0's new [time-series collections](https://docs.mongodb.com/manual/core/timeseries-collections/).","originalPublishDate":"2021-10-15T15:52:14.156Z","SEO":null,"related_content":[],"createdAt":"2021-10-14T09:09:32.622Z","originalUpdatedAt":"2021-10-15T15:52:14.332Z","created_by":"60958822b4522964e193dbc6","image":{"_id":"627d26898891f3001d997e91","name":"*Python Banner_1280x720.png","alternativeText":"","caption":"","hash":"Python_Banner_1280x720_ab74d31ebe","ext":".png","mime":"image/png","size":34.26,"width":1280,"height":720,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/Python_Banner_1280x720_ab74d31ebe.png","formats":{"thumbnail":{"name":"*thumbnail_Python Banner_1280x720.png","hash":"thumbnail_Python_Banner_1280x720_ab74d31ebe","ext":".png","mime":"image/png","width":245,"height":138,"size":11.99,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/thumbnail_Python_Banner_1280x720_ab74d31ebe.png"},"large":{"name":"*large_Python Banner_1280x720.png","hash":"large_Python_Banner_1280x720_ab74d31ebe","ext":".png","mime":"image/png","width":1000,"height":563,"size":67.91,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/large_Python_Banner_1280x720_ab74d31ebe.png"},"medium":{"name":"*medium_Python Banner_1280x720.png","hash":"medium_Python_Banner_1280x720_ab74d31ebe","ext":".png","mime":"image/png","width":750,"height":422,"size":45.36,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/medium_Python_Banner_1280x720_ab74d31ebe.png"},"small":{"name":"*small_Python Banner_1280x720.png","hash":"small_Python_Banner_1280x720_ab74d31ebe","ext":".png","mime":"image/png","width":500,"height":281,"size":27.36,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/small_Python_Banner_1280x720_ab74d31ebe.png"}},"provider":"aws-s3","related":["6244b4fd7a304f0ca6c4d9cd","6244b4fd7a304f0ca6c4d9ce","6244b4fd7a304f0ca6c4da4f","6244b4fd7a304f0ca6c4d9ef","6244b4fd7a304f0ca6c4da01","6244b4fd7a304f0ca6c4d98e","6244b4fd7a304f0ca6c4d9c0","6244b4fd7a304f0ca6c4d9c1","6244b4fd7a304f0ca6c4d9c2","6244b4fd7a304f0ca6c4d9c3","6244b4fd7a304f0ca6c4d9c4","6244b4fd7a304f0ca6c4d9c7","6244b4fd7a304f0ca6c4d9c5","6244b4fd7a304f0ca6c4d9c6","6244b4fd7a304f0ca6c4d9c8"],"createdAt":"2022-05-12T15:23:53.601Z","updatedAt":"2022-05-12T17:03:04.614Z","__v":0,"created_by":"60acfb196a6d99001c58c549","updated_by":"60acfb196a6d99001c58c549","id":"627d26898891f3001d997e91"},"updated_by":"61f82d1bdf707f001cad52ff","description":"MongoDB has always been a great database for data science and data analysis, and now with PyMongoArrow, it integrates optimally with Apache Arrow, Python's Numpy, and Pandas libraries.","__v":3,"other_tags":[{"__component":"other-tag-info.other-tag-info","id":"62585bcb4a0541001d3813f7"}],"primary_tag":[{"__component":"primary-tag-info.programming-language","id":"62585bcb4a0541001d3813f5"}],"updatedAt":"2022-05-20T18:12:33.039Z","calculated_slug":"/languages/python/pymongoarrow-and-data-analysis","published_at":"2022-05-09T19:03:49.656Z","id":"6244b4fd7a304f0ca6c4d98e"},{"awaiting_editorial_review":false,"awaiting_technical_review":false,"editorial_review_LGTM":true,"technical_review_LGTM":true,"authors":["60ec57b2ac2aef22719767ba"],"_id":"6244b4fd7a304f0ca6c4d9ef","type":"HowTo","name":"*Build a RESTful API with Flask, MongoDB, and Python","slug":"/flask-python-mongodb","content":">This is the first part of a short series of blog posts called \"Rewrite it in Rust (RiiR).\" It's a tongue-in-cheek title for some posts that will investigate the similarities and differences between the same service written in Python with Flask, and Rust with Actix-Web.\n\nThis post will show how I built a RESTful API for a collection of cocktail recipes I just happen to have lying around. The aim is to show an API server with some complexity, so although it's a small example, it will cover important factors such as:\n\n-   Data transformation between the database and a JSON representation.\n-   Data validation.\n-   Pagination.\n-   Error-handling.\n\n## Prerequisites\n\n-   Python 3.8 or above\n-   A MongoDB Atlas cluster. Follow the \"[Get Started with Atlas](https://docs.atlas.mongodb.com/getting-started/)\" guide to create your account and MongoDB cluster. Keep a note of your database username, password, and [connection string](https://docs.atlas.mongodb.com/tutorial/connect-to-your-cluster/#connect-to-your-atlas-cluster) as you will need those later.\n\nThis is an *advanced* guide, so it'll cover a whole bunch of different libraries which can be brought together to build a declarative Restful API server on top of MongoDB. I won't cover repeating patterns in the codebase, so if you want to build the whole thing, I recommend checking out the source code, which is all [on GitHub](https://github.com/mongodb-developer/rewrite-it-in-rust).\n\nIt won't cover the basics of Python, Flask, or MongoDB, so if that's what you're looking for, I recommend checking out the following resources before tackling this post:\n\n-   [Think Python](https://greenteapress.com/wp/think-python-2e/)\n-   [The Python & MongoDB Quickstart Series](https://developer.mongodb.com/quickstart/python-quickstart-crud/)\n-   [Flask Tutorial](https://flask.palletsprojects.com/en/1.1.x/tutorial/)\n-   [Pydantic Documentation](https://pydantic-docs.helpmanual.io/)\n\n## Getting Started\n\nBegin by cloning the sample code source [from GitHub](https://github.com/mongodb-developer/rewrite-it-in-rust). There are four top-level directories:\n\n-   [actix-cocktail-api](https://github.com/mongodb-developer/rewrite-it-in-rust/tree/master/actix-cocktail-api): You can ignore this for now.\n-   [data](https://github.com/mongodb-developer/rewrite-it-in-rust/tree/master/data): This contains an export of my cocktail data. You'll import this into your cluster in a moment.\n-   [flask-cocktail-api](https://github.com/mongodb-developer/rewrite-it-in-rust/tree/master/flask-cocktail-api): The code for this blog post.\n-   [test_scripts](https://github.com/mongodb-developer/rewrite-it-in-rust/tree/master/test_scripts): A few shell scripts that use curl to test the HTTP interface of the API server.\n\nThere are more details in the [GitHub repo](https://github.com/mongodb-developer/rewrite-it-in-rust/tree/master/flask-cocktail-api), but the basics are: Install the project with your virtualenv active:\n\n``` shell\npip install -e .\n```\n\nNext, you should import the data into your cluster. Set the environment variable `$MONGO_URI` to your cluster URI. This environment variable will be used in a moment to import your data, and also by the Flask app. I use `direnv` to configure this, and put the following line in my `.envrc` file in my project's directory:\n\n``` shell\nexport MONGO_URI=\"mongodb+srv://USERNAME:PASSW0RD@cluster0-abcde.azure.mongodb.net/cocktails?retryWrites=true&w=majority\"\n```\n\nNote that your database must be called \"cocktails,\" and the import will create a collection called \"recipes.\" After checking that `$MONGO_URI` is set correctly, run the following command:\n\n``` shell\nmongoimport --uri \"$MONGO_URI\" --file ./recipes.json\n```\n\nNow you should be able to run the Flask app from the\n`flask-cocktail-api` directory:\n\n``` shell\nFLASK_DEBUG=true FLASK_APP=cocktailapi flask run\n```\n\n(You can run `make run` if you prefer.)\n\nCheck the output to ensure it is happy with the configuration, and then in a different terminal window, run the `list_cocktails.sh` script in the `test_scripts` directory. It should print something like this:\n\n``` json\n{\n    \"_links\": {\n        \"last\": {\n            \"href\": \"http://localhost:5000/cocktails/?page=5\"\n        }, \n        \"next\": {\n            \"href\": \"http://localhost:5000/cocktails/?page=5\"\n        }, \n        \"prev\": {\n            \"href\": \"http://localhost:5000/cocktails/?page=3\"\n        }, \n        \"self\": {\n            \"href\": \"http://localhost:5000/cocktails/?page=4\"\n        }\n    }, \n    \"recipes\": [\n        {\n            \"_id\": \"5f7daa198ec9dfb536781b0d\", \n            \"date_added\": null, \n            \"date_updated\": null, \n            \"ingredients\": [\n            {\n                \"name\": \"Light rum\", \n                \"quantity\": {\n                \"unit\": \"oz\", \n                }\n            }, \n            {\n                \"name\": \"Grapefruit juice\", \n                \"quantity\": {\n                \"unit\": \"oz\", \n                }\n            }, \n            {\n                \"name\": \"Bitters\", \n                \"quantity\": {\n                \"unit\": \"dash\", \n                }\n            }\n            ], \n            \"instructions\": [\n            \"Pour all of the ingredients into an old-fashioned glass almost filled with ice cubes\", \n            \"Stir well.\"\n            ], \n            \"name\": \"Monkey Wrench\", \n            \"slug\": \"monkey-wrench\"\n        },\n    ]\n    ...\n```\n\n## Breaking it All Down\n\nThe code is divided into three submodules.\n\n-   `__init__.py` contains all the Flask setup code, and defines all the HTTP routes.\n-   `model.py` contains all the Pydantic model definitions.\n-   `objectid.py` contains a Pydantic field definition that I stole from the [Beanie](https://github.com/roman-right/beanie) object-data mapper for MongoDB.\n\nI mentioned earlier that this code makes use of several libraries:\n\n-   [PyMongo](https://pymongo.readthedocs.io/en/stable/index.html) and [Flask-PyMongo](https://flask-pymongo.readthedocs.io/en/latest/) handle the connection to the database. Flask-PyMongo specifically wraps the database collection object to provide a convenient`find_one_or_404` method.\n-   [Pydantic](https://pydantic-docs.helpmanual.io/usage/exporting_models/) manages data validation, and some aspects of data transformation between the database and a JSON representations.\n-   along with a single function from [FastAPI](https://fastapi.tiangolo.com/).\n\n## Data Validation and Transformation\n\nWhen building a robust API, it's important to validate all the data passing into the system. It would be possible to do this using a stack of `if/else` statements, but it's much more effective to define a schema declaratively, and to allow that to programmatically validate the data being input.\n\nI used a technique that I learned from [Beanie](https://github.com/roman-right/beanie), a new and neat ODM that I unfortunately couldn't practically use on this project, because Beanie is async, and Flask is a blocking framework.\n\nBeanie uses [Pydantic](https://pydantic-docs.helpmanual.io/usage/exporting_models/) to define a schema, and adds a custom Field type for ObjectId.\n\n``` python\n# model.py\n\nclass Cocktail(BaseModel):\n    id: Optional[PydanticObjectId] = Field(None, alias=\"_id\")\n    slug: str\n    name: str\n    ingredients: List[Ingredient]\n    instructions: List[str]\n    date_added: Optional[datetime]\n    date_updated: Optional[datetime]\n\n    def to_json(self):\n        return jsonable_encoder(self, exclude_none=True)\n\n    def to_bson(self):\n        data = self.dict(by_alias=True, exclude_none=True)\n        if data[\"_id\"] is None:\n            data.pop(\"_id\")\n        return data\n```\n\nThis `Cocktail` schema defines the structure of a `Cocktail` instance, which will be validated by Pydantic when instances are created. It includes another embedded schema for `Ingredient`, which is defined in a similar way.\n\nI added convenience functions to export the data in the `Cocktail` instance to either a JSON-compatible `dict` or a BSON-compatible `dict`. The differences are subtle, but BSON supports native `ObjectId` and `datetime` types, for example, whereas when encoding as JSON, it's necessary to encode ObjectId instances in some other way (I prefer a string containing the hex value of the id), and datetime objects are encoded as ISO8601 strings.\n\nThe `to_json` method makes use of a function imported from FastAPI, which recurses through the instance data, encoding all values in a JSON-compatible form. It already handles `datetime` instances correctly, but to get it to handle ObjectId values, I extracted some [custom field](https://github.com/mongodb-developer/rewrite-it-in-rust/blob/master/flask-cocktail-api/src/cocktailapi/objectid.py) code from Beanie, which can be found in `objectid.py`.\n\nThe `to_bson` method doesn't need to pass the `dict` data through `jsonable_encoder`. All the types used in the schema can be directly saved with PyMongo. It's important to set `by_alias` to `True`, so that the key for `_id` is just that, `_id`, and not the schema's `id` without an underscore.\n\n``` python\n# objectid.py\n\nclass PydanticObjectId(ObjectId):\n    \"\"\"\n    ObjectId field. Compatible with Pydantic.\n    \"\"\"\n\n    @classmethod\n    def __get_validators__(cls):\n        yield cls.validate\n\n    @classmethod\n    def validate(cls, v):\n        return PydanticObjectId(v)\n\n    @classmethod\n    def __modify_schema__(cls, field_schema: dict):\n        field_schema.update(\n            type=\"string\",\n            examples=[\"5eb7cf5a86d9755df3a6c593\", \"5eb7cfb05e32e07750a1756a\"],\n        )\n\nENCODERS_BY_TYPE[PydanticObjectId] = str\n```\n\nThis approach is neat for this particular use-case, but I can't help feeling that it would be limiting in a more complex system. There are many [patterns for storing data in MongoDB](https://www.mongodb.com/blog/post/building-with-patterns-a-summary). These often result in storing data in a form that is optimal for writes or reads, but not necessarily the representation you would wish to export in an API.\n\n>**What is a Slug?**\n>\n>Looking at the schema above, you may have wondered what a \"slug\" is ... well, apart from a slimy garden pest.\n>\n>A slug is a unique, URL-safe, mnemonic used for identifying a document. I picked up the terminology as a Django developer, where this term is part of the framework. A slug is usually derived from another field. In this case, the slug is derived from the name of the cocktail, so if a cocktail was called \"Rye Whiskey Old-Fashioned,\" the slug would be \"rye-whiskey-old-fashioned.\"\n>\n>In this API, that cocktail could be accessed by sending a `GET` request to the `/cocktails/rye-whiskey-old-fashioned` endpoint.\n>\n>I've kept the unique `slug` field separate from the auto-assigned `_id` field, but I've provided both because the slug could change if the name of the cocktail was tweaked, in which case the `_id` value would provide a constant identifier to look up an exact document.\n\nIn the Rust version of this code, I was nudged to use a different approach. It's a bit more verbose, but in the end I was convinced that it would be more powerful and flexible as the system grew.\n\n## Creating a New Document\n\nNow I'll show you what a single endpoint looks like, first focusing on the \"Create\" endpoint, that handles a POST request to `/cocktails` and creates a new document in the \"recipes\" collection. It then returns the document that was stored, including the newly unique ID that MongoDB assigned as `_id`, because this is a RESTful API, and that's what RESTful APIs do.\n\n``` python\n@app.route(\"/cocktails/\", methods=[\"POST\"])\ndef new_cocktail():\n    raw_cocktail = request.get_json()\n    raw_cocktail[\"date_added\"] = datetime.utcnow()\n\n    cocktail = Cocktail(**raw_cocktail)\n    insert_result = recipes.insert_one(cocktail.to_bson())\n    cocktail.id = PydanticObjectId(str(insert_result.inserted_id))\n    print(cocktail)\n\n    return cocktail.to_json()\n```\n\nThis endpoint modifies the incoming JSON directly, to add a `date_added` item with the current time. It then passes it to the constructor for our Pydantic schema. At this point, if the schema failed to validate the data, an exception would be raised and displayed to the user.\n\nAfter validating the data, `to_bson()` is called on the `Cocktail` to convert it to a BSON-compatible dict, and this is directly passed to PyMongo's `insert_one` method. There's no way to get PyMongo to return the document that was just inserted in a single operation (although an upsert using `find_one_and_update` is similar to just that).\n\nAfter inserting the data, the code then updates the local object with the newly-assigned `id` and returns it to the client.\n\n## Reading a Single Cocktail\n\nThanks to `Flask-PyMongo`, the endpoint for looking up a single cocktail is even more straightforward:\n\n``` python\n@app.route(\"/cocktails/<string:slug>\", methods=[\"GET\"])\ndef get_cocktail(slug):\n    recipe = recipes.find_one_or_404({\"slug\": slug})\n    return Cocktail(**recipe).to_json()\n```\n\nThis endpoint will abort with a 404 if the slug can't be found in the collection. Otherwise, it simply instantiates a Cocktail with the document from the database, and calls `to_json` to convert it to a dict that Flask will automatically encode correctly as JSON.\n\n## Listing All the Cocktails\n\nThis endpoint is a monster, and it's because of pagination, and the links for pagination. In the sample data above, you probably noticed the `_links` section:\n\n``` json\n\"_links\": {\n    \"last\": {\n        \"href\": \"http://localhost:5000/cocktails/?page=5\"\n    }, \n    \"next\": {\n        \"href\": \"http://localhost:5000/cocktails/?page=5\"\n    }, \n    \"prev\": {\n        \"href\": \"http://localhost:5000/cocktails/?page=3\"\n    }, \n    \"self\": {\n        \"href\": \"http://localhost:5000/cocktails/?page=4\"\n    }\n}, \n```\n\nThis `_links` section is specified as part of the [HAL (Hypertext Application\nLanguage)](https://tools.ietf.org/html/draft-kelly-json-hal-00) specification. It's a good idea to follow a standard for pagination data, and I didn't feel like inventing something myself!\n\nAnd here's the code to generate all this. Don't freak out.\n\n``` python\n@app.route(\"/cocktails/\")\ndef list_cocktails():\n    \"\"\"\n    GET a list of cocktail recipes.\n\n    The results are paginated using the `page` parameter.\n    \"\"\"\n\n    page = int(request.args.get(\"page\", 1))\n    per_page = 10  # A const value.\n\n    # For pagination, it's necessary to sort by name,\n    # then skip the number of docs that earlier pages would have displayed,\n    # and then to limit to the fixed page size, ``per_page``.\n    cursor = recipes.find().sort(\"name\").skip(per_page * (page - 1)).limit(per_page)\n\n    cocktail_count = recipes.count_documents({})\n\n    links = {\n        \"self\": {\"href\": url_for(\".list_cocktails\", page=page, _external=True)},\n        \"last\": {\n            \"href\": url_for(\n                \".list_cocktails\", page=(cocktail_count // per_page) + 1, _external=True\n            )\n        },\n    }\n    # Add a 'prev' link if it's not on the first page:\n    if page > 1:\n        links[\"prev\"] = {\n            \"href\": url_for(\".list_cocktails\", page=page - 1, _external=True)\n        }\n    # Add a 'next' link if it's not on the last page:\n    if page - 1 < cocktail_count // per_page:\n        links[\"next\"] = {\n            \"href\": url_for(\".list_cocktails\", page=page + 1, _external=True)\n        }\n\n    return {\n        \"recipes\": [Cocktail(**doc).to_json() for doc in cursor],\n        \"_links\": links,\n    }\n```\n\nAlthough there's a lot of code there, it's not as complex as it may first appear. Two requests are made to MongoDB: one for a page-worth of cocktail recipes, and the other for the total number of cocktails in the collection. Various calculations are done to work out how many documents to skip, and how many pages of cocktails there are. Finally, some links are added for \"prev\" and \"next\" pages, if appropriate (i.e.: the current page isn't the first or last.) Serialization of the cocktail documents is done in the same way as the previous endpoint, but in a loop this time.\n\nThe update and delete endpoints are mainly repetitions of the code I've already included, so I'm not going to include them here. Check them out in the [GitHub repo](https://github.com/mongodb-developer/rewrite-it-in-rust/blob/master/flask-cocktail-api/src/cocktailapi/__init__.py) if you want to see how they work.\n\n## Error Handling\n\nNothing irritates me more than using a JSON API which returns HTML when an error occurs, so I was keen to put in some reasonable error handling to avoid this happening.\n\nAfter Flask set-up code, and before the endpoint definitions, the code registers two error-handlers:\n\n``` python\n@app.errorhandler(404)\ndef resource_not_found(e):\n    \"\"\"\n    An error-handler to ensure that 404 errors are returned as JSON.\n    \"\"\"\n    return jsonify(error=str(e)), 404\n\n\n@app.errorhandler(DuplicateKeyError)\ndef resource_not_found(e):\n    \"\"\"\n    An error-handler to ensure that MongoDB duplicate key errors are returned as JSON.\n    \"\"\"\n    return jsonify(error=f\"Duplicate key error.\"), 400\n```\n\nThe first error-handler intercepts any endpoint that fails with a 404 status code and ensures that the error is returned as a JSON dict.\n\nThe second error-handler intercepts a `DuplicateKeyError` raised by any endpoint, and does the same thing as the first error-handler, but sets the HTTP status code to \"400 Bad Request.\"\n\nAs I was writing this post, I realised that I've missed an error-handler to deal with invalid Cocktail data. I'll leave implementing that as an exercise for the reader! Indeed, this is one of the difficulties with writing robust Python applications: Because exceptions can be raised from deep in your stack of dependencies, it's very difficult to comprehensively predict what exceptions your application may raise in different circumstances.\n\nThis is something that's very different in Rust, and even though, as you'll see, error-handling in Rust can be verbose and tricky, I've started to love the language for its insistence on correctness.\n\n## Wrapping Up\n\nWhen I started writing this post, I though it would end up being relatively straightforward. As I added the requirement that the code should not just be a toy example, some of the inherent difficulties with building a robust API on top of any database became apparent.\n\nIn this case, Flask may not have been the right tool for the job. I recently wrote a blog post about [building an API with Beanie](https://developer.mongodb.com/article/beanie-odm-fastapi-cocktails/). Beanie and FastAPI are a match made in heaven for this kind of application and will handle validation, transformation, and pagination with much less code. On top of that, they're self-documenting and can provide the data's schema in open formats, including [OpenAPI Spec](https://swagger.io/specification/) and [JSON Schema](https://json-schema.org/)!\n\nIf you're about to build an API from scratch, I strongly recommend you check them out, and you may enjoy reading Aaron Bassett's posts on the [FARM (FastAPI, React, MongoDB) Stack](https://developer.mongodb.com/how-to/FARM-Stack-FastAPI-React-MongoDB/).\n\nI will shortly publish the second post in this series, *Build a Cocktail API with Actix-Web, MongoDB, and Rust*, and then I'll conclude with a third post, *I Rewrote it in Rust—How Did it Go?*, where I'll evaluate the strengths and weaknesses of the two experiments.\n\nThank you for reading. Keep a look out for the upcoming posts!\n\n>If you have questions, please head to our [developer community website](https://community.mongodb.com/) where the MongoDB engineers and the MongoDB community will help you build your next big idea with MongoDB.","originalPublishDate":"2022-01-14T12:56:45.050Z","SEO":"61b7fd84e454ca0b0d5285cd","related_content":[],"createdAt":"2021-12-14T02:12:20.435Z","originalUpdatedAt":"2022-01-14T12:56:45.117Z","image":{"_id":"627d26898891f3001d997e91","name":"*Python Banner_1280x720.png","alternativeText":"","caption":"","hash":"Python_Banner_1280x720_ab74d31ebe","ext":".png","mime":"image/png","size":34.26,"width":1280,"height":720,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/Python_Banner_1280x720_ab74d31ebe.png","formats":{"thumbnail":{"name":"*thumbnail_Python Banner_1280x720.png","hash":"thumbnail_Python_Banner_1280x720_ab74d31ebe","ext":".png","mime":"image/png","width":245,"height":138,"size":11.99,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/thumbnail_Python_Banner_1280x720_ab74d31ebe.png"},"large":{"name":"*large_Python Banner_1280x720.png","hash":"large_Python_Banner_1280x720_ab74d31ebe","ext":".png","mime":"image/png","width":1000,"height":563,"size":67.91,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/large_Python_Banner_1280x720_ab74d31ebe.png"},"medium":{"name":"*medium_Python Banner_1280x720.png","hash":"medium_Python_Banner_1280x720_ab74d31ebe","ext":".png","mime":"image/png","width":750,"height":422,"size":45.36,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/medium_Python_Banner_1280x720_ab74d31ebe.png"},"small":{"name":"*small_Python Banner_1280x720.png","hash":"small_Python_Banner_1280x720_ab74d31ebe","ext":".png","mime":"image/png","width":500,"height":281,"size":27.36,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/small_Python_Banner_1280x720_ab74d31ebe.png"}},"provider":"aws-s3","related":["6244b4fd7a304f0ca6c4d9cd","6244b4fd7a304f0ca6c4d9ce","6244b4fd7a304f0ca6c4da4f","6244b4fd7a304f0ca6c4d9ef","6244b4fd7a304f0ca6c4da01","6244b4fd7a304f0ca6c4d98e","6244b4fd7a304f0ca6c4d9c0","6244b4fd7a304f0ca6c4d9c1","6244b4fd7a304f0ca6c4d9c2","6244b4fd7a304f0ca6c4d9c3","6244b4fd7a304f0ca6c4d9c4","6244b4fd7a304f0ca6c4d9c7","6244b4fd7a304f0ca6c4d9c5","6244b4fd7a304f0ca6c4d9c6","6244b4fd7a304f0ca6c4d9c8"],"createdAt":"2022-05-12T15:23:53.601Z","updatedAt":"2022-05-12T17:03:04.614Z","__v":0,"created_by":"60acfb196a6d99001c58c549","updated_by":"60acfb196a6d99001c58c549","id":"627d26898891f3001d997e91"},"updated_by":"60acfb196a6d99001c58c549","description":"Build a RESTful API with Flask, MongoDB, and Python","__v":3,"other_tags":[{"__component":"other-tag-info.other-tag-info","id":"62585a394a0541001d3813dc"}],"primary_tag":[{"__component":"primary-tag-info.programming-language","id":"62585a394a0541001d3813da"}],"updatedAt":"2022-05-12T16:49:13.884Z","calculated_slug":"/languages/python/flask-python-mongodb","published_at":"2022-05-09T19:15:32.292Z","id":"6244b4fd7a304f0ca6c4d9ef"},{"awaiting_editorial_review":false,"awaiting_technical_review":false,"editorial_review_LGTM":true,"technical_review_LGTM":true,"authors":["61969acfa0957d40b0be63c1"],"_id":"6244b4fd7a304f0ca6c4d9c4","type":"Quickstart","name":"*Getting Started with MongoDB and FastAPI","slug":"/python-quickstart-fastapi","content":"<div>\n    <img\n        style=\"float: right; width: 30%;\"\n        src=\"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/old_images/qs-badges/qs-badge-python.png\"\n        alt=\"QuickStart Python Logo\" />\n\n[FastAPI](https://fastapi.tiangolo.com/) is a modern, high-performance, easy-to-learn, fast-to-code, production-ready, Python 3.6+ framework for building APIs based on standard Python type hints. While it might not be as established as some other Python frameworks such as Django, it is already in production at companies such as Uber, Netflix, and Microsoft.\n\n</div>\n\nFastAPI is async, and as its name implies, it is super fast; so, MongoDB is the perfect accompaniment. In this quick start, we will create a CRUD (Create, Read, Update, Delete) app showing how you can integrate MongoDB with your FastAPI projects.\n\n## Prerequisites\n\n-   Python 3.9.0\n-   A MongoDB Atlas cluster. Follow the \"[Get Started with Atlas](https://docs.atlas.mongodb.com/getting-started/)\" guide to create your account and MongoDB cluster. Keep a note of your username, password, and [connection string](https://docs.atlas.mongodb.com/tutorial/connect-to-your-cluster/#connect-to-your-atlas-cluster) as you will need those later.\n\n## Running the Example\n\nTo begin, you should [clone the example code from GitHub](https://github.com/mongodb-developer/mongodb-with-fastapi).\n\n``` shell\ngit clone git@github.com:mongodb-developer/mongodb-with-fastapi.git\n```\n\nYou will need to install a few dependencies: FastAPI, [Motor](https://motor.readthedocs.io/), etc. I always recommend that you install all Python dependencies in a [virtualenv](https://docs.python.org/3/tutorial/venv.html) for the project. Before running pip, ensure your virtualenv is active.\n\n``` shell\ncd mongodb-with-fastapi\npip install -r requirements.txt\n```\n\nIt may take a few moments to download and install your dependencies.  This is normal, especially if you have not installed a particular package before.\n\nOnce you have installed the dependencies, you need to create an environment variable for your MongoDB connection string.\n\n``` shell\nexport MONGODB_URL=\"mongodb+srv://<username>:<password>@<url>/<db>?retryWrites=true&w=majority\"\n```\n\nRemember, anytime you start a new terminal session, you will need to set this environment variable again. I use [direnv](https://direnv.net/) to make this process easier.\n\nThe final step is to start your FastAPI server.\n\n``` shell\nuvicorn app:app --reload\n```\n\n![Screenshot of terminal running FastAPI](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/old_images/mongodb-with-fastapi/terminal.png)\n\nOnce the application has started, you can view it in your browser at <http://127.0.0.1:8000/docs>.\n\n![Screenshot of browser and swagger UI](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/old_images/mongodb-with-fastapi/browser.png)\n\nOnce you have had a chance to try the example, come back and we will walk through the code.\n\n## Creating the Application\n\nAll the code for the example application is within `app.py`. I'll break it down into sections and walk through what each is doing.\n\n### Connecting to MongoDB\n\nOne of the very first things we do is connect to our MongoDB database.\n\n``` python\nclient = motor.motor_asyncio.AsyncIOMotorClient(os.environ[\"MONGODB_URL\"])\ndb = client.college\n```\n\nWe're using the async [motor driver](https://motor.readthedocs.io/en/stable/) to create our MongoDB client, and then we specify our database name `college`.\n\n### The \\_id Attribute and ObjectIds\n\n``` python\nclass PyObjectId(ObjectId):\n    @classmethod\n    def __get_validators__(cls):\n        yield cls.validate\n\n    @classmethod\n    def validate(cls, v):\n        if not ObjectId.is_valid(v):\n            raise ValueError(\"Invalid objectid\")\n        return ObjectId(v)\n\n    @classmethod\n    def __modify_schema__(cls, field_schema):\n        field_schema.update(type=\"string\")\n```\n\nMongoDB stores data as [BSON](https://www.mongodb.com/json-and-bson).  FastAPI encodes and decodes data as JSON strings. BSON has support for additional non-JSON-native data types, including `ObjectId` which can't be directly encoded as JSON. Because of this, we convert `ObjectId`s to strings before storing them as the `_id`.\n\n### Database Models\n\nMany people think of MongoDB as being schema-less, which is wrong.  MongoDB has a flexible schema. That is to say that collections do not enforce document structure by default, so you have the flexibility to make whatever data-modelling choices best match your application and its performance requirements. So, it's not unusual to create models when working with a MongoDB database. Our application has two models, the `StudentModel` and the `UpdateStudentModel`.\n\n``` python\nclass StudentModel(BaseModel):\n    id: PyObjectId = Field(default_factory=PyObjectId, alias=\"_id\")\n    name: str = Field(...)\n    email: EmailStr = Field(...)\n    course: str = Field(...)\n    gpa: float = Field(..., le=4.0)\n\n    class Config:\n        allow_population_by_field_name = True\n        arbitrary_types_allowed = True\n        json_encoders = {ObjectId: str}\n        schema_extra = {\n            \"example\": {\n                \"name\": \"Jane Doe\",\n                \"email\": \"jdoe@example.com\",\n                \"course\": \"Experiments, Science, and Fashion in Nanophotonics\",\n                \"gpa\": \"3.0\",\n            }\n        }\n```\n\nThis is the primary model we use as the [response model](https://fastapi.tiangolo.com/tutorial/response-model/) for the majority of our endpoints.\n\nI want to draw attention to the `id` field on this model. MongoDB uses `_id`, but in Python, underscores at the start of attributes have special meaning. If you have an attribute on your model that starts with an underscore, [pydantic](https://pydantic-docs.helpmanual.io/)—the data validation framework used by FastAPI—will assume that it is a private variable, meaning you will not be able to assign it a value! To get around this, we name the field `id` but give it an alias of `_id`. You also need to set `allow_population_by_field_name` to `True` in the model's `Config` class.\n\nWe set this `id` value automatically to an `ObjectId` string, so you do not need to supply it when creating a new student.\n\n``` python\nclass UpdateStudentModel(BaseModel):\n    name: Optional[str]\n    email: Optional[EmailStr]\n    course: Optional[str]\n    gpa: Optional[float]\n\n    class Config:\n        arbitrary_types_allowed = True\n        json_encoders = {ObjectId: str}\n        schema_extra = {\n            \"example\": {\n                \"name\": \"Jane Doe\",\n                \"email\": \"jdoe@example.com\",\n                \"course\": \"Experiments, Science, and Fashion in Nanophotonics\",\n                \"gpa\": \"3.0\",\n            }\n        }\n```\n\nThe `UpdateStudentModel` has two key differences from the `StudentModel`:\n\n-   It does not have an `id` attribute as this should never change.\n-   All fields are optional, so you only need to supply the fields you wish to update.\n\n### Application Routes\n\nOur application has five routes:\n\n-   POST / - creates a new student.\n-   GET / - view a list of all students.\n-   GET /{id} - view a single student.\n-   PUT /{id} - update a student.\n-   DELETE /{id} - delete a student.\n\n#### Create Student Route\n\n``` python\n@app.post(\"/\", response_description=\"Add new student\", response_model=StudentModel)\nasync def create_student(student: StudentModel = Body(...)):\n    student = jsonable_encoder(student)\n    new_student = await db[\"students\"].insert_one(student)\n    created_student = await db[\"students\"].find_one({\"_id\": new_student.inserted_id})\n    return JSONResponse(status_code=status.HTTP_201_CREATED, content=created_student)\n```\n\nThe `create_student` route receives the new student data as a JSON string in a `POST` request. We have to decode this JSON request body into a Python dictionary before passing it to our MongoDB client.\n\nThe `insert_one` method response includes the `_id` of the newly created student. After we insert the student into our collection, we use the `inserted_id` to find the correct document and return this in our `JSONResponse`.\n\nFastAPI returns an HTTP `200` status code by default; but in this instance, a `201` created is more appropriate.\n\n##### Read Routes\n\nThe application has two read routes: one for viewing all students and the other for viewing an individual student.\n\n``` python\n@app.get(\n    \"/\", response_description=\"List all students\", response_model=List[StudentModel]\n)\nasync def list_students():\n    students = await db[\"students\"].find().to_list(1000)\n    return students\n```\n\nMotor's `to_list` method requires a max document count argument. For this example, I have hardcoded it to `1000`; but in a real application, you would use the [skip and limit parameters](https://pymongo.readthedocs.io/en/3.11.0/api/pymongo/collection.html#pymongo.collection.Collection.find) in `find` to paginate your results.\n\n``` python\n@app.get(\n    \"/{id}\", response_description=\"Get a single student\", response_model=StudentModel\n)\nasync def show_student(id: str):\n    if (student := await db[\"students\"].find_one({\"_id\": id})) is not None:\n        return student\n\n    raise HTTPException(status_code=404, detail=f\"Student {id} not found\")\n```\n\nThe student detail route has a path parameter of `id`, which FastAPI passes as an argument to the `show_student` function. We use the `id` to attempt to find the corresponding student in the database. The conditional in this section is using an [assignment expression](https://www.python.org/dev/peps/pep-0572/), a recent addition to Python (introduced in version 3.8) and often referred to by the incredibly cute sobriquet \"walrus operator.\"\n\nIf a document with the specified `id` does not exist, we raise an `HTTPException` with a status of `404`.\n\n##### Update Route\n\n``` python\n@app.put(\"/{id}\", response_description=\"Update a student\", response_model=StudentModel)\nasync def update_student(id: str, student: UpdateStudentModel = Body(...)):\n    student = {k: v for k, v in student.dict().items() if v is not None}\n\n    if len(student) >= 1:\n        update_result = await db[\"students\"].update_one({\"_id\": id}, {\"$set\": student})\n\n        if update_result.modified_count == 1:\n            if (\n                updated_student := await db[\"students\"].find_one({\"_id\": id})\n            ) is not None:\n                return updated_student\n\n    if (existing_student := await db[\"students\"].find_one({\"_id\": id})) is not None:\n        return existing_student\n\n    raise HTTPException(status_code=404, detail=f\"Student {id} not found\")\n```\n\nThe `update_student` route is like a combination of the `create_student` and the `show_student` routes. It receives the `id` of the document to update as well as the new data in the JSON body. We don't want to update any fields with empty values; so, first of all, we iterate over all the items in the received dictionary and only add the items that have a value to our new document.\n\nIf, after we remove the empty values, there are no fields left to update, we instead look for an existing record that matches the `id` and return that unaltered. However, if there are values to update, we use [update_one](https://motor.readthedocs.io/en/stable/api-asyncio/asyncio_motor_collection.html#motor.motor_asyncio.AsyncIOMotorCollection.update_one) to [$set](https://docs.mongodb.com/manual/reference/operator/update/set/) the new values, and then return the updated document.\n\nBut if we get to the end of the function and we have not been able to find a matching document to update or return, then we raise a `404` error again.\n\n##### Delete Route\n\n``` python\n@app.delete(\"/{id}\", response_description=\"Delete a student\")\nasync def delete_student(id: str):\n    delete_result = await db[\"students\"].delete_one({\"_id\": id})\n\n    if delete_result.deleted_count == 1:\n        return JSONResponse(status_code=status.HTTP_204_NO_CONTENT)\n\n    raise HTTPException(status_code=404, detail=f\"Student {id} not found\")\n```\n\nOur final route is `delete_student`. Again, because this is acting upon a single document, we have to supply an `id` in the URL. If we find a matching document and successfully delete it, then we return an HTTP status of `204` or \"No Content.\" In this case, we do not return a document as we've already deleted it! However, if we cannot find a student with the specified `id`, then instead we return a `404`.\n\n## Wrapping Up\n\nI hope you have found this introduction to FastAPI with MongoDB useful.  If you would like to learn more, check out my post [introducing the FARM stack (FastAPI, React and MongoDB)](https://developer.mongodb.com/how-to/FARM-Stack-FastAPI-React-MongoDB) as well as the [FastAPI documentation](https://motor.readthedocs.io) and this [awesome list](https://github.com/mjhea0/awesome-fastapi).\n\n>If you have questions, please head to our [developer community website](https://community.mongodb.com/) where the MongoDB engineers and the MongoDB community will help you build your next big idea with MongoDB.","originalPublishDate":"2022-02-05T15:53:35.751Z","SEO":"61b7fc19e454ca0b0d5282c8","related_content":[],"createdAt":"2021-12-14T02:06:17.210Z","originalUpdatedAt":"2022-02-05T15:53:35.831Z","image":{"_id":"627d26898891f3001d997e91","name":"*Python Banner_1280x720.png","alternativeText":"","caption":"","hash":"Python_Banner_1280x720_ab74d31ebe","ext":".png","mime":"image/png","size":34.26,"width":1280,"height":720,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/Python_Banner_1280x720_ab74d31ebe.png","formats":{"thumbnail":{"name":"*thumbnail_Python Banner_1280x720.png","hash":"thumbnail_Python_Banner_1280x720_ab74d31ebe","ext":".png","mime":"image/png","width":245,"height":138,"size":11.99,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/thumbnail_Python_Banner_1280x720_ab74d31ebe.png"},"large":{"name":"*large_Python Banner_1280x720.png","hash":"large_Python_Banner_1280x720_ab74d31ebe","ext":".png","mime":"image/png","width":1000,"height":563,"size":67.91,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/large_Python_Banner_1280x720_ab74d31ebe.png"},"medium":{"name":"*medium_Python Banner_1280x720.png","hash":"medium_Python_Banner_1280x720_ab74d31ebe","ext":".png","mime":"image/png","width":750,"height":422,"size":45.36,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/medium_Python_Banner_1280x720_ab74d31ebe.png"},"small":{"name":"*small_Python Banner_1280x720.png","hash":"small_Python_Banner_1280x720_ab74d31ebe","ext":".png","mime":"image/png","width":500,"height":281,"size":27.36,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/small_Python_Banner_1280x720_ab74d31ebe.png"}},"provider":"aws-s3","related":["6244b4fd7a304f0ca6c4d9cd","6244b4fd7a304f0ca6c4d9ce","6244b4fd7a304f0ca6c4da4f","6244b4fd7a304f0ca6c4d9ef","6244b4fd7a304f0ca6c4da01","6244b4fd7a304f0ca6c4d98e","6244b4fd7a304f0ca6c4d9c0","6244b4fd7a304f0ca6c4d9c1","6244b4fd7a304f0ca6c4d9c2","6244b4fd7a304f0ca6c4d9c3","6244b4fd7a304f0ca6c4d9c4","6244b4fd7a304f0ca6c4d9c7","6244b4fd7a304f0ca6c4d9c5","6244b4fd7a304f0ca6c4d9c6","6244b4fd7a304f0ca6c4d9c8"],"createdAt":"2022-05-12T15:23:53.601Z","updatedAt":"2022-05-12T17:03:04.614Z","__v":0,"created_by":"60acfb196a6d99001c58c549","updated_by":"60acfb196a6d99001c58c549","id":"627d26898891f3001d997e91"},"updated_by":"62bc6e657fbd69001dfd486e","description":"Getting started with MongoDB and FastAPI","__v":3,"other_tags":[{"__component":"other-tag-info.other-tag-info","id":"62585d124a0541001d38141c"}],"primary_tag":[{"__component":"primary-tag-info.programming-language","id":"62585d124a0541001d38141a"}],"updatedAt":"2022-09-23T13:35:45.719Z","calculated_slug":"/languages/python/python-quickstart-fastapi","published_at":"2022-05-10T20:11:38.817Z","expiry_date":"2022-12-14T02:06:17.210Z","id":"6244b4fd7a304f0ca6c4d9c4"}],"podcasts":[],"videos":[],"events":[],"_id":"62b3486013e171001ca58ed2","__v":0,"programming_language":{"_id":"62471b14ce7cde001ccae8f2","name":"*Python","published_at":"2022-05-09T18:49:11.726Z","createdAt":"2022-04-01T15:32:36.560Z","updatedAt":"2022-06-11T11:55:53.999Z","__v":0,"created_by":"61f82d1bdf707f001cad52ff","updated_by":"61f82d1bdf707f001cad52ff","calculated_slug":"/languages/python","description":"A high-level, interpreted programming language and it is used for general purpose. Python is one of the most popular languages for data-intensive tasks and data science because of its rich library support for statistics, machine learning, and AI-related tasks.","icon":{"_id":"62795f15413697001c652b39","name":"*python.svg","alternativeText":"","caption":"","hash":"python_9a4237db11","ext":".svg","mime":"image/svg+xml","size":2.54,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/python_9a4237db11.svg","provider":"aws-s3","width":42,"height":51,"related":["62471b14ce7cde001ccae8f2"],"createdAt":"2022-05-09T18:36:05.704Z","updatedAt":"2022-05-09T19:32:41.893Z","__v":0,"created_by":"60acfb196a6d99001c58c549","updated_by":"60acfb196a6d99001c58c549","id":"62795f15413697001c652b39"},"documentation_link":"https://www.mongodb.com/docs/drivers/python/","id":"62471b14ce7cde001ccae8f2"},"id":"62b3486013e171001ca58ed2"},{"__component":"featured-category.content-type","articles":[{"awaiting_editorial_review":false,"awaiting_technical_review":false,"editorial_review_LGTM":false,"technical_review_LGTM":false,"authors":["61969cc0a0957d40b0be6803"],"_id":"62a4998e3790de001c896d8c","published_at":"2022-06-11T13:39:38.923Z","content":"## Description of Application\nA quick and easy example application project that creates a demo blog post engine. Very simple UI, ideal for beginners to Rust programming langauge.\n\n##  Technology Stack\nThis code example utilizes the following technologies:\n\n* MongoDB Atlas\n* Rust\n* Rocket.rs framework\n\n","slug":"/rust-mongodb-blog-project","description":"A beginner level project using MongoDB with Rust","name":"*Beginner Coding Project: Build a Blog Engine with Rust and MongoDB","SEO":"62a49aa23790de001c896d92","related_content":[],"primary_tag":[{"__component":"primary-tag-info.programming-language","id":"62a4998e3790de001c896d8d"}],"other_tags":[{"__component":"other-tag-info.other-tag-info","id":"62a4998e3790de001c896d8f"}],"createdAt":"2022-06-11T13:33:02.007Z","updatedAt":"2022-06-11T13:48:56.763Z","__v":2,"created_by":"61f82d1bdf707f001cad52ff","updated_by":"61f82d1bdf707f001cad52ff","calculated_slug":"/code-examples/rust/rust-mongodb-blog-project","image":{"_id":"62a49d443790de001c896da2","name":"*Rust_programming_language_black_logo.svg.png","alternativeText":"","caption":"","hash":"Rust_programming_language_black_logo_svg_c55a575573","ext":".png","mime":"image/png","size":76,"width":2048,"height":2048,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/Rust_programming_language_black_logo_svg_c55a575573.png","formats":{"thumbnail":{"name":"*thumbnail_Rust_programming_language_black_logo.svg.png","hash":"thumbnail_Rust_programming_language_black_logo_svg_c55a575573","ext":".png","mime":"image/png","width":156,"height":156,"size":7.96,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/thumbnail_Rust_programming_language_black_logo_svg_c55a575573.png"},"large":{"name":"*large_Rust_programming_language_black_logo.svg.png","hash":"large_Rust_programming_language_black_logo_svg_c55a575573","ext":".png","mime":"image/png","width":1000,"height":1000,"size":70.45,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/large_Rust_programming_language_black_logo_svg_c55a575573.png"},"medium":{"name":"*medium_Rust_programming_language_black_logo.svg.png","hash":"medium_Rust_programming_language_black_logo_svg_c55a575573","ext":".png","mime":"image/png","width":750,"height":750,"size":48.35,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/medium_Rust_programming_language_black_logo_svg_c55a575573.png"},"small":{"name":"*small_Rust_programming_language_black_logo.svg.png","hash":"small_Rust_programming_language_black_logo_svg_c55a575573","ext":".png","mime":"image/png","width":500,"height":500,"size":29.99,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/small_Rust_programming_language_black_logo_svg_c55a575573.png"}},"provider":"aws-s3","related":["62a4998e3790de001c896d8c"],"createdAt":"2022-06-11T13:48:52.962Z","updatedAt":"2022-06-11T13:48:56.759Z","__v":0,"created_by":"61f82d1bdf707f001cad52ff","updated_by":"61f82d1bdf707f001cad52ff","id":"62a49d443790de001c896da2"},"id":"62a4998e3790de001c896d8c"},{"awaiting_editorial_review":false,"awaiting_technical_review":false,"editorial_review_LGTM":false,"technical_review_LGTM":false,"authors":["61969cc0a0957d40b0be6803"],"_id":"6304daefe50177001c2bf43a","published_at":"2022-08-23T13:49:51.949Z","content":"## Introduction\nBuild your first application with Java and Spring! This simple application demonstrates basic CRUD operations via a book app - you can add a book, edit a book, delete a book. Stores the data in MongoDB database. \n\n\n## Technology\n\n* Java\n* Spring\n* MongoDB\n\n\n","slug":"/spring-java-mongodb-example-app2","description":"Build an application to track the books you've read with Spring, Java, and MongoDB","name":"*Build a Spring Java Book Tracker for Beginners","SEO":null,"related_content":[],"primary_tag":[{"__component":"primary-tag-info.programming-language","id":"6304daefe50177001c2bf43b"}],"other_tags":[{"__component":"other-tag-info.other-tag-info","id":"6304daefe50177001c2bf43d"}],"createdAt":"2022-08-23T13:49:35.932Z","updatedAt":"2022-08-23T13:49:52.035Z","__v":2,"created_by":"61f82d1bdf707f001cad52ff","image":{"_id":"62c022627fbd69001dfd4880","name":"*Java-Emblem.jpeg","alternativeText":"java logo","caption":"","hash":"Java_Emblem_4069eda9a5","ext":".jpeg","mime":"image/jpeg","size":91.34,"width":3840,"height":2400,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/Java_Emblem_4069eda9a5.jpeg","formats":{"thumbnail":{"name":"*thumbnail_Java-Emblem.jpeg","hash":"thumbnail_Java_Emblem_4069eda9a5","ext":".jpeg","mime":"image/jpeg","width":245,"height":153,"size":3.96,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/thumbnail_Java_Emblem_4069eda9a5.jpeg"},"large":{"name":"*large_Java-Emblem.jpeg","hash":"large_Java_Emblem_4069eda9a5","ext":".jpeg","mime":"image/jpeg","width":1000,"height":625,"size":24.39,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/large_Java_Emblem_4069eda9a5.jpeg"},"medium":{"name":"*medium_Java-Emblem.jpeg","hash":"medium_Java_Emblem_4069eda9a5","ext":".jpeg","mime":"image/jpeg","width":750,"height":469,"size":16.93,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/medium_Java_Emblem_4069eda9a5.jpeg"},"small":{"name":"*small_Java-Emblem.jpeg","hash":"small_Java_Emblem_4069eda9a5","ext":".jpeg","mime":"image/jpeg","width":500,"height":313,"size":10.35,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/small_Java_Emblem_4069eda9a5.jpeg"}},"provider":"aws-s3","related":["62c0229d7fbd69001dfd4881","6304daefe50177001c2bf43a"],"createdAt":"2022-07-02T10:48:02.770Z","updatedAt":"2022-08-23T13:49:36.016Z","__v":0,"created_by":"61f82d1bdf707f001cad52ff","updated_by":"61f82d1bdf707f001cad52ff","id":"62c022627fbd69001dfd4880"},"updated_by":"61f82d1bdf707f001cad52ff","calculated_slug":"/code-examples/java/spring-java-mongodb-example-app2","expiry_date":"2023-08-23T13:49:35.932Z","id":"6304daefe50177001c2bf43a"},{"awaiting_editorial_review":false,"awaiting_technical_review":false,"editorial_review_LGTM":false,"technical_review_LGTM":false,"authors":["61969cc0a0957d40b0be6803"],"_id":"62aa683b419fe6001dc9de57","published_at":"2022-06-23T18:42:34.205Z","content":"## Creators\n[Lucas De Oliveira](https://www.linkedin.com/in/lbdeoliveira/), [Chandrish Ambati](https://www.linkedin.com/in/avmchandrish/), and [Anish Mukherjee](https://www.linkedin.com/in/mukherjeeanish/) from University of San Francisco contributed this amazing project.\n\n## Background to the Project\nIn 2018, Spotify organized an Association for Computing Machinery (ACM) [RecSys Challenge](https://www.recsyschallenge.com/2018/) where they posted [a dataset of one million playlists](https://www.aicrowd.com/challenges/spotify-million-playlist-dataset-challenge), challenging participants to recommend a list of 500 songs given a user-created playlist.\n\nAs both music lovers and data scientists, we were naturally drawn to this challenge. Right away, we agreed that combining song embeddings with some nearest-neighbors method for recommendation would likely produce very good results. Importantly, we were curious about how we could  solve  this recommendation task at scale with over [4 billion user-curated playlists](https://soundplate.com/how-many-playlists-are-there-on-spotify-and-other-spotify-stats/) on Spotify, where this number keeps growing. This realization raised serious questions about how to train a decent model since all that data would likely not fit in memory or a single server.\n\n## What We Built\nThis project resulted in a scalable ETL pipeline utilizing\n* Apache Spark\n* MongoDB\n* Amazon S3\n* Databricks (PySpark)\nThese were used to train a deep learning Word2Vec model to build song and playlist embeddings for recommendation. We followed up with data visualizations we created on Tensorflow’s Embedding Projector.\n\n\n## The Process\n### Collecting Lyrics\nThe most tedious task of this project was collecting as many lyrics for the songs in the playlists as possible. We began by isolating the unique songs in the playlist files by their track URI; in total we had over 2 million unique songs. Then, we used the track name and artist name to look up the lyrics on the web. Initially, we used simple Python requests to pull in the lyrical information but this proved too slow for our purposes. We then used asyncio, which allowed us to make requests concurrently. This sped up the process significantly, reducing the downloading time of lyrics for 10k songs from 15 mins to under a minute. Ultimately, we were only able to collect lyrics for 138,000 songs.\n\n### Pre-processing\nThe original dataset contains 1 million playlists spread across 1 thousand JSON files totaling about 33 GB of data. We used PySpark in Databricks to preprocess these separate JSON files into a single SparkSQL DataFrame and then joined this DataFrame with the lyrics we saved. \n\nWhile the aforementioned data collection and preprocessing steps are time-consuming, the model also needs to be re-trained and re-evaluated often, so it is critical to store data in a scalable database. In addition, we’d like to consider a database that is schemaless for future expansion in data sets and supports various data types.  Considering our needs, we concluded that MongoDB would be the optimal solution as a data and feature store.\n\nCheck out the [Preprocessing.ipynb](https://github.com/lbdeoliveira/song-playlist-recommendation/blob/main/notebooks/Preprocessing_Pipeline.ipynb) notebook to see how we preprocessed the data.\n\n### Training Song Embeddings\nFor our analyses, we read our preprocessed data from MongoDB into a Spark DataFrame and grouped the records by playlist id (pid), aggregating all of the songs in a playlist into a list under the column song_list. \nUsing the Word2Vec model in Spark MLlib we trained song embeddings by feeding lists of track IDs from a playlist into the model much like you would send a list of words from a sentence to train word embeddings. As shown below, we trained song embeddings in only 3 lines of PySpark code:\n```\nfrom pyspark.ml.feature import Word2Vec\nword2Vec = Word2Vec(vectorSize=32, seed=42, inputCol=\"song_list\").setMinCount(1)\nword2Vec.sexMaxIter(10)\nmodel = word2Vec.fit(df_play)\n```\n\nWe then saved the song embeddings down to MongoDB for later use. Below is a snapshot of the song embeddings DataFrame that we saved:\n\n![](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/song_embeddings_dataframe_c3fc7a455b.png)\n\nCheck out the [Song_Embeddings.ipynb](https://github.com/lbdeoliveira/song-playlist-recommendation/blob/main/notebooks/Song_Embeddings.ipynb) notebook to see how we train song embeddings.\n\n### Training Playlists Embeddings\nFinally, we extended our recommendation task beyond simple song recommendations to recommending entire playlists. Given an input playlist, we would return the k closest or most similar playlists. We took a “continuous bag of songs” approach to this problem by calculating playlist embeddings as the average of all song embeddings in that playlist.\n\nThis workflow started by reading back the song embeddings from MongoDB into a SparkSQL DataFrame. Then, we calculated a playlist embedding by taking the average of all song embeddings in that playlist and saved them in MongoDB.\n\nCheck out the [Playlist_Embeddings.ipynb](https://github.com/lbdeoliveira/song-playlist-recommendation/blob/main/notebooks/Playlist_Embeddings.ipynb) notebook to see how we did this.\n\n### Training Lyrics Embeddings\nAre you still reading? Whew!\nWe trained lyrics embeddings by loading in a song's lyrics, separating the words into lists, and feeding those words to a Word2Vec model to produce 32-dimensional vectors for each word. We then took the average embedding across all words as that song's lyrical embedding. Ultimately, our analytical goal here was to determine whether users create playlists based on common lyrical themes by seeing if the pairwise song embedding distance and the pairwise lyrical embedding distance between two songs were correlated. Unsurprisingly, it appears they are not.\n\nCheck out the[Lyrical_Embeddings.ipynb](https://github.com/lbdeoliveira/song-playlist-recommendation/blob/main/notebooks/Lyrical_Embeddings.ipynb) notebook to see our analysis.\n\n## Notes on our Approach\nYou may be wondering why we used a language model (Word2Vec) to train these embeddings. Why not use a Pin2Vec or custom neural network model to predict implicit ratings? For practical reasons, we wanted to work exclusively in the Spark ecosystem and deal with the data in a distributed fashion. This was a constraint set on the project ahead of time and challenged us to think creatively.\n\nHowever, we found Word2Vec an attractive candidate model for theoretical reasons as well. The Word2Vec model uses a word’s context to train static embeddings by training the input word’s embeddings to predict its surrounding words. In essence, the embedding of any word is determined by how it co-occurs with other words. This had a clear mapping to our own problem: by using a Word2Vec model the distance between song embeddings would reflect the songs’ co-occurrence throughout 1M playlists, making it a useful measure for a distance-based recommendation (nearest neighbors). It would effectively model how people grouped songs together, using user behavior as the determinant factor in similarity.\n\nAdditionally, the Word2Vec model accepts input in the form of a list of words. For each playlist we had a list of track IDs, which made working with the Word2Vec model not only conceptually but also practically appealing.\n\n## Data Visualizations with Tensorflow and MongoDB\nAfter all of that, we were finally ready to visualize our results and make some interactive recommendations. We decided to represent our embedding results visually using [Tensorflow’s Embedding Projector](https://projector.tensorflow.org) which maps the 32-dimensional song and playlist embeddings into an interactive visualization of a 3D embedding space. You have the choice of using PCA or tSNE for dimensionality reduction and cosine similarity or Euclidean distance for measuring distances between vectors.\n\nClick [here](https://projector.tensorflow.org/?config=https://embedding-projector.s3.us-west-2.amazonaws.com/template_config_2M.json) for the song embeddings projector for the full 2 million songs, or [here](https://projector.tensorflow.org/?config=https://embedding-projector.s3.us-west-2.amazonaws.com/template_config.json) for a less crowded version with a random sample of 100k songs (shown below):\n\n![](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/164569070_88be5d94_a291_495d_b33d_3094634d9205_afc69037e9.gif)\n\nThe neat thing about using Tensorflow’s projector is that it gives us a beautiful visualization tool and distance calculator all in one. Try searching on the right panel for a song and if the song is part of the original dataset, you will see the “most similar” songs appear under it.\n\n## Using MongoDB for ML/AI\nWe were impressed by how easy it was to use MongoDB to reliably store and load our data. Because we were using distributed computing, it would have been infeasible to run our pipeline from start to finish any time we wanted to update our code or fine-tune the model. MongoDB allowed us to save our incremental results for later processing and modeling, which collectively saved us hours of waiting for code to re-run.\n\nIt worked well with all the tools we use everyday and the tooling we chose - we didn't have any areas of friction. \n\nWe were shocked by how this method of training embeddings actually worked. While the 2 million song embedding projector is crowded visually, we see that the recommendations it produces are actually quite good at grouping songs together.\n\nConsider the embedding recommendation for The Beatles’ “A Day In The Life”:\n![](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/165581471_420ad43d_47f9_4aee_bf0c_2de6ac301144_c656a07f0e.gif)\n\nOr the recommendation for Jay Z’s “Heart of the City (Ain’t No Love)”:\n![](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/164567916_28f6ebd6_0473_4d7b_b60c_55af628016f7_ec16751581.png)\n\nFan of Taylor Swift? Here are the recommendations for “New Romantics”:\n![](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/164567889_9ccf8326_7bc8_4c8e_9bc6_f123c0acba3f_0fab2ea1db.png)\n\nWe were delighted to find naturally occurring clusters in the playlist embeddings. Most notably, we see a cluster containing mostly Christian rock, one with Christmas music, one for reggaeton, and one large cluster where genres span its length rather continuously and intuitively.\n\nNote also that when we select a playlist, we have many recommended playlists with the same names. This in essence validates our song embeddings. Recall that playlist embeddings were created by taking the average embedding of all its songs; the name of the playlists did not factor in at all. The similar names only conceptually reinforce this fact.\n\n\n\n## Next Steps?\nWe felt happy with the conclusion of this project but there is more that could be done here.\n\n1. We could use these trained song embeddings in other downstream tasks and see how effective these are. Also, you could download the song embeddings we here: [Embeddings](https://embedding-projector.s3.us-west-2.amazonaws.com/emb_word2vec_2M.tsv) | [Meta Info](https://embedding-projector.s3.us-west-2.amazonaws.com/meta_word2vec_2M.tsv)\n2. We could look at other methods of training these embeddings using some recurrent neural networks and enhanced implementation of this Word2Vec model.\n\n\n\n","name":"*A Spotify Song and Playlist Recommendation Engine","SEO":null,"related_content":[],"primary_tag":[{"__component":"primary-tag-info.programming-language","id":"62aa683b419fe6001dc9de58"}],"other_tags":[{"__component":"other-tag-info.other-tag-info","id":"62aa683b419fe6001dc9de5a"}],"createdAt":"2022-06-15T23:16:11.745Z","updatedAt":"2022-07-13T08:19:11.020Z","__v":2,"created_by":"61f82d1bdf707f001cad52ff","updated_by":"5ff608bdd9de35072ceceaf8","calculated_slug":"/code-examples/python/song-recommendations-example-app","slug":"/song-recommendations-example-app","description":"Python code example application for Spotify playlist and song recommendations using spark and tensorflow","image":{"_id":"62b4b40c13e171001ca58f0e","name":"*165581471-420ad43d-47f9-4aee-bf0c-2de6ac301144.gif","alternativeText":"","caption":"","hash":"165581471_420ad43d_47f9_4aee_bf0c_2de6ac301144_17b45ae96b","ext":".gif","mime":"image/gif","size":10470.32,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/165581471_420ad43d_47f9_4aee_bf0c_2de6ac301144_17b45ae96b.gif","provider":"aws-s3","width":520,"height":320,"related":["62aa683b419fe6001dc9de57"],"createdAt":"2022-06-23T18:42:20.954Z","updatedAt":"2022-06-23T18:42:25.830Z","__v":0,"created_by":"61f82d1bdf707f001cad52ff","updated_by":"61f82d1bdf707f001cad52ff","id":"62b4b40c13e171001ca58f0e"},"expiry_date":"2023-06-15T23:16:11.745Z","id":"62aa683b419fe6001dc9de57"}],"podcasts":[],"videos":[],"events":[],"_id":"62b34a6613e171001ca58ed4","__v":0,"content_type":{"_id":"624af026ce7cde001ccae941","content_type":"Code Example","published_at":"2022-05-09T18:36:16.758Z","createdAt":"2022-04-04T13:18:30.522Z","updatedAt":"2022-05-09T18:36:16.815Z","__v":0,"created_by":"61f82d1bdf707f001cad52ff","updated_by":"61f82d1bdf707f001cad52ff","calculated_slug":"/code-examples","id":"624af026ce7cde001ccae941"},"id":"62b34a6613e171001ca58ed4"},{"__component":"featured-category.programming-language","articles":[{"awaiting_editorial_review":false,"awaiting_technical_review":false,"editorial_review_LGTM":true,"technical_review_LGTM":true,"authors":["61606665a21c93001c3c7e87"],"_id":"6244b4fd7a304f0ca6c4d9af","type":"Quickstart","name":"*Java - Aggregation Pipeline","slug":"/java-aggregation-pipeline","content":"## Updates\n\nThe MongoDB Java quickstart repository is [available on Github](https://github.com/mongodb-developer/java-quick-start).\n\n### March 25th, 2021\n\n-   Update Java Driver to 4.2.2.\n-   Added Client Side Field Level Encryption example.\n\n### October 21th, 2020\n\n-   Update Java Driver to 4.1.1.\n-   The Java Driver logging is now enabled via the popular [SLF4J](http://www.slf4j.org/) API so I added logback in the `pom.xml` and a configuration file `logback.xml`.\n\n## What's the Aggregation Pipeline?\n\n<div>\n    <img style=\"float: right;\n        border-radius: 10px;\n        margin-bottom: 30px;\n        vertical-align: bottom;\n        width: 30%;\"\n        src=\"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/old_images/qs-badges/qs-badge-java.png\" alt=\"Java badge\" />\n\nThe [aggregation pipeline](https://docs.mongodb.com/manual/core/aggregation-pipeline/) is a framework for data aggregation modeled on the concept of data processing pipelines, just like the \"pipe\" in the Linux Shell. Documents enter a multi-stage pipeline that transforms the documents into aggregated results.\n</div>\n\nIt's the most powerful way to work with your data in MongoDB. It will allow us to make advanced queries like grouping documents, manipulate arrays, reshape document models, etc.\n\nLet's see how we can harvest this power using Java.\n\n## Getting Set Up\n\nI will use the same repository as usual in this series. If you don't have a copy of it yet, you can clone it or just update it if you already have it:\n\n``` sh\ngit clone https://github.com/mongodb-developer/java-quick-start\n```\n\n>If you didn't set up your free cluster on MongoDB Atlas, now is great time to do so. You have all the instructions in this [blog post](/quickstart/free-atlas-cluster/).\n\n## First Example with Zips\n\nIn the [MongoDB Sample Dataset](https://docs.atlas.mongodb.com/sample-data/available-sample-datasets/) in [MongoDB Atlas](https://www.mongodb.com/cloud/atlas/), let's explore a bit the `zips` collection in the `sample_training` database.\n\n``` javascript\nMongoDB Enterprise Cluster0-shard-0:PRIMARY> db.zips.find({city:\"NEW YORK\"}).limit(2).pretty()\n{\n    \"_id\" : ObjectId(\"5c8eccc1caa187d17ca72f8a\"),\n    \"city\" : \"NEW YORK\",\n    \"zip\" : \"10001\",\n    \"loc\" : {\n        \"y\" : 40.74838,\n        \"x\" : 73.996705\n    },\n    \"pop\" : 18913,\n    \"state\" : \"NY\"\n}\n{\n    \"_id\" : ObjectId(\"5c8eccc1caa187d17ca72f8b\"),\n    \"city\" : \"NEW YORK\",\n    \"zip\" : \"10003\",\n    \"loc\" : {\n        \"y\" : 40.731253,\n        \"x\" : 73.989223\n    },\n    \"pop\" : 51224,\n    \"state\" : \"NY\"\n}\n```\n\nAs you can see, we have one document for each zip code in the USA and for each, we have the associated population.\n\nTo calculate the population of New York, I would have to sum the population of each zip code to get the population of the entire city.\n\nLet's try to find the 3 biggest cities in the state of Texas. Let's design this on paper first.\n\n-   I don't need to work with the entire collection. I need to filter only the cities in Texas.\n-   Once this is done, I can regroup all the zip code from a same city together to get the total population.\n-   Then I can order my cities by descending order or population.\n-   Finally I can keep the first 3 cities of my list.\n\nThe easiest way to build this pipeline in MongoDB is to use the [aggregation pipeline builder](https://docs.mongodb.com/compass/master/aggregation-pipeline-builder/) that is available in [MongoDB Compass](https://www.mongodb.com/products/compass) or in [MongoDB Atlas](https://www.mongodb.com/cloud/atlas/) in the `Collections` tab.\n\nOnce this is done, you can [export your pipeline to Java](https://docs.mongodb.com/compass/master/export-pipeline-to-language/) using the export button.\n\nAfter a little code refactoring, here is what I have:\n\n``` java\n/**\n * find the 3 most densely populated cities in Texas.\n * @param zips sample_training.zips collection from the MongoDB Sample Dataset in MongoDB Atlas.\n */\nprivate static void threeMostPopulatedCitiesInTexas(MongoCollection<Document> zips) {\n    Bson match = match(eq(\"state\", \"TX\"));\n    Bson group = group(\"$city\", sum(\"totalPop\", \"$pop\"));\n    Bson project = project(fields(excludeId(), include(\"totalPop\"), computed(\"city\", \"$_id\")));\n    Bson sort = sort(descending(\"totalPop\"));\n    Bson limit = limit(3);\n\n    List<Document> results = zips.aggregate(Arrays.asList(match, group, project, sort, limit))\n                                 .into(new ArrayList<>());\n    System.out.println(\"==> 3 most densely populated cities in Texas\");\n    results.forEach(printDocuments());\n}\n```\n\nThe MongoDB driver provides a lot of helpers to make the code easy to write and to read.\n\nAs you can see, I solved this problem with:\n\n-   A [$match stage](https://docs.mongodb.com/manual/reference/operator/aggregation/match/) to filter my documents and keep only the zip code in Texas,\n-   A [$group stage](https://docs.mongodb.com/manual/reference/operator/aggregation/group/) to regroup my zip codes in cities,\n-   A [$project stage](https://docs.mongodb.com/manual/reference/operator/aggregation/project/) to rename the field `_id` in `city` for a clean output (not mandatory but I'm classy),\n-   A [$sort stage](https://docs.mongodb.com/manual/reference/operator/aggregation/sort/) to sort by population descending,\n-   A [$limit stage](https://docs.mongodb.com/manual/reference/operator/aggregation/limit/) to keep only the 3 most populated cities.\n\nHere is the output we get:\n\n``` json\n==> 3 most densely populated cities in Texas\n{\n  \"totalPop\": 2095918,\n  \"city\": \"HOUSTON\"\n}\n{\n  \"totalPop\": 940191,\n  \"city\": \"DALLAS\"\n}\n{\n  \"totalPop\": 811792,\n  \"city\": \"SAN ANTONIO\"\n}\n```\n\nIn MongoDB 4.2, there are 30 different aggregation pipeline stages that you can use to manipulate your documents. If you want to know more, I encourage you to follow this course on MongoDB University: [M121: The MongoDB Aggregation Framework](https://university.mongodb.com/courses/M121/about).\n\n## Second Example with Posts\n\nThis time, I'm using the collection `posts` in the same database.\n\n``` json\nMongoDB Enterprise Cluster0-shard-0:PRIMARY> db.posts.findOne()\n{\n    \"_id\" : ObjectId(\"50ab0f8bbcf1bfe2536dc3f9\"),\n    \"body\" : \"Amendment I\\n<p>Congress shall make no law respecting an establishment of religion, or prohibiting the free exercise thereof; or abridging the freedom of speech, or of the press; or the right of the people peaceably to assemble, and to petition the Government for a redress of grievances.\\n<p>\\nAmendment II\\n<p>\\nA well regulated Militia, being necessary to the security of a free State, the right of the people to keep and bear Arms, shall not be infringed.\\n<p>\\nAmendment III\\n<p>\\nNo Soldier shall, in time of peace be quartered in any house, without the consent of the Owner, nor in time of war, but in a manner to be prescribed by law.\\n<p>\\nAmendment IV\\n<p>\\nThe right of the people to be secure in their persons, houses, papers, and effects, against unreasonable searches and seizures, shall not be violated, and no Warrants shall issue, but upon probable cause, supported by Oath or affirmation, and particularly describing the place to be searched, and the persons or things to be seized.\\n<p>\\nAmendment V\\n<p>\\nNo person shall be held to answer for a capital, or otherwise infamous crime, unless on a presentment or indictment of a Grand Jury, except in cases arising in the land or naval forces, or in the Militia, when in actual service in time of War or public danger; nor shall any person be subject for the same offence to be twice put in jeopardy of life or limb; nor shall be compelled in any criminal case to be a witness against himself, nor be deprived of life, liberty, or property, without due process of law; nor shall private property be taken for public use, without just compensation.\\n<p>\\n\\nAmendment VI\\n<p>\\nIn all criminal prosecutions, the accused shall enjoy the right to a speedy and public trial, by an impartial jury of the State and district wherein the crime shall have been committed, which district shall have been previously ascertained by law, and to be informed of the nature and cause of the accusation; to be confronted with the witnesses against him; to have compulsory process for obtaining witnesses in his favor, and to have the Assistance of Counsel for his defence.\\n<p>\\nAmendment VII\\n<p>\\nIn Suits at common law, where the value in controversy shall exceed twenty dollars, the right of trial by jury shall be preserved, and no fact tried by a jury, shall be otherwise re-examined in any Court of the United States, than according to the rules of the common law.\\n<p>\\nAmendment VIII\\n<p>\\nExcessive bail shall not be required, nor excessive fines imposed, nor cruel and unusual punishments inflicted.\\n<p>\\nAmendment IX\\n<p>\\nThe enumeration in the Constitution, of certain rights, shall not be construed to deny or disparage others retained by the people.\\n<p>\\nAmendment X\\n<p>\\nThe powers not delegated to the United States by the Constitution, nor prohibited by it to the States, are reserved to the States respectively, or to the people.\\\"\\n<p>\\n\",\n    \"permalink\" : \"aRjNnLZkJkTyspAIoRGe\",\n    \"author\" : \"machine\",\n    \"title\" : \"Bill of Rights\",\n    \"tags\" : [\n        \"watchmaker\",\n        \"santa\",\n        \"xylophone\",\n        \"math\",\n        \"handsaw\",\n        \"dream\",\n        \"undershirt\",\n        \"dolphin\",\n        \"tanker\",\n        \"action\"\n    ],\n    \"comments\" : [\n        {\n            \"body\" : \"Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum\",\n            \"email\" : \"HvizfYVx@pKvLaagH.com\",\n            \"author\" : \"Santiago Dollins\"\n        },\n        {\n            \"body\" : \"Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum\",\n            \"email\" : \"glbeRCMi@KwnNwhzl.com\",\n            \"author\" : \"Omar Bowdoin\"\n        }\n    ],\n    \"date\" : ISODate(\"2012-11-20T05:05:15.231Z\")\n}\n```\n\nThis collection of 500 posts has been generated artificially but it contains arrays and I want to show you how we can manipulate arrays in a pipeline.\n\nLet's try to find the three most popular tags and for each tag, I also want the list of post titles they are tagging.\n\nHere is my solution in Java.\n\n``` java\n/**\n * find the 3 most popular tags and their post titles\n * @param posts sample_training.posts collection from the MongoDB Sample Dataset in MongoDB Atlas.\n */\nprivate static void threeMostPopularTags(MongoCollection<Document> posts) {\n    Bson unwind = unwind(\"$tags\");\n    Bson group = group(\"$tags\", sum(\"count\", 1L), push(\"titles\", \"$title\"));\n    Bson sort = sort(descending(\"count\"));\n    Bson limit = limit(3);\n    Bson project = project(fields(excludeId(), computed(\"tag\", \"$_id\"), include(\"count\", \"titles\")));\n    List<Document> results = posts.aggregate(Arrays.asList(unwind, group, sort, limit, project)).into(new ArrayList<>());\n    System.out.println(\"==> 3 most popular tags and their posts titles\");\n    results.forEach(printDocuments());\n}\n```\n\nHere I'm using the very useful [$unwind stage](https://docs.mongodb.com/manual/reference/operator/aggregation/unwind/) to break down my array of tags.\n\nIt allows me in the following $group stage to group my tags, count the posts and collect the titles in a new array `titles`.\n\nHere is the final output I get.\n\n``` json\n==> 3 most popular tags and their posts titles\n{\n  \"count\": 8,\n  \"titles\": [\n    \"Gettysburg Address\",\n    \"US Constitution\",\n    \"Bill of Rights\",\n    \"Gettysburg Address\",\n    \"Gettysburg Address\",\n    \"Declaration of Independence\",\n    \"Bill of Rights\",\n    \"Declaration of Independence\"\n  ],\n  \"tag\": \"toad\"\n}\n{\n  \"count\": 8,\n  \"titles\": [\n    \"Bill of Rights\",\n    \"Gettysburg Address\",\n    \"Bill of Rights\",\n    \"Bill of Rights\",\n    \"Declaration of Independence\",\n    \"Declaration of Independence\",\n    \"Bill of Rights\",\n    \"US Constitution\"\n  ],\n  \"tag\": \"forest\"\n}\n{\n  \"count\": 8,\n  \"titles\": [\n    \"Bill of Rights\",\n    \"Declaration of Independence\",\n    \"Declaration of Independence\",\n    \"Gettysburg Address\",\n    \"US Constitution\",\n    \"Bill of Rights\",\n    \"US Constitution\",\n    \"US Constitution\"\n  ],\n  \"tag\": \"hair\"\n}\n```\n\nAs you can see, some titles are repeated. As I said earlier, the collection was generated so the post titles are not uniq. I could solve this \"problem\" by using the [$addToSet operator](https://docs.mongodb.com/manual/reference/operator/aggregation/addToSet/index.html) instead of the [$push](https://docs.mongodb.com/manual/reference/operator/aggregation/push/) one if this was really an issue.\n\n## Final Code\n\n``` java\npackage com.mongodb.quickstart;\n\nimport com.mongodb.client.MongoClient;\nimport com.mongodb.client.MongoClients;\nimport com.mongodb.client.MongoCollection;\nimport com.mongodb.client.MongoDatabase;\nimport org.bson.Document;\nimport org.bson.conversions.Bson;\nimport org.bson.json.JsonWriterSettings;\n\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.function.Consumer;\n\nimport static com.mongodb.client.model.Accumulators.push;\nimport static com.mongodb.client.model.Accumulators.sum;\nimport static com.mongodb.client.model.Aggregates.*;\nimport static com.mongodb.client.model.Filters.eq;\nimport static com.mongodb.client.model.Projections.*;\nimport static com.mongodb.client.model.Sorts.descending;\n\npublic class AggregationFramework {\n\n    public static void main(String[] args) {\n        String connectionString = System.getProperty(\"mongodb.uri\");\n        try (MongoClient mongoClient = MongoClients.create(connectionString)) {\n            MongoDatabase db = mongoClient.getDatabase(\"sample_training\");\n            MongoCollection<Document> zips = db.getCollection(\"zips\");\n            MongoCollection<Document> posts = db.getCollection(\"posts\");\n            threeMostPopulatedCitiesInTexas(zips);\n            threeMostPopularTags(posts);\n        }\n    }\n\n    /**\n     * find the 3 most densely populated cities in Texas.\n     * @param zips sample_training.zips collection from the MongoDB Sample Dataset in MongoDB Atlas.\n     */\n    private static void threeMostPopulatedCitiesInTexas(MongoCollection<Document> zips) {\n        Bson match = match(eq(\"state\", \"TX\"));\n        Bson group = group(\"$city\", sum(\"totalPop\", \"$pop\"));\n        Bson project = project(fields(excludeId(), include(\"totalPop\"), computed(\"city\", \"$_id\")));\n        Bson sort = sort(descending(\"totalPop\"));\n        Bson limit = limit(3);\n\n        List<Document> results = zips.aggregate(Arrays.asList(match, group, project, sort, limit))\n                                     .into(new ArrayList<>());\n        System.out.println(\"==> 3 most densely populated cities in Texas\");\n        results.forEach(printDocuments());\n    }\n\n    /**\n     * find the 3 most popular tags and their post titles\n     * @param posts sample_training.posts collection from the MongoDB Sample Dataset in MongoDB Atlas.\n     */\n    private static void threeMostPopularTags(MongoCollection<Document> posts) {\n        Bson unwind = unwind(\"$tags\");\n        Bson group = group(\"$tags\", sum(\"count\", 1L), push(\"titles\", \"$title\"));\n        Bson sort = sort(descending(\"count\"));\n        Bson limit = limit(3);\n        Bson project = project(fields(excludeId(), computed(\"tag\", \"$_id\"), include(\"count\", \"titles\")));\n\n        List<Document> results = posts.aggregate(Arrays.asList(unwind, group, sort, limit, project)).into(new ArrayList<>());\n        System.out.println(\"==> 3 most popular tags and their posts titles\");\n        results.forEach(printDocuments());\n    }\n\n    private static Consumer<Document> printDocuments() {\n        return doc -> System.out.println(doc.toJson(JsonWriterSettings.builder().indent(true).build()));\n    }\n}\n```\n\n## Wrapping Up\n\nThe aggregation pipeline is very powerful. We have just scratched the surface with these two examples but trust me if I tell you that it's your best ally if you can master it.\n\n>I encourage you to follow the [M121 course on MongoDB University](https://university.mongodb.com/courses/M121/about) to become an aggregation pipeline jedi.\n>\n>If you want to learn more and deepen your knowledge faster, I recommend you check out the M220J: MongoDB for Java Developers training available for free on [MongoDB University](https://university.mongodb.com/).\n\nIn the next blog post, I will explain to you the [Change Streams](https://docs.mongodb.com/manual/changeStreams/) in Java.","originalPublishDate":"2022-02-01T18:03:01.322Z","SEO":"61b7fb5de454ca0b0d528161","related_content":[],"createdAt":"2021-12-14T02:03:09.513Z","originalUpdatedAt":"2022-02-01T18:03:01.358Z","image":{"_id":"627d17de8891f3001d997e5d","name":"*Java Banner_1280x720.png","alternativeText":"","caption":"","hash":"Java_Banner_1280x720_f64f523556","ext":".png","mime":"image/png","size":26.78,"width":1280,"height":720,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/Java_Banner_1280x720_f64f523556.png","formats":{"thumbnail":{"name":"*thumbnail_Java Banner_1280x720.png","hash":"thumbnail_Java_Banner_1280x720_f64f523556","ext":".png","mime":"image/png","width":245,"height":138,"size":10.43,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/thumbnail_Java_Banner_1280x720_f64f523556.png"},"large":{"name":"*large_Java Banner_1280x720.png","hash":"large_Java_Banner_1280x720_f64f523556","ext":".png","mime":"image/png","width":1000,"height":563,"size":60.7,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/large_Java_Banner_1280x720_f64f523556.png"},"medium":{"name":"*medium_Java Banner_1280x720.png","hash":"medium_Java_Banner_1280x720_f64f523556","ext":".png","mime":"image/png","width":750,"height":422,"size":41.4,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/medium_Java_Banner_1280x720_f64f523556.png"},"small":{"name":"*small_Java Banner_1280x720.png","hash":"small_Java_Banner_1280x720_f64f523556","ext":".png","mime":"image/png","width":500,"height":281,"size":24.22,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/small_Java_Banner_1280x720_f64f523556.png"}},"provider":"aws-s3","related":["6244b4fd7a304f0ca6c4d9af","6244b4fd7a304f0ca6c4d9b2","6244b4fd7a304f0ca6c4d9b3","6244b4fd7a304f0ca6c4d9b1"],"createdAt":"2022-05-12T14:21:18.948Z","updatedAt":"2022-05-12T15:48:02.291Z","__v":0,"created_by":"60acfb196a6d99001c58c549","updated_by":"60acfb196a6d99001c58c549","id":"627d17de8891f3001d997e5d"},"updated_by":"62bc6e657fbd69001dfd486e","description":"Learn how to use the Aggregation Pipeline using the MongoDB Java Driver.","__v":3,"other_tags":[{"__component":"other-tag-info.other-tag-info","id":"625847344a0541001d38133c"}],"primary_tag":[{"__component":"primary-tag-info.programming-language","id":"625847344a0541001d38133a"}],"updatedAt":"2023-01-26T16:56:03.124Z","calculated_slug":"/languages/java/java-aggregation-pipeline","published_at":"2022-05-10T20:59:41.827Z","expiry_date":"2022-12-14T02:03:09.513Z","id":"6244b4fd7a304f0ca6c4d9af"},{"awaiting_editorial_review":false,"awaiting_technical_review":false,"editorial_review_LGTM":true,"technical_review_LGTM":true,"authors":["61606665a21c93001c3c7e87"],"_id":"6244b4fd7a304f0ca6c4d9b3","type":"Quickstart","name":"*Getting Started with MongoDB and Java - CRUD Operations Tutorial","slug":"/java-setup-crud-operations","content":"## Updates\n\nThe MongoDB Java quickstart repository is [available on Github](https://github.com/mongodb-developer/java-quick-start).\n\n### March 25th, 2021\n\n-   Update Java Driver to 4.2.2.\n-   Added Client Side Field Level Encryption example.\n\n### October 21th, 2020\n\n-   Update Java Driver to 4.1.1.\n-   The MongoDB Java Driver logging is now enabled via the popular [SLF4J](http://www.slf4j.org/) API so I added logback in the `pom.xml` and a configuration file `logback.xml`.\n\n## Introduction\n\n<div>\n    <img\n        style=\"float: right;\n        border-radius: 10px;\n        margin-bottom: 30px;\n        vertical-align: bottom;\n        width: 30%;\"\n        src=\"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/old_images/qs-badges/qs-badge-java.png\" alt=\"Java badge\" />\n\nIn this very first blog post of the Java Quick Start series, I will show you how to set up your Java project with Maven and execute a MongoDB command in Java. Then we will explore the most common operations — such as create, read, update, and delete — using the [MongoDB Java driver](https://www.mongodb.com/docs/drivers/java-drivers/). I will also show you some of the more powerful options and features available as part of the MongoDB [Java driver](https://www.mongodb.com/docs/drivers/java/sync/current/compatibility/) for each of these operations, giving you a really great foundation of knowledge to build upon as we go through the series.\n</div>\n\nIn future blog posts, we will move on and work through:\n\n-   [Mapping MongoDB BSON documents directly to Plain Old Java Object (POJO)](/developer/languages/java/java-mapping-pojos/).\n-   [The MongoDB Aggregation Framework](/developer/languages/java/java-aggregation-pipeline/).\n-   [Change Streams](/developer/languages/java/java-change-streams/).\n-   Multi-document ACID transactions.\n-   The MongoDB Java reactive streams driver.\n\n### Why MongoDB and Java? \n\nJava is the [most popular language in the IT industry](https://stackify.com/popular-programming-languages-2018/) at the date of this blog post, and [developers voted MongoDB as their most wanted database four years in a row](https://www.mongodb.com/blog/post/mongodb-the-most-wanted-database-by-developers-for-the-4th-consecutive-year).  In this series of blog posts, I will be demonstrating how powerful these two great pieces of technology are when combined and how you can access that power.\n\n### Prerequisites\n\nTo follow along, you can use any environment you like and the integrated development environment of your choice. I'll use [Maven](http://maven.apache.org/install.html) 3.6.2 and the Java OpenJDK 13, but all the code will be compatible with Java versions 8 to 13, so feel free to use the JDK of your choice and update the Java version accordingly in the pom.xml file we are about to set up.\n\nFor the MongoDB cluster, we will be using a M0 Free Tier MongoDB Cluster from [MongoDB Atlas](https://www.mongodb.com/cloud/atlas/). If you don't have one already, check out my [Get Started with an M0 Cluster](/developer/products/atlas/free-atlas-cluster/) blog post.\n\n>Get your free M0 cluster on [MongoDB Atlas](https://www.mongodb.com/cloud/atlas/) today. It's free forever, and you'll be able to use it to work with the examples in this blog series.\n\nLet's jump in and take a look at how well Java and MongoDB work together.\n\n## Getting set up\n\nTo begin with, we will need to set up a new Maven project. You have two options at this point. You can either clone this series' git repository or you can create and set up the Maven project.\n\n### Using the git repository\n\nIf you choose to use git, you will get all the code immediately. I still recommend you read through the manual set-up.\n\nYou can clone the repository if you like with the following command.\n\n``` bash\ngit clone https://github.com/mongodb-developer/java-quick-start\n```\n\nOr you can [download the repository as a zip file](https://github.com/mongodb-developer/java-quick-start/archive/master.zip).\n\n### Setting up manually\n\nYou can either use your favorite IDE to create a new Maven project for you or you can create the Maven project manually. Either way, you should get the following folder architecture:\n\n``` none\njava-quick-start/\n├── pom.xml\n└── src\n    └── main\n        └── java\n            └── com\n                └── mongodb\n                    └── quickstart\n```\n\nThe pom.xml file should contain the following code:\n\n``` xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>com.mongodb</groupId>\n    <artifactId>java-quick-start</artifactId>\n    <version>1.0-SNAPSHOT</version>\n\n    <properties>\n        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n        <maven-compiler-plugin.source>8</maven-compiler-plugin.source>\n        <maven-compiler-plugin.target>8</maven-compiler-plugin.target>\n        <maven-compiler-plugin.version>3.10.1</maven-compiler-plugin.version>\n        <mongodb-driver-sync.version>4.6.1</mongodb-driver-sync.version>\n        <mongodb-crypt.version>1.4.1</mongodb-crypt.version>\n        <logback-classic.version>1.2.11</logback-classic.version>\n    </properties>\n\n    <dependencies>\n        <dependency>\n            <groupId>org.mongodb</groupId>\n            <artifactId>mongodb-driver-sync</artifactId>\n            <version>${mongodb-driver-sync.version}</version>\n        </dependency>\n        <dependency>\n            <groupId>org.mongodb</groupId>\n            <artifactId>mongodb-crypt</artifactId>\n            <version>${mongodb-crypt.version}</version>\n        </dependency>\n        <dependency>\n            <groupId>ch.qos.logback</groupId>\n            <artifactId>logback-classic</artifactId>\n            <version>${logback-classic.version}</version>\n        </dependency>\n    </dependencies>\n\n    <build>\n        <plugins>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-compiler-plugin</artifactId>\n                <version>${maven-compiler-plugin.version}</version>\n                <configuration>\n                    <source>${maven-compiler-plugin.source}</source>\n                    <target>${maven-compiler-plugin.target}</target>\n                </configuration>\n            </plugin>\n        </plugins>\n    </build>\n\n</project>\n```\n\nTo verify that everything works correctly, you should be able to create and run a simple \"Hello MongoDB!\" program. In `src/main/java/com/mongodb/quickstart`, create the `HelloMongoDB.java` file:\n\n``` java\npackage com.mongodb.quickstart;\n\npublic class HelloMongoDB {\n\n    public static void main(String[] args) {\n        System.out.println(\"Hello MongoDB!\");\n    }\n}\n```\n\nThen compile and execute it with your IDE or use the command line in the root directory (where the `src` folder is):\n\n``` bash\nmvn compile exec:java -Dexec.mainClass=\"com.mongodb.quickstart.HelloMongoDB\"\n```\n\nThe result should look like this:\n\n``` none\n[...]\n[INFO] Scanning for projects...\n[INFO]\n[INFO] --------------------< com.mongodb:java-quick-start >--------------------\n[INFO] Building java-quick-start 1.0-SNAPSHOT\n[INFO] --------------------------------[ jar ]---------------------------------\n[INFO]\n[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ java-quick-start ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] Copying 1 resource\n[INFO]\n[INFO] --- maven-compiler-plugin:3.8.1:compile (default-compile) @ java-quick-start ---\n[INFO] Nothing to compile - all classes are up to date\n[INFO]\n[INFO] --- exec-maven-plugin:1.4.0:java (default-cli) @ java-quick-start ---\nHello MongoDB!\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD SUCCESS\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time:  0.786 s\n[INFO] Finished at: 2019-10-02T20:19:36+02:00\n[INFO] ------------------------------------------------------------------------\n```\n\n>Note: If you see some warnings about an illegal reflective access from `guice.java`, it's safe to ignore them. Guice is used by Maven and needs an update. You can read more about it [in this GitHub issue](https://github.com/google/guice/issues/1133). These warnings will disappear in a future release of Guice and Maven.\n\n## Connecting with Java\n\nNow that our Maven project works and we have resolved our dependencies, we can start using MongoDB Atlas with Java.\n\nIf you have imported the [sample dataset](/developer/products/atlas/atlas-sample-datasets/) as suggested in the [Quick Start Atlas blog post](/developer/products/atlas/free-atlas-cluster/), then with the Java code we are about to create, you will be able to see a list of the databases in the sample dataset.\n\nThe first step is to instantiate a `MongoClient` by passing a MongoDB Atlas connection string into the `MongoClients.create()` static method.  This will establish a connection to [MongoDB Atlas](https://www.mongodb.com/cloud/atlas/) using the connection string. Then we can retrieve the list of databases on this cluster and print them out to test the connection with MongoDB.\n\nIn `src/main/java/com/mongodb`, create the `Connection.java` file:\n\n``` java\npackage com.mongodb.quickstart;\n\nimport com.mongodb.client.MongoClient;\nimport com.mongodb.client.MongoClients;\nimport org.bson.Document;\n\nimport java.util.ArrayList;\nimport java.util.List;\n\npublic class Connection {\n\n    public static void main(String[] args) {\n        String connectionString = System.getProperty(\"mongodb.uri\");\n        try (MongoClient mongoClient = MongoClients.create(connectionString)) {\n            List<Document> databases = mongoClient.listDatabases().into(new ArrayList<>());\n            databases.forEach(db -> System.out.println(db.toJson()));\n        }\n    }\n}\n```\n\nAs you can see, the MongoDB connection string is retrieved from the *System Properties*, so we need to set this up. Once you have retrieved your [MongoDB Atlas connection string](https://docs.mongodb.com/guides/cloud/connectionstring/), you can add the `mongodb.uri` system property into your IDE. Here is my configuration with IntelliJ for example.\n\n![IntelliJ Configuration](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/old_images/intellij-configuration.png \"IntelliJ Configuration\")\n\nOr if you prefer to use Maven in command line, here is the equivalent command line you can run in the root directory:\n\n``` bash\nmvn compile exec:java -Dexec.mainClass=\"com.mongodb.quickstart.Connection\" -Dmongodb.uri=\"mongodb+srv://username:password@cluster0-abcde.mongodb.net/test?w=majority\"\n```\n\n>Note: Don't forget the double quotes around the MongoDB URI to avoid surprises from your shell.\n\nThe standard output should look like this:\n\n``` none\n{\"name\": \"admin\", \"sizeOnDisk\": 303104.0, \"empty\": false}\n{\"name\": \"config\", \"sizeOnDisk\": 147456.0, \"empty\": false}\n{\"name\": \"local\", \"sizeOnDisk\": 5.44731136E8, \"empty\": false}\n{\"name\": \"sample_airbnb\", \"sizeOnDisk\": 5.761024E7, \"empty\": false}\n{\"name\": \"sample_geospatial\", \"sizeOnDisk\": 1384448.0, \"empty\": false}\n{\"name\": \"sample_mflix\", \"sizeOnDisk\": 4.583424E7, \"empty\": false}\n{\"name\": \"sample_supplies\", \"sizeOnDisk\": 1339392.0, \"empty\": false}\n{\"name\": \"sample_training\", \"sizeOnDisk\": 7.4801152E7, \"empty\": false}\n{\"name\": \"sample_weatherdata\", \"sizeOnDisk\": 5103616.0, \"empty\": false}\n```\n\n## Insert operations\n\n### Getting set up\n\nIn the Connecting with Java section, we created the classes `HelloMongoDB` and `Connection`. Now we will work on the `Create` class.\n\nIf you didn't set up your free cluster on MongoDB Atlas, now is great time to do so. Get the directions for [creating your cluster](/developer/products/atlas/free-atlas-cluster/).\n\n### Checking the collection and data model\n\nIn the sample dataset, you can find the database `sample_training`, which contains a collection `grades`. Each document in this collection represents a student's grades for a particular class.\n\nHere is the JSON representation of a document in the [mongo shell](https://docs.mongodb.com/manual/mongo/).\n\n``` bash\nMongoDB Enterprise Cluster0-shard-0:PRIMARY> db.grades.findOne({student_id: 0, class_id: 339})\n{\n    \"_id\" : ObjectId(\"56d5f7eb604eb380b0d8d8ce\"),\n    \"student_id\" : 0,\n    \"scores\" : [\n        {\n            \"type\" : \"exam\",\n            \"score\" : 78.40446309504266\n        },\n        {\n            \"type\" : \"quiz\",\n            \"score\" : 73.36224783231339\n        },\n        {\n            \"type\" : \"homework\",\n            \"score\" : 46.980982486720535\n        },\n        {\n            \"type\" : \"homework\",\n            \"score\" : 76.67556138656222\n        }\n    ],\n    \"class_id\" : 339\n}\n```\n\nAnd here is the [extended JSON](https://docs.mongodb.com/manual/reference/mongodb-extended-json/) representation of the same student. You can retrieve it in [MongoDB Compass](https://www.mongodb.com/products/compass), our free GUI tool, if you want.\n\nExtended JSON is the human readable version of a BSON document without loss of type information. You can read more about the Java driver and BSON [in the MongoDB Java driver documentation](https://mongodb.github.io/mongo-java-driver/3.11/bson/extended-json/).\n\n``` json\n{\n    \"_id\": {\n        \"$oid\": \"56d5f7eb604eb380b0d8d8ce\"\n    },\n    \"student_id\": {\n        \"$numberDouble\": \"0\"\n    },\n    \"scores\": [{\n        \"type\": \"exam\",\n        \"score\": {\n            \"$numberDouble\": \"78.40446309504266\"\n        }\n    }, {\n        \"type\": \"quiz\",\n        \"score\": {\n            \"$numberDouble\": \"73.36224783231339\"\n        }\n    }, {\n        \"type\": \"homework\",\n        \"score\": {\n            \"$numberDouble\": \"46.980982486720535\"\n        }\n    }, {\n        \"type\": \"homework\",\n        \"score\": {\n            \"$numberDouble\": \"76.67556138656222\"\n        }\n    }],\n    \"class_id\": {\n        \"$numberDouble\": \"339\"\n    }\n}\n```\n\nAs you can see, MongoDB stores BSON documents and for each key-value pair, the BSON contains the key and the value along with its type. This is how MongoDB knows that `class_id` is actually a double and not an integer, which is not explicit in the mongo shell representation of this document.\n\nWe have 10,000 students (`student_id` from 0 to 9999) already in this collection and each of them took 10 different classes, which adds up to 100,000 documents in this collection. Let's say a new student (`student_id` 10,000) just arrived in this university and received a bunch of (random) grades in his first class. Let's insert this new student document using Java and the MongoDB Java driver.\n\nIn this university, the `class_id` varies from 0 to 500, so I can use any random value between 0 and 500.\n\n### Selecting databases and collections\n\nFirstly, we need to set up our `Create` class and access this `sample_training.grades` collection.\n\n``` java\npackage com.mongodb.quickstart;\n\nimport com.mongodb.client.MongoClient;\nimport com.mongodb.client.MongoClients;\nimport com.mongodb.client.MongoCollection;\nimport com.mongodb.client.MongoDatabase;\nimport org.bson.Document;\n\npublic class Create {\n\n    public static void main(String[] args) {\n        try (MongoClient mongoClient = MongoClients.create(System.getProperty(\"mongodb.uri\"))) {\n\n            MongoDatabase sampleTrainingDB = mongoClient.getDatabase(\"sample_training\");\n            MongoCollection<Document> gradesCollection = sampleTrainingDB.getCollection(\"grades\");\n\n        }\n    }\n}\n```\n\n### Create a BSON document\n\nSecondly, we need to represent this new student in Java using the `Document` class.\n\n``` java\nRandom rand = new Random();\nDocument student = new Document(\"_id\", new ObjectId());\nstudent.append(\"student_id\", 10000d)\n       .append(\"class_id\", 1d)\n       .append(\"scores\", asList(new Document(\"type\", \"exam\").append(\"score\", rand.nextDouble() * 100),\n                                new Document(\"type\", \"quiz\").append(\"score\", rand.nextDouble() * 100),\n                                new Document(\"type\", \"homework\").append(\"score\", rand.nextDouble() * 100),\n                                new Document(\"type\", \"homework\").append(\"score\", rand.nextDouble() * 100)));\n```\n\nAs you can see, we reproduced the same data model from the existing documents in this collection as we made sure that `student_id`, `class_id`, and `score` are all doubles.\n\nAlso, the Java driver would have generated the `_id` field with an ObjectId for us if we didn't explicitly create one here, but it's good practice to set the `_id` ourselves. This won't change our life right now, but it makes more sense when we directly manipulate POJOs and we want to create a clean REST API. I'm doing this in my [mapping POJOs post](/developer/languages/java/java-mapping-pojos/).\n\nNote as well that we are inserting a document into an existing collection and database, but if these didn’t already exist, MongoDB would automatically create them the first time you to go insert a document into the collection.\n\n### Insert document\n\nFinally, we can insert this document.\n\n``` java\ngradesCollection.insertOne(student);\n```\n\n### Final code to insert one document\n\nHere is the final `Create` class to insert one document in MongoDB with all the details I mentioned above.\n\n``` java\npackage com.mongodb.quickstart;\n\nimport com.mongodb.client.MongoClient;\nimport com.mongodb.client.MongoClients;\nimport com.mongodb.client.MongoCollection;\nimport com.mongodb.client.MongoDatabase;\nimport org.bson.Document;\nimport org.bson.types.ObjectId;\n\nimport java.util.Random;\n\nimport static java.util.Arrays.asList;\n\npublic class Create {\n\n    public static void main(String[] args) {\n        try (MongoClient mongoClient = MongoClients.create(System.getProperty(\"mongodb.uri\"))) {\n\n            MongoDatabase sampleTrainingDB = mongoClient.getDatabase(\"sample_training\");\n            MongoCollection<Document> gradesCollection = sampleTrainingDB.getCollection(\"grades\");\n\n            Random rand = new Random();\n            Document student = new Document(\"_id\", new ObjectId());\n            student.append(\"student_id\", 10000d)\n                   .append(\"class_id\", 1d)\n                   .append(\"scores\", asList(new Document(\"type\", \"exam\").append(\"score\", rand.nextDouble() * 100),\n                                            new Document(\"type\", \"quiz\").append(\"score\", rand.nextDouble() * 100),\n                                            new Document(\"type\", \"homework\").append(\"score\", rand.nextDouble() * 100),\n                                            new Document(\"type\", \"homework\").append(\"score\", rand.nextDouble() * 100)));\n\n            gradesCollection.insertOne(student);\n        }\n    }\n}\n```\n\nYou can execute this class with the following Maven command line in the root directory or using your IDE (see above for more details). Don't forget the double quotes around the MongoDB URI to avoid surprises.\n\n``` bash\nmvn compile exec:java -Dexec.mainClass=\"com.mongodb.quickstart.Create\" -Dmongodb.uri=\"mongodb+srv://USERNAME:PASSWORD@cluster0-abcde.mongodb.net/test?w=majority\"\n```\n\nAnd here is the document I extracted from [MongoDB\nCompass](https://www.mongodb.com/products/compass).\n\n``` json\n{\n    \"_id\": {\n        \"$oid\": \"5d97c375ded5651ea3462d0f\"\n    },\n    \"student_id\": {\n        \"$numberDouble\": \"10000\"\n    },\n    \"class_id\": {\n        \"$numberDouble\": \"1\"\n    },\n    \"scores\": [{\n        \"type\": \"exam\",\n        \"score\": {\n            \"$numberDouble\": \"4.615256396625178\"\n        }\n    }, {\n        \"type\": \"quiz\",\n        \"score\": {\n            \"$numberDouble\": \"73.06173415145801\"\n        }\n    }, {\n        \"type\": \"homework\",\n        \"score\": {\n            \"$numberDouble\": \"19.378205578990727\"\n        }\n    }, {\n        \"type\": \"homework\",\n        \"score\": {\n            \"$numberDouble\": \"82.3089189278531\"\n        }\n    }]\n}\n```\n\nNote that the order of the fields is different from the initial document with `\"student_id\": 0`.\n\nWe could get exactly the same order if we wanted to by creating the document like this.\n\n``` java\nRandom rand = new Random();\nDocument student = new Document(\"_id\", new ObjectId());\nstudent.append(\"student_id\", 10000d)\n       .append(\"scores\", asList(new Document(\"type\", \"exam\").append(\"score\", rand.nextDouble() * 100),\n                                new Document(\"type\", \"quiz\").append(\"score\", rand.nextDouble() * 100),\n                                new Document(\"type\", \"homework\").append(\"score\", rand.nextDouble() * 100),\n                                new Document(\"type\", \"homework\").append(\"score\", rand.nextDouble() * 100)))\n       .append(\"class_id\", 1d);\n```\n\nBut if you do things correctly, this should not have any impact on your code and logic as fields in JSON documents are not ordered.\n\nI'm quoting [json.org](http://json.org/) for this:\n\n>An object is an unordered set of name/value pairs.\n\n### Insert multiple documents\n\nNow that we know how to create one document, let's learn how to insert many documents.\n\nOf course, we could just wrap the previous `insert` operation into a `for` loop. Indeed, if we loop 10 times on this method, we would send 10 insert commands to the cluster and expect 10 insert acknowledgments. As you can imagine, this would not be very efficient as it would generate a lot more TCP communications than necessary.\n\nInstead, we want to wrap our 10 documents and send them in one call to the cluster and we want to receive only one insert acknowledgement for the entire list.\n\nLet's refactor the code. First, let's make the random generator a `private static final` field.\n\n``` java\nprivate static final Random rand = new Random();\n```\n\nLet's make a grade factory method.\n\n``` java\nprivate static Document generateNewGrade(double studentId, double classId) {\n    List<Document> scores = asList(new Document(\"type\", \"exam\").append(\"score\", rand.nextDouble() * 100),\n                                   new Document(\"type\", \"quiz\").append(\"score\", rand.nextDouble() * 100),\n                                   new Document(\"type\", \"homework\").append(\"score\", rand.nextDouble() * 100),\n                                   new Document(\"type\", \"homework\").append(\"score\", rand.nextDouble() * 100));\n    return new Document(\"_id\", new ObjectId()).append(\"student_id\", studentId)\n                                              .append(\"class_id\", classId)\n                                              .append(\"scores\", scores);\n}\n```\n\nAnd now we can use this to insert 10 documents all at once.\n\n``` java\nList<Document> grades = new ArrayList<>();\nfor (double classId = 1d; classId <= 10d; classId++) {\n    grades.add(generateNewGrade(10001d, classId));\n}\n\ngradesCollection.insertMany(grades, new InsertManyOptions().ordered(false));\n```\n\nAs you can see, we are now wrapping our grade documents into a list and we are sending this list in a single call with the `insertMany` method.\n\nBy default, the `insertMany` method will insert the documents in order and stop if an error occurs during the process. For example, if you try to insert a new document with the same `_id` as an existing document, you would get a `DuplicateKeyException`.\n\nTherefore, with an ordered `insertMany`, the last documents of the list would not be inserted and the insertion process would stop and return the appropriate exception as soon as the error occurs.\n\nAs you can see here, this is not the behaviour we want because all the grades are completely independent from one to another. So, if one of them fails, we want to process all the grades and then eventually fall back to an exception for the ones that failed.\n\nThis is why you see the second parameter `new InsertManyOptions().ordered(false)` which is true by default.\n\n### The final code to insert multiple documents\n\nLet's refactor the code a bit and here is the final `Create` class.\n\n``` java\npackage com.mongodb.quickstart;\n\nimport com.mongodb.client.MongoClient;\nimport com.mongodb.client.MongoClients;\nimport com.mongodb.client.MongoCollection;\nimport com.mongodb.client.MongoDatabase;\nimport com.mongodb.client.model.InsertManyOptions;\nimport org.bson.Document;\nimport org.bson.types.ObjectId;\n\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.Random;\n\nimport static java.util.Arrays.asList;\n\npublic class Create {\n\n    private static final Random rand = new Random();\n\n    public static void main(String[] args) {\n        try (MongoClient mongoClient = MongoClients.create(System.getProperty(\"mongodb.uri\"))) {\n\n            MongoDatabase sampleTrainingDB = mongoClient.getDatabase(\"sample_training\");\n            MongoCollection<Document> gradesCollection = sampleTrainingDB.getCollection(\"grades\");\n\n            insertOneDocument(gradesCollection);\n            insertManyDocuments(gradesCollection);\n        }\n    }\n\n    private static void insertOneDocument(MongoCollection<Document> gradesCollection) {\n        gradesCollection.insertOne(generateNewGrade(10000d, 1d));\n        System.out.println(\"One grade inserted for studentId 10000.\");\n    }\n\n    private static void insertManyDocuments(MongoCollection<Document> gradesCollection) {\n        List<Document> grades = new ArrayList<>();\n        for (double classId = 1d; classId <= 10d; classId++) {\n            grades.add(generateNewGrade(10001d, classId));\n        }\n\n        gradesCollection.insertMany(grades, new InsertManyOptions().ordered(false));\n        System.out.println(\"Ten grades inserted for studentId 10001.\");\n    }\n\n    private static Document generateNewGrade(double studentId, double classId) {\n        List<Document> scores = asList(new Document(\"type\", \"exam\").append(\"score\", rand.nextDouble() * 100),\n                                       new Document(\"type\", \"quiz\").append(\"score\", rand.nextDouble() * 100),\n                                       new Document(\"type\", \"homework\").append(\"score\", rand.nextDouble() * 100),\n                                       new Document(\"type\", \"homework\").append(\"score\", rand.nextDouble() * 100));\n        return new Document(\"_id\", new ObjectId()).append(\"student_id\", studentId)\n                                                  .append(\"class_id\", classId)\n                                                  .append(\"scores\", scores);\n    }\n}\n```\n\nAs a reminder, every write operation (create, replace, update, delete) performed on a **single** document is [ACID](https://en.wikipedia.org/wiki/ACID) in MongoDB. Which means `insertMany` is not ACID by default but, good news, since MongoDB 4.0, we can wrap this call in a multi-document ACID transaction to make it fully ACID. I explain this in more detail in my blog about [multi-document ACID transactions](https://www.mongodb.com/blog/post/java-and-mongodb-40-support-for-multidocument-acid-transactions).\n\n## Read documents\n\n### Create data\n\nWe created the class `Create`. Now we will work in the `Read` class.\n\nWe wrote 11 new grades, one for the student with `{\"student_id\": 10000}` and 10 for the student with `{\"student_id\": 10001}` in the `sample_training.grades` collection.\n\nAs a reminder, here are the grades of the `{\"student_id\": 10000}`.\n\n``` javascript\nMongoDB Enterprise Cluster0-shard-0:PRIMARY> db.grades.findOne({\"student_id\":10000})\n{\n    \"_id\" : ObjectId(\"5daa0e274f52b44cfea94652\"),\n    \"student_id\" : 10000,\n    \"class_id\" : 1,\n    \"scores\" : [\n        {\n            \"type\" : \"exam\",\n            \"score\" : 39.25175977753478\n        },\n        {\n            \"type\" : \"quiz\",\n            \"score\" : 80.2908713167313\n        },\n        {\n            \"type\" : \"homework\",\n            \"score\" : 63.5444978481843\n        },\n        {\n            \"type\" : \"homework\",\n            \"score\" : 82.35202261582563\n        }\n    ]\n}\n```\n\nWe also discussed BSON types and we noted that `student_id` and `class_id` are doubles.\n\nMongoDB treats some types as equivalent for comparison purposes. For instance, numeric types undergo conversion before comparison.\n\nSo, don't be surprised if I filter with an integer number and match a document which contains a double number for example. If you want to filter documents by value types, you can use the [$type operator](https://docs.mongodb.com/manual/reference/operator/query/type/).\n\nYou can read more about [type bracketing](https://docs.mongodb.com/manual/reference/method/db.collection.find/#type-bracketing) and [comparison and sort order](https://docs.mongodb.com/manual/reference/bson-type-comparison-order/) in our documentation.\n\n### Read a specific document\n\nLet's read the document above. To achieve this, we will use the method `find`, passing it a filter to help identify the document we want to find.\n\nPlease create a class `Read` in the `com.mongodb.quickstart` package with this code:\n\n``` java\npackage com.mongodb.quickstart;\n\nimport com.mongodb.client.*;\nimport org.bson.Document;\n\nimport java.util.ArrayList;\nimport java.util.List;\n\nimport static com.mongodb.client.model.Filters.*;\nimport static com.mongodb.client.model.Projections.*;\nimport static com.mongodb.client.model.Sorts.descending;\n\npublic class Read {\n\n    public static void main(String[] args) {\n        try (MongoClient mongoClient = MongoClients.create(System.getProperty(\"mongodb.uri\"))) {\n            MongoDatabase sampleTrainingDB = mongoClient.getDatabase(\"sample_training\");\n            MongoCollection<Document> gradesCollection = sampleTrainingDB.getCollection(\"grades\");\n\n            // find one document with new Document\n            Document student1 = gradesCollection.find(new Document(\"student_id\", 10000)).first();\n            System.out.println(\"Student 1: \" + student1.toJson());\n        }\n    }\n}\n```\n\nAlso, make sure you set up your `mongodb.uri` in your system properties using your IDE if you want to run this code in your favorite IDE.\n\nAlternatively, you can use this Maven command line in your root project (where the `src` folder is):\n\n``` bash\nmvn compile exec:java -Dexec.mainClass=\"com.mongodb.quickstart.Read\" -Dmongodb.uri=\"mongodb+srv://USERNAME:PASSWORD@cluster0-abcde.mongodb.net/test?w=majority\"\n```\n\nThe standard output should be:\n\n``` javascript\nStudent 1: {\"_id\": {\"$oid\": \"5daa0e274f52b44cfea94652\"},\n    \"student_id\": 10000.0,\n    \"class_id\": 1.0,\n    \"scores\": [\n        {\"type\": \"exam\", \"score\": 39.25175977753478},\n        {\"type\": \"quiz\", \"score\": 80.2908713167313},\n        {\"type\": \"homework\", \"score\": 63.5444978481843},\n        {\"type\": \"homework\", \"score\": 82.35202261582563}\n    ]\n}\n```\n\nThe MongoDB driver comes with a few helpers to ease the writing of these queries. Here's an equivalent query using the `Filters.eq()` method.\n\n``` java\ngradesCollection.find(eq(\"student_id\", 10000)).first();\n```\n\nOf course, I used a static import to make the code as compact and easy to read as possible.\n\n``` java\nimport static com.mongodb.client.model.Filters.eq;\n```\n\n### Read a range of documents\n\nIn the previous example, the benefit of these helpers is not obvious, but let me show you another example where I'm searching all the grades with a *student_id* greater than or equal to 10,000.\n\n``` java\n// without helpers\ngradesCollection.find(new Document(\"student_id\", new Document(\"$gte\", 10000)));\n// with the Filters.gte() helper\ngradesCollection.find(gte(\"student_id\", 10000));\n```\n\nAs you can see, I'm using the `$gte` operator to write this query. You can learn about all the different [query operators](https://docs.mongodb.com/manual/reference/operator/query/) in the MongoDB documentation.\n\n### Iterators\n\nThe `find` method returns an object that implements the interface `FindIterable`, which ultimately extends the `Iterable` interface so we can use an iterator to go through the list of documents we are receiving from MongoDB:\n\n``` java\nFindIterable<Document> iterable = gradesCollection.find(gte(\"student_id\", 10000));\nMongoCursor<Document> cursor = iterable.iterator();\nSystem.out.println(\"Student list with cursor: \");\nwhile (cursor.hasNext()) {\n    System.out.println(cursor.next().toJson());\n}\n```\n\n### Lists\n\nLists are usually easier to manipulate than iterators, so we can also do this to retrieve directly an `ArrayList<Document>`:\n\n``` java\nList<Document> studentList = gradesCollection.find(gte(\"student_id\", 10000)).into(new ArrayList<>());\nSystem.out.println(\"Student list with an ArrayList:\");\nfor (Document student : studentList) {\n    System.out.println(student.toJson());\n}\n```\n\n### Consumers\n\nWe could also use a `Consumer` which is a functional interface:\n\n``` java\nConsumer<Document> printConsumer = document -> System.out.println(document.toJson());\ngradesCollection.find(gte(\"student_id\", 10000)).forEach(printConsumer);\n```\n\n### Cursors, sort, skip, limit, and projections\n\nAs we saw above with the `Iterator` example, MongoDB leverages [cursors](https://docs.mongodb.com/manual/reference/method/js-cursor/) to iterate through your result set.\n\nIf you are already familiar with the cursors in the [mongo shell](https://www.mongodb.com/docs/v4.4/mongo/), you know that transformations can be applied to it. A cursor can be [sorted](https://docs.mongodb.com/manual/reference/method/cursor.sort/) and the documents it contains can be transformed using a [projection](https://docs.mongodb.com/manual/tutorial/project-fields-from-query-results/).  Also, once the cursor is sorted, we can choose to skip a few documents and limit the number of documents in the output. This is very useful to implement pagination in your frontend for example.\n\nLet's combine everything we have learnt in one query:\n\n``` java\nList<Document> docs = gradesCollection.find(and(eq(\"student_id\", 10001), lte(\"class_id\", 5)))\n                                                  .projection(fields(excludeId(),\n                                                                     include(\"class_id\",\n                                                                             \"student_id\")))\n                                                  .sort(descending(\"class_id\"))\n                                                  .skip(2)\n                                                  .limit(2)\n                                                  .into(new ArrayList<>());\n\nSystem.out.println(\"Student sorted, skipped, limited and projected: \");\nfor (Document student : docs) {\n    System.out.println(student.toJson());\n}\n```\n\nHere is the output we get:\n\n``` javascript\n{\"student_id\": 10001.0, \"class_id\": 3.0}\n{\"student_id\": 10001.0, \"class_id\": 2.0}\n```\n\nRemember that documents are returned in the [natural order](https://docs.mongodb.com/manual/reference/glossary/#term-natural-order), so if you want your output ordered, you need to sort your cursors to make sure there is no randomness in your algorithm.\n\n### Indexes\n\nIf you want to make these queries (with or without sort) efficient, **you need** [indexes](https://docs.mongodb.com/manual/indexes/)!\n\nTo make my last query efficient, I should create this index:\n\n``` javascript\ndb.grades.createIndex({\"student_id\": 1, \"class_id\": -1})\n```\n\nWhen I run an [explain](https://docs.mongodb.com/manual/reference/method/cursor.explain/) on this query, this is the winning plan I get:\n\n``` javascript\n\"winningPlan\" : {\n            \"stage\" : \"LIMIT\",\n            \"limitAmount\" : 2,\n            \"inputStage\" : {\n                \"stage\" : \"PROJECTION_COVERED\",\n                \"transformBy\" : {\n                    \"_id\" : 0,\n                    \"class_id\" : 1,\n                    \"student_id\" : 1\n                },\n                \"inputStage\" : {\n                    \"stage\" : \"SKIP\",\n                    \"skipAmount\" : 2,\n                    \"inputStage\" : {\n                        \"stage\" : \"IXSCAN\",\n                        \"keyPattern\" : {\n                            \"student_id\" : 1,\n                            \"class_id\" : -1\n                        },\n                        \"indexName\" : \"student_id_1_class_id_-1\",\n                        \"isMultiKey\" : false,\n                        \"multiKeyPaths\" : {\n                            \"student_id\" : [ ],\n                            \"class_id\" : [ ]\n                        },\n                        \"isUnique\" : false,\n                        \"isSparse\" : false,\n                        \"isPartial\" : false,\n                        \"indexVersion\" : 2,\n                        \"direction\" : \"forward\",\n                        \"indexBounds\" : {\n                            \"student_id\" : [\n                                \"[10001.0, 10001.0]\"\n                            ],\n                            \"class_id\" : [\n                                \"[5.0, -inf.0]\"\n                            ]\n                        }\n                    }\n                }\n            }\n        }\n```\n\nWith this index, we can see that we have no *SORT* stage, so we are not doing a sort in memory as the documents are already sorted \"for free\" and returned in the order of the index.\n\nAlso, we can see that we don't have any *FETCH* stage, so this is a [covered query](https://docs.mongodb.com/manual/core/query-optimization/#covered-query), the most efficient type of query you can run in MongoDB. Indeed, all the information we are returning at the end is already in the index, so the index itself contains everything we need to answer this query.\n\n### The final code to read documents\n\n``` java\npackage com.mongodb.quickstart;\n\nimport com.mongodb.client.*;\nimport org.bson.Document;\n\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.function.Consumer;\n\nimport static com.mongodb.client.model.Filters.*;\nimport static com.mongodb.client.model.Projections.*;\nimport static com.mongodb.client.model.Sorts.descending;\n\npublic class Read {\n\n    public static void main(String[] args) {\n        try (MongoClient mongoClient = MongoClients.create(System.getProperty(\"mongodb.uri\"))) {\n            MongoDatabase sampleTrainingDB = mongoClient.getDatabase(\"sample_training\");\n            MongoCollection<Document> gradesCollection = sampleTrainingDB.getCollection(\"grades\");\n\n            // find one document with new Document\n            Document student1 = gradesCollection.find(new Document(\"student_id\", 10000)).first();\n            System.out.println(\"Student 1: \" + student1.toJson());\n\n            // find one document with Filters.eq()\n            Document student2 = gradesCollection.find(eq(\"student_id\", 10000)).first();\n            System.out.println(\"Student 2: \" + student2.toJson());\n\n            // find a list of documents and iterate throw it using an iterator.\n            FindIterable<Document> iterable = gradesCollection.find(gte(\"student_id\", 10000));\n            MongoCursor<Document> cursor = iterable.iterator();\n            System.out.println(\"Student list with a cursor: \");\n            while (cursor.hasNext()) {\n                System.out.println(cursor.next().toJson());\n            }\n\n            // find a list of documents and use a List object instead of an iterator\n            List<Document> studentList = gradesCollection.find(gte(\"student_id\", 10000)).into(new ArrayList<>());\n            System.out.println(\"Student list with an ArrayList:\");\n            for (Document student : studentList) {\n                System.out.println(student.toJson());\n            }\n\n            // find a list of documents and print using a consumer\n            System.out.println(\"Student list using a Consumer:\");\n            Consumer<Document> printConsumer = document -> System.out.println(document.toJson());\n            gradesCollection.find(gte(\"student_id\", 10000)).forEach(printConsumer);\n\n            // find a list of documents with sort, skip, limit and projection\n            List<Document> docs = gradesCollection.find(and(eq(\"student_id\", 10001), lte(\"class_id\", 5)))\n                                                  .projection(fields(excludeId(), include(\"class_id\", \"student_id\")))\n                                                  .sort(descending(\"class_id\"))\n                                                  .skip(2)\n                                                  .limit(2)\n                                                  .into(new ArrayList<>());\n\n            System.out.println(\"Student sorted, skipped, limited and projected: \");\n            for (Document student : docs) {\n                System.out.println(student.toJson());\n            }\n        }\n    }\n}\n```\n\n## Update documents\n\n### Update one document\n\nLet's edit the document with `{student_id: 10000}`. To achieve this, we will use the method `updateOne`.\n\nPlease create a class `Update` in the `com.mongodb.quickstart` package with this code:\n\n``` java\npackage com.mongodb.quickstart;\n\nimport com.mongodb.client.MongoClient;\nimport com.mongodb.client.MongoClients;\nimport com.mongodb.client.MongoCollection;\nimport com.mongodb.client.MongoDatabase;\nimport com.mongodb.client.model.FindOneAndUpdateOptions;\nimport com.mongodb.client.model.ReturnDocument;\nimport com.mongodb.client.model.UpdateOptions;\nimport com.mongodb.client.result.UpdateResult;\nimport org.bson.Document;\nimport org.bson.conversions.Bson;\nimport org.bson.json.JsonWriterSettings;\n\nimport static com.mongodb.client.model.Filters.and;\nimport static com.mongodb.client.model.Filters.eq;\nimport static com.mongodb.client.model.Updates.*;\n\npublic class Update {\n\n    public static void main(String[] args) {\n        JsonWriterSettings prettyPrint = JsonWriterSettings.builder().indent(true).build();\n\n        try (MongoClient mongoClient = MongoClients.create(System.getProperty(\"mongodb.uri\"))) {\n            MongoDatabase sampleTrainingDB = mongoClient.getDatabase(\"sample_training\");\n            MongoCollection<Document> gradesCollection = sampleTrainingDB.getCollection(\"grades\");\n\n            // update one document\n            Bson filter = eq(\"student_id\", 10000);\n            Bson updateOperation = set(\"comment\", \"You should learn MongoDB!\");\n            UpdateResult updateResult = gradesCollection.updateOne(filter, updateOperation);\n            System.out.println(\"=> Updating the doc with {\\\"student_id\\\":10000}. Adding comment.\");\n            System.out.println(gradesCollection.find(filter).first().toJson(prettyPrint));\n            System.out.println(updateResult);\n        }\n    }\n}\n```\n\nAs you can see in this example, the method `updateOne` takes two parameters:\n\n-   The first one is the filter that identifies the document we want to update.\n-   The second one is the update operation. Here, we are setting a new field `comment` with the value `\"You should learn MongoDB!\"`.\n\nIn order to run this program, make sure you set up your `mongodb.uri` in your system properties using your IDE if you want to run this code in your favorite IDE (see above for more details).\n\nAlternatively, you can use this Maven command line in your root project (where the `src` folder is):\n\n``` bash\nmvn compile exec:java -Dexec.mainClass=\"com.mongodb.quickstart.Update\" -Dmongodb.uri=\"mongodb+srv://USERNAME:PASSWORD@cluster0-abcde.mongodb.net/test?w=majority\"\n```\n\nThe standard output should look like this:\n\n``` javascript\n=> Updating the doc with {\"student_id\":10000}. Adding comment.\n{\n  \"_id\": {\n    \"$oid\": \"5dd5c1f351f97d4a034109ed\"\n  },\n  \"student_id\": 10000.0,\n  \"class_id\": 1.0,\n  \"scores\": [\n    {\n      \"type\": \"exam\",\n      \"score\": 21.580800815091415\n    },\n    {\n      \"type\": \"quiz\",\n      \"score\": 87.66967927111044\n    },\n    {\n      \"type\": \"homework\",\n      \"score\": 96.4060480668003\n    },\n    {\n      \"type\": \"homework\",\n      \"score\": 75.44966835508427\n    }\n  ],\n  \"comment\": \"You should learn MongoDB!\"\n}\nAcknowledgedUpdateResult{matchedCount=1, modifiedCount=1, upsertedId=null}\n```\n\n### Upsert a document\n\nAn upsert is a mix between an insert operation and an update one. It happens when you want to update a document, assuming it exists, but it actually doesn't exist yet in your database.\n\nIn MongoDB, you can set an option to create this document on the fly and carry on with your update operation. This is an upsert operation.\n\nIn this example, I want to add a comment to the grades of my student 10002 for the class 10 but this document doesn't exist yet.\n\n``` java\nfilter = and(eq(\"student_id\", 10002d), eq(\"class_id\", 10d));\nupdateOperation = push(\"comments\", \"You will learn a lot if you read the MongoDB blog!\");\nUpdateOptions options = new UpdateOptions().upsert(true);\nupdateResult = gradesCollection.updateOne(filter, updateOperation, options);\nSystem.out.println(\"\\n=> Upsert document with {\\\"student_id\\\":10002.0, \\\"class_id\\\": 10.0} because it doesn't exist yet.\");\nSystem.out.println(updateResult);\nSystem.out.println(gradesCollection.find(filter).first().toJson(prettyPrint));\n```\n\nAs you can see, I'm using the third parameter of the update operation to set the option upsert to true.\n\nI'm also using the static method `Updates.push()` to push a new value in my array `comments` which does not exist yet, so I'm creating an array of one element in this case.\n\nThis is the output we get:\n\n``` javascript\n=> Upsert document with {\"student_id\":10002.0, \"class_id\": 10.0} because it doesn't exist yet.\nAcknowledgedUpdateResult{matchedCount=0, modifiedCount=0, upsertedId=BsonObjectId{value=5ddeb7b7224ad1d5cfab3733}}\n{\n  \"_id\": {\n    \"$oid\": \"5ddeb7b7224ad1d5cfab3733\"\n  },\n  \"class_id\": 10.0,\n  \"student_id\": 10002.0,\n  \"comments\": [\n    \"You will learn a lot if you read the MongoDB blog!\"\n  ]\n}\n```\n\n### Update many documents\n\nThe same way I was able to update one document with `updateOne()`, I can update multiple documents with `updateMany()`.\n\n``` java\nfilter = eq(\"student_id\", 10001);\nupdateResult = gradesCollection.updateMany(filter, updateOperation);\nSystem.out.println(\"\\n=> Updating all the documents with {\\\"student_id\\\":10001}.\");\nSystem.out.println(updateResult);\n```\n\nIn this example, I'm using the same `updateOperation` as earlier, so I'm creating a new one element array `comments` in these 10 documents.\n\nHere is the output:\n\n``` javascript\n=> Updating all the documents with {\"student_id\":10001}.\nAcknowledgedUpdateResult{matchedCount=10, modifiedCount=10, upsertedId=null}\n```\n\n### The findOneAndUpdate method\n\nFinally, we have one last very useful method available in the MongoDB Java Driver: `findOneAndUpdate()`.\n\nIn most web applications, when a user updates something, they want to see this update reflected on their web page. Without the `findOneAndUpdate()` method, you would have to run an update operation and then fetch the document with a find operation to make sure you are printing the latest version of this object in the web page.\n\nThe `findOneAndUpdate()` method allows you to combine these two operations in one.\n\n``` java\n// findOneAndUpdate\nfilter = eq(\"student_id\", 10000);\nBson update1 = inc(\"x\", 10); // increment x by 10. As x doesn't exist yet, x=10.\nBson update2 = rename(\"class_id\", \"new_class_id\"); // rename variable \"class_id\" in \"new_class_id\".\nBson update3 = mul(\"scores.0.score\", 2); // multiply the first score in the array by 2.\nBson update4 = addToSet(\"comments\", \"This comment is uniq\"); // creating an array with a comment.\nBson update5 = addToSet(\"comments\", \"This comment is uniq\"); // using addToSet so no effect.\nBson updates = combine(update1, update2, update3, update4, update5);\n// returns the old version of the document before the update.\nDocument oldVersion = gradesCollection.findOneAndUpdate(filter, updates);\nSystem.out.println(\"\\n=> FindOneAndUpdate operation. Printing the old version by default:\");\nSystem.out.println(oldVersion.toJson(prettyPrint));\n\n// but I can also request the new version\nfilter = eq(\"student_id\", 10001);\nFindOneAndUpdateOptions optionAfter = new FindOneAndUpdateOptions().returnDocument(ReturnDocument.AFTER);\nDocument newVersion = gradesCollection.findOneAndUpdate(filter, updates, optionAfter);\nSystem.out.println(\"\\n=> FindOneAndUpdate operation. But we can also ask for the new version of the doc:\");\nSystem.out.println(newVersion.toJson(prettyPrint));\n```\n\nHere is the output:\n\n``` javascript\n=> FindOneAndUpdate operation. Printing the old version by default:\n{\n  \"_id\": {\n    \"$oid\": \"5dd5d46544fdc35505a8271b\"\n  },\n  \"student_id\": 10000.0,\n  \"class_id\": 1.0,\n  \"scores\": [\n    {\n      \"type\": \"exam\",\n      \"score\": 69.52994626959251\n    },\n    {\n      \"type\": \"quiz\",\n      \"score\": 87.27457417188077\n    },\n    {\n      \"type\": \"homework\",\n      \"score\": 83.40970667948744\n    },\n    {\n      \"type\": \"homework\",\n      \"score\": 40.43663797673247\n    }\n  ],\n  \"comment\": \"You should learn MongoDB!\"\n}\n\n=> FindOneAndUpdate operation. But we can also ask for the new version of the doc:\n{\n  \"_id\": {\n    \"$oid\": \"5dd5d46544fdc35505a82725\"\n  },\n  \"student_id\": 10001.0,\n  \"scores\": [\n    {\n      \"type\": \"exam\",\n      \"score\": 138.42535412437857\n    },\n    {\n      \"type\": \"quiz\",\n      \"score\": 84.66740178906916\n    },\n    {\n      \"type\": \"homework\",\n      \"score\": 36.773091359279675\n    },\n    {\n      \"type\": \"homework\",\n      \"score\": 14.90842128691825\n    }\n  ],\n  \"comments\": [\n    \"You will learn a lot if you read the MongoDB blog!\",\n    \"This comment is uniq\"\n  ],\n  \"new_class_id\": 10.0,\n  \"x\": 10\n}\n```\n\nAs you can see in this example, you can choose which version of the document you want to return using the appropriate option.\n\nI also used this example to show you a bunch of update operators:\n\n-   `set` will set a value.\n-   `inc` will increment a value.\n-   `rename` will rename a field.\n-   `mul` will multiply the value by the given number.\n-   `addToSet` is similar to push but will only push the value in the array if the value doesn't exist already.\n\nThere are a few other update operators. You can consult the entire list in our [documentation](https://docs.mongodb.com/manual/reference/operator/update/).\n\n### The final code for updates\n\n``` java\npackage com.mongodb.quickstart;\n\nimport com.mongodb.client.MongoClient;\nimport com.mongodb.client.MongoClients;\nimport com.mongodb.client.MongoCollection;\nimport com.mongodb.client.MongoDatabase;\nimport com.mongodb.client.model.FindOneAndUpdateOptions;\nimport com.mongodb.client.model.ReturnDocument;\nimport com.mongodb.client.model.UpdateOptions;\nimport com.mongodb.client.result.UpdateResult;\nimport org.bson.Document;\nimport org.bson.conversions.Bson;\nimport org.bson.json.JsonWriterSettings;\n\nimport static com.mongodb.client.model.Filters.and;\nimport static com.mongodb.client.model.Filters.eq;\nimport static com.mongodb.client.model.Updates.*;\n\npublic class Update {\n\n    public static void main(String[] args) {\n        JsonWriterSettings prettyPrint = JsonWriterSettings.builder().indent(true).build();\n\n        try (MongoClient mongoClient = MongoClients.create(System.getProperty(\"mongodb.uri\"))) {\n            MongoDatabase sampleTrainingDB = mongoClient.getDatabase(\"sample_training\");\n            MongoCollection<Document> gradesCollection = sampleTrainingDB.getCollection(\"grades\");\n\n            // update one document\n            Bson filter = eq(\"student_id\", 10000);\n            Bson updateOperation = set(\"comment\", \"You should learn MongoDB!\");\n            UpdateResult updateResult = gradesCollection.updateOne(filter, updateOperation);\n            System.out.println(\"=> Updating the doc with {\\\"student_id\\\":10000}. Adding comment.\");\n            System.out.println(gradesCollection.find(filter).first().toJson(prettyPrint));\n            System.out.println(updateResult);\n\n            // upsert\n            filter = and(eq(\"student_id\", 10002d), eq(\"class_id\", 10d));\n            updateOperation = push(\"comments\", \"You will learn a lot if you read the MongoDB blog!\");\n            UpdateOptions options = new UpdateOptions().upsert(true);\n            updateResult = gradesCollection.updateOne(filter, updateOperation, options);\n            System.out.println(\"\\n=> Upsert document with {\\\"student_id\\\":10002.0, \\\"class_id\\\": 10.0} because it doesn't exist yet.\");\n            System.out.println(updateResult);\n            System.out.println(gradesCollection.find(filter).first().toJson(prettyPrint));\n\n            // update many documents\n            filter = eq(\"student_id\", 10001);\n            updateResult = gradesCollection.updateMany(filter, updateOperation);\n            System.out.println(\"\\n=> Updating all the documents with {\\\"student_id\\\":10001}.\");\n            System.out.println(updateResult);\n\n            // findOneAndUpdate\n            filter = eq(\"student_id\", 10000);\n            Bson update1 = inc(\"x\", 10); // increment x by 10. As x doesn't exist yet, x=10.\n            Bson update2 = rename(\"class_id\", \"new_class_id\"); // rename variable \"class_id\" in \"new_class_id\".\n            Bson update3 = mul(\"scores.0.score\", 2); // multiply the first score in the array by 2.\n            Bson update4 = addToSet(\"comments\", \"This comment is uniq\"); // creating an array with a comment.\n            Bson update5 = addToSet(\"comments\", \"This comment is uniq\"); // using addToSet so no effect.\n            Bson updates = combine(update1, update2, update3, update4, update5);\n            // returns the old version of the document before the update.\n            Document oldVersion = gradesCollection.findOneAndUpdate(filter, updates);\n            System.out.println(\"\\n=> FindOneAndUpdate operation. Printing the old version by default:\");\n            System.out.println(oldVersion.toJson(prettyPrint));\n\n            // but I can also request the new version\n            filter = eq(\"student_id\", 10001);\n            FindOneAndUpdateOptions optionAfter = new FindOneAndUpdateOptions().returnDocument(ReturnDocument.AFTER);\n            Document newVersion = gradesCollection.findOneAndUpdate(filter, updates, optionAfter);\n            System.out.println(\"\\n=> FindOneAndUpdate operation. But we can also ask for the new version of the doc:\");\n            System.out.println(newVersion.toJson(prettyPrint));\n        }\n    }\n}\n```\n\n## Delete documents\n\n### Delete one document\n\nLet's delete the document above. To achieve this, we will use the method `deleteOne`.\n\nPlease create a class `Delete` in the `com.mongodb.quickstart` package with this code:\n\n``` java\npackage com.mongodb.quickstart;\n\nimport com.mongodb.client.MongoClient;\nimport com.mongodb.client.MongoClients;\nimport com.mongodb.client.MongoCollection;\nimport com.mongodb.client.MongoDatabase;\nimport com.mongodb.client.result.DeleteResult;\nimport org.bson.Document;\nimport org.bson.conversions.Bson;\n\nimport static com.mongodb.client.model.Filters.eq;\nimport static com.mongodb.client.model.Filters.gte;\n\npublic class Delete {\n\n    public static void main(String[] args) {\n\n        try (MongoClient mongoClient = MongoClients.create(System.getProperty(\"mongodb.uri\"))) {\n            MongoDatabase sampleTrainingDB = mongoClient.getDatabase(\"sample_training\");\n            MongoCollection<Document> gradesCollection = sampleTrainingDB.getCollection(\"grades\");\n\n            // delete one document\n            Bson filter = eq(\"student_id\", 10000);\n            DeleteResult result = gradesCollection.deleteOne(filter);\n            System.out.println(result);\n        }\n    }\n}\n```\n\nAs you can see in this example, the method `deleteOne` only takes one parameter: a filter, just like the `find()` operation.\n\nIn order to run this program, make sure you set up your `mongodb.uri` in your system properties using your IDE if you want to run this code in your favorite IDE (see above for more details).\n\nAlternatively, you can use this Maven command line in your root project (where the `src` folder is):\n\n``` bash\nmvn compile exec:java -Dexec.mainClass=\"com.mongodb.quickstart.Delete\" -Dmongodb.uri=\"mongodb+srv://USERNAME:PASSWORD@cluster0-abcde.mongodb.net/test?w=majority\"\n```\n\nThe standard output should look like this:\n\n``` javascript\nAcknowledgedDeleteResult{deletedCount=1}\n```\n\n### FindOneAndDelete()\n\nAre you emotionally attached to your document and want a chance to see it one last time before it's too late? We have what you need.\n\nThe method `findOneAndDelete()` allows you to retrieve a document and delete it in a single atomic operation.\n\nHere is how it works:\n\n``` java\nBson filter = eq(\"student_id\", 10002);\nDocument doc = gradesCollection.findOneAndDelete(filter);\nSystem.out.println(doc.toJson(JsonWriterSettings.builder().indent(true).build()));\n```\n\nHere is the output we get:\n\n``` javascript\n{\n  \"_id\": {\n    \"$oid\": \"5ddec378224ad1d5cfac02b8\"\n  },\n  \"class_id\": 10.0,\n  \"student_id\": 10002.0,\n  \"comments\": [\n    \"You will learn a lot if you read the MongoDB blog!\"\n  ]\n}\n```\n\n### Delete many documents\n\nThis time we will use `deleteMany()` instead of `deleteOne()` and we will use a different filter to match more documents.\n\n``` java\nBson filter = gte(\"student_id\", 10000);\nDeleteResult result = gradesCollection.deleteMany(filter);\nSystem.out.println(result);\n```\n\nAs a reminder, you can learn more about all the query selectors [in our\ndocumentation](https://docs.mongodb.com/manual/reference/operator/query/#query-selectors).\n\nThis is the output we get:\n\n``` javascript\nAcknowledgedDeleteResult{deletedCount=10}\n```\n\n### Delete a collection\n\nDeleting all the documents from a collection will not delete the collection itself because a collection also contains metadata like the index definitions or the chunk distribution if your collection is sharded for example.\n\nIf you want to remove the entire collection **and** all the metadata associated with it, then you need to use the `drop()` method.\n\n``` java\ngradesCollection.drop();\n```\n\n### The final code for delete operations\n\n``` java\npackage com.mongodb.quickstart;\n\nimport com.mongodb.client.MongoClient;\nimport com.mongodb.client.MongoClients;\nimport com.mongodb.client.MongoCollection;\nimport com.mongodb.client.MongoDatabase;\nimport com.mongodb.client.result.DeleteResult;\nimport org.bson.Document;\nimport org.bson.conversions.Bson;\nimport org.bson.json.JsonWriterSettings;\n\nimport static com.mongodb.client.model.Filters.eq;\nimport static com.mongodb.client.model.Filters.gte;\n\npublic class Delete {\n\n    public static void main(String[] args) {\n        try (MongoClient mongoClient = MongoClients.create(System.getProperty(\"mongodb.uri\"))) {\n            MongoDatabase sampleTrainingDB = mongoClient.getDatabase(\"sample_training\");\n            MongoCollection<Document> gradesCollection = sampleTrainingDB.getCollection(\"grades\");\n\n            // delete one document\n            Bson filter = eq(\"student_id\", 10000);\n            DeleteResult result = gradesCollection.deleteOne(filter);\n            System.out.println(result);\n\n            // findOneAndDelete operation\n            filter = eq(\"student_id\", 10002);\n            Document doc = gradesCollection.findOneAndDelete(filter);\n            System.out.println(doc.toJson(JsonWriterSettings.builder().indent(true).build()));\n\n            // delete many documents\n            filter = gte(\"student_id\", 10000);\n            result = gradesCollection.deleteMany(filter);\n            System.out.println(result);\n\n            // delete the entire collection and its metadata (indexes, chunk metadata, etc).\n            gradesCollection.drop();\n        }\n    }\n}\n```\n\n## Wrapping up\n\nWith this blog post, we have covered all the basic operations, such as create and read, and have also seen how we can easily use powerful functions available in the Java driver for MongoDB. You can find the links to the other blog posts of this series just below.\n\n>If you want to learn more and deepen your knowledge faster, I recommend you check out the M220J: MongoDB for Java Developers training available for free on [MongoDB University](https://university.mongodb.com/courses/M220J/about).","originalPublishDate":"2022-02-01T19:28:57.565Z","SEO":"61b7fb80e454ca0b0d52819f","related_content":[],"createdAt":"2021-12-14T02:03:44.090Z","originalUpdatedAt":"2022-02-01T19:28:57.599Z","image":{"_id":"627d17de8891f3001d997e5d","name":"*Java Banner_1280x720.png","alternativeText":"","caption":"","hash":"Java_Banner_1280x720_f64f523556","ext":".png","mime":"image/png","size":26.78,"width":1280,"height":720,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/Java_Banner_1280x720_f64f523556.png","formats":{"thumbnail":{"name":"*thumbnail_Java Banner_1280x720.png","hash":"thumbnail_Java_Banner_1280x720_f64f523556","ext":".png","mime":"image/png","width":245,"height":138,"size":10.43,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/thumbnail_Java_Banner_1280x720_f64f523556.png"},"large":{"name":"*large_Java Banner_1280x720.png","hash":"large_Java_Banner_1280x720_f64f523556","ext":".png","mime":"image/png","width":1000,"height":563,"size":60.7,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/large_Java_Banner_1280x720_f64f523556.png"},"medium":{"name":"*medium_Java Banner_1280x720.png","hash":"medium_Java_Banner_1280x720_f64f523556","ext":".png","mime":"image/png","width":750,"height":422,"size":41.4,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/medium_Java_Banner_1280x720_f64f523556.png"},"small":{"name":"*small_Java Banner_1280x720.png","hash":"small_Java_Banner_1280x720_f64f523556","ext":".png","mime":"image/png","width":500,"height":281,"size":24.22,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/small_Java_Banner_1280x720_f64f523556.png"}},"provider":"aws-s3","related":["6244b4fd7a304f0ca6c4d9af","6244b4fd7a304f0ca6c4d9b2","6244b4fd7a304f0ca6c4d9b3","6244b4fd7a304f0ca6c4d9b1"],"createdAt":"2022-05-12T14:21:18.948Z","updatedAt":"2022-05-12T15:48:02.291Z","__v":0,"created_by":"60acfb196a6d99001c58c549","updated_by":"60acfb196a6d99001c58c549","id":"627d17de8891f3001d997e5d"},"updated_by":"60958855b4522964e193dbc8","description":"Learn how to use MongoDB with Java in this tutorial on CRUD operations with example code and walkthrough.","__v":3,"other_tags":[{"__component":"other-tag-info.other-tag-info","id":"625848494a0541001d381354"}],"primary_tag":[{"__component":"primary-tag-info.programming-language","id":"625848494a0541001d381352"}],"updatedAt":"2023-01-26T16:56:03.124Z","calculated_slug":"/languages/java/java-setup-crud-operations","published_at":"2022-05-12T14:27:41.112Z","expiry_date":"2022-12-14T02:03:44.090Z","id":"6244b4fd7a304f0ca6c4d9b3"},{"awaiting_editorial_review":false,"awaiting_technical_review":false,"editorial_review_LGTM":false,"technical_review_LGTM":false,"authors":["61969cc0a0957d40b0be6803"],"_id":"6304daefe50177001c2bf43a","published_at":"2022-08-23T13:49:51.949Z","content":"## Introduction\nBuild your first application with Java and Spring! This simple application demonstrates basic CRUD operations via a book app - you can add a book, edit a book, delete a book. Stores the data in MongoDB database. \n\n\n## Technology\n\n* Java\n* Spring\n* MongoDB\n\n\n","slug":"/spring-java-mongodb-example-app2","description":"Build an application to track the books you've read with Spring, Java, and MongoDB","name":"*Build a Spring Java Book Tracker for Beginners","SEO":null,"related_content":[],"primary_tag":[{"__component":"primary-tag-info.programming-language","id":"6304daefe50177001c2bf43b"}],"other_tags":[{"__component":"other-tag-info.other-tag-info","id":"6304daefe50177001c2bf43d"}],"createdAt":"2022-08-23T13:49:35.932Z","updatedAt":"2022-08-23T13:49:52.035Z","__v":2,"created_by":"61f82d1bdf707f001cad52ff","image":{"_id":"62c022627fbd69001dfd4880","name":"*Java-Emblem.jpeg","alternativeText":"java logo","caption":"","hash":"Java_Emblem_4069eda9a5","ext":".jpeg","mime":"image/jpeg","size":91.34,"width":3840,"height":2400,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/Java_Emblem_4069eda9a5.jpeg","formats":{"thumbnail":{"name":"*thumbnail_Java-Emblem.jpeg","hash":"thumbnail_Java_Emblem_4069eda9a5","ext":".jpeg","mime":"image/jpeg","width":245,"height":153,"size":3.96,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/thumbnail_Java_Emblem_4069eda9a5.jpeg"},"large":{"name":"*large_Java-Emblem.jpeg","hash":"large_Java_Emblem_4069eda9a5","ext":".jpeg","mime":"image/jpeg","width":1000,"height":625,"size":24.39,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/large_Java_Emblem_4069eda9a5.jpeg"},"medium":{"name":"*medium_Java-Emblem.jpeg","hash":"medium_Java_Emblem_4069eda9a5","ext":".jpeg","mime":"image/jpeg","width":750,"height":469,"size":16.93,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/medium_Java_Emblem_4069eda9a5.jpeg"},"small":{"name":"*small_Java-Emblem.jpeg","hash":"small_Java_Emblem_4069eda9a5","ext":".jpeg","mime":"image/jpeg","width":500,"height":313,"size":10.35,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/small_Java_Emblem_4069eda9a5.jpeg"}},"provider":"aws-s3","related":["62c0229d7fbd69001dfd4881","6304daefe50177001c2bf43a"],"createdAt":"2022-07-02T10:48:02.770Z","updatedAt":"2022-08-23T13:49:36.016Z","__v":0,"created_by":"61f82d1bdf707f001cad52ff","updated_by":"61f82d1bdf707f001cad52ff","id":"62c022627fbd69001dfd4880"},"updated_by":"61f82d1bdf707f001cad52ff","calculated_slug":"/code-examples/java/spring-java-mongodb-example-app2","expiry_date":"2023-08-23T13:49:35.932Z","id":"6304daefe50177001c2bf43a"}],"podcasts":[],"videos":[],"events":[],"_id":"62b3783413e171001ca58efa","__v":0,"programming_language":{"_id":"62471b39ce7cde001ccae8f3","name":"*Java","published_at":"2022-05-09T18:49:55.904Z","createdAt":"2022-04-01T15:33:13.202Z","updatedAt":"2022-06-11T11:53:15.139Z","__v":0,"created_by":"61f82d1bdf707f001cad52ff","updated_by":"61f82d1bdf707f001cad52ff","calculated_slug":"/languages/java","description":"A high-level, class-based, object-oriented programming language. With Java Virtual Machine (JVM) Java applications are called WORA (Write Once Run Anywhere). ","icon":{"_id":"62795f15413697001c652b3c","name":"*java.svg","alternativeText":"","caption":"","hash":"java_6313b07c59","ext":".svg","mime":"image/svg+xml","size":2.22,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/java_6313b07c59.svg","provider":"aws-s3","width":38,"height":51,"related":["62471b39ce7cde001ccae8f3"],"createdAt":"2022-05-09T18:36:05.752Z","updatedAt":"2022-05-09T18:55:59.553Z","__v":0,"created_by":"60acfb196a6d99001c58c549","updated_by":"60acfb196a6d99001c58c549","id":"62795f15413697001c652b3c"},"documentation_link":"https://www.mongodb.com/docs/drivers/java-drivers/","id":"62471b39ce7cde001ccae8f3"},"id":"62b3783413e171001ca58efa"},{"__component":"featured-category.content-type","articles":[{"awaiting_editorial_review":false,"awaiting_technical_review":false,"editorial_review_LGTM":true,"technical_review_LGTM":true,"authors":["61153e776ebafd4c6e4c5bbc"],"_id":"6244b4fd7a304f0ca6c4da08","type":"HowTo","name":"*Building Modern Applications with Next.js and MongoDB","slug":"/nextjs-building-modern-applications","content":">\n>\n>This article is out of date. Check out the [official Next.js with MongoDB tutorial](/developer/languages/javascript/nextjs-with-mongodb/) for the latest guide on integrating MongoDB with Next.js.\n>\n>\n\nDevelopers have more choices than ever before when it comes to choosing the technology stack for their next application. Developer productivity is one of the most important factors in choosing a modern stack and I believe that Next.js coupled with MongoDB can get you up and running on the next great application in no time at all. Let's find out how and why!\n\nIf you would like to follow along with this tutorial, you can get the code from the [GitHub repo](https://github.com/kukicado/building-modern-app-with-nextjs-and-mongodb).  Also, be sure to sign up for a [free MongoDB Atlas account](https://www.mongodb.com/atlas) to make it easier to connect your MongoDB database.\n\n## What is Next.js\n\n[Next.js](https://nextjs.org/) is a [React](https://reactjs.org/) based framework for building modern web applications. The framework comes with a lot of powerful features such as server side rendering, automatic code splitting, static exporting and much more that make it easy to build scalable and production ready apps. Its opinionated nature means that the framework is focused on developer productivity, but still flexible enough to give developers plenty of choice when it comes to handling the big architectural decisions.\n\n![NextJS Homepage](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/old_images/nextjs/nextjs.png)\n\nFor this tutorial, I'll assume that you are already familiar with React, and if so, you'll be up and running with Next.js in no time at all. If you are not familiar with React, I would suggest looking at resources such as the [official React docs](https://reactjs.org/docs/getting-started.html) or taking a [free React starter course](https://scotch.io/starters/react/getting-started-with-react-2019-edition?ref=home-start-here) to get familiar with the framework first.\n\n## What We're Building: Macro Compliance Tracker\n\nThe app we're building today is called the Macro Compliance Tracker. If you're like me, you probably had a New Years Resolution of *\"I'm going to get in better shape!\"* This year, I am taking that resolution seriously, and have gotten a person trainer and nutritionist. One interesting thing that I learned is that while the old adage of calories in needs to be less than calories out to lose weight is generally true, your macronutrients also play just as an important role in weight loss.\n\nThere are many great apps that help you track your calories and macros.  Unfortunately, most apps do not allow you to track a range and another interesting thing that I learned in my fitness journey this year is that for many beginners trying to hit their daily macro goals is a challenge and many folks end up giving up when they fail to hit the exact targets consistently. For that reason, my coach suggests a target range for calories and macros rather than a hard set number.\n\n![MCT App](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/old_images/nextjs/mct-app.png)\n\nSo that's what we're building today. We'll use Next.js to build our entire application and MongoDB as our database to store our progress.  Let's get into it!\n\n## Setting up a Next.js Application\n\nThe easiest way to create a Next.js application is by using the official create-next-app npx command. To do that we'll simply open up our Terminal window and type: `npx create-next-app mct`. \"mct\" is going to be the name of our application as well as the directory where our code is going to live.\n\n![create-next-app](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/old_images/nextjs/create-next-app.png)\n\nExecute this command and a default application will be created. Once the files are created navigate into the directory by running `cd mct` in the Terminal window and then execute `npm run dev`. This will start a development server for your Next.js application which you'll be able to access at `localhost:3000`.\n\n![Next.js Default](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/old_images/nextjs/next-default.png)\n\nNavigate to `localhost:3000` and you should see a page very similar to the one in the above screenshot. If you see the Welcome to Next.js page you are good to go. If not, I would suggest following the Next.js docs and troubleshooting tips to ensure proper setup.\n\n## Next.js Directory Structure\n\nBefore we dive into building our application any further, let's quickly look at how Next.js structures our application. The default directory structure looks like this:\n\n![Next.js Default Directory Structure](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/old_images/nextjs/next-directory.png)\n\nThe areas we're going to be focused on are the pages, components, and public directories. The .next directory contains the build artifacts for our application, and we should generally avoid making direct changes to it.\n\nThe pages directory will contain our application pages, or another way to think of these is that each file here will represent a single route in our application. Our default app only has the index.js page created which corresponds with our home route. If we wanted to add a second page, for example, an about page, we can easily do that by just creating a new file called about.js. The name we give to the filename will correspond to the route. So let's go ahead and create an `about.js` file in the pages directory.\n\nAs I mentioned earlier, Next.js is a React based framework, so all your React knowledge is fully transferable here. You can create components using either as functions or as classes. I will be using the function based approach. Feel free to grab the complete [GitHub repo](https://github.com/kukicado/building-modern-app-with-nextjs-and-mongodb) if you would like to follow along. Our About.js component will look like this:\n\n``` javascript\nimport React from 'react'\nimport Head from 'next/head'\nimport Nav from '../components/nav'\n\nconst About = () => (\n  <div>\n    <Head>\n      <title>About</title>\n      <link rel=\"icon\" href=\"/favicon.ico\" />\n    </Head>\n\n    <Nav />\n\n    <div>\n      <h1>Macro Compliance Tracker!</h1>\n      <p>\n        This app will help you ensure your macros are within a selected range to help you achieve your New Years Resolution!\n      </p>\n    </div>\n  </div>\n)\n\nexport default About\n```\n\nGo ahead and save this file. Next.js will automatically rebuild the application and you should be able to navigate to `http://localhost:3000/about` now and see your new component in action.\n\n![About Us Page Unstyled](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/old_images/nextjs/about-unstyled.png)\n\nNext.js will automatically handle all the routing plumbing and ensure the right component gets loaded. Just remember, whatever you name your file in the pages directory is what the corresponding URL will be.\n\n## Adding Some Style with Tailwind.css\n\nOur app is looking good, but from a design perspective, it's looking pretty bare. Let's add [Tailwind.css](https://tailwindcss.com/) to spruce up our design and make it a little easier on the eyes. Tailwind is a very powerful CSS framework, but for brevity we'll just import the base styles from a CDN and won't do any customizations. To do this, we'll simply add `<link href=\"https://unpkg.com/tailwindcss@^1.0/dist/tailwind.min.css\" rel=\"stylesheet\"/>` in the Head components of our pages.\n\nLet's do this for our About component and also add some Tailwind classes to improve our design. Our next component should look like this:\n\n``` javascript\nimport React from 'react'\nimport Head from 'next/head'\nimport Nav from '../components/nav'\n\nconst About = () => (\n  <div>\n    <Head>\n      <title>About</title>\n      <link rel=\"icon\" href=\"/favicon.ico\" />\n      <link href=\"https://unpkg.com/tailwindcss@^1.0/dist/tailwind.min.css\" rel=\"stylesheet\" />\n    </Head>\n\n    <Nav />\n\n    <div className=\"container mx-auto text-center\">\n      <h1 className=\"text-6xl m-12\">Macro Compliance Tracker!</h1>\n      <p className=\"text-xl\">\n        This app will help you ensure your macros are within a selected range to help you achieve your New Years Resolution!\n      </p>\n    </div>\n  </div>\n)\n\nexport default About\n```\n\nIf we go and refresh our browser, the About page should look like this:\n\n![About Us Page Styled](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/old_images/nextjs/about-styled.png)\n\nGood enough for now. If you want to learn more about Tailwind, check out their [official docs here](https://tailwindcss.com/docs/installation/).\n\nNote: If when you make changes to your Next.js application such as adding the `className`'s or other changes, and they are not reflected when you refresh the page, restart the dev server.\n\n## Creating Our Application\n\nNow that we have our Next.js application setup, we've gone through and familiarized ourselves with how creating components and pages works, let's get into building our Macro Compliance Tracker app. For our first implementation of this app, we'll put all of our logic in the main index.js page. Open the page up and delete all the existing Next.js boilerplate.\n\nBefore we write the code, let's figure out what features we'll need.  We'll want to show the user their daily calorie and macro goals, as well as if they're in compliance with their targeted range or not.  Additionally, we'll want to allow the user to update their information every day. Finally, we'll want the user to be able to view previous days and see how they compare.\n\nLet's create the UI for this first. We'll do it all in the Home component, and then start breaking it up into smaller individual components. Our code will look like this:\n\n``` javascript\nimport React from 'react'\nimport Head from 'next/head'\nimport Nav from '../components/nav'\n\nconst Home = () => (\n  <div>\n    <Head>\n      <title>Home</title>\n      <link rel=\"icon\" href=\"/favicon.ico\" />\n      <link href=\"https://unpkg.com/tailwindcss@^1.0/dist/tailwind.min.css\" rel=\"stylesheet\" />\n    </Head>\n\n    <div className=\"container mx-auto\">\n\n      <div className=\"flex text-center\">\n        <div className=\"w-full m-4\">\n          <h1 className=\"text-4xl\">Macro Compliance Tracker</h1>\n        </div>\n      </div>\n\n      <div class=\"flex text-center\">\n        <div class=\"w-1/3 bg-gray-200 p-4\">Previous Day</div>\n        <div class=\"w-1/3 p-4\">1/23/2020</div>\n        <div class=\"w-1/3 bg-gray-200 p-4\">Next Day</div>\n      </div>\n\n      <div class=\"flex mb-4 text-center\">\n        <div class=\"w-1/4 p-4 bg-green-500 text-white\">\n          <h2 className=\"text-3xl font-bold\">1850\n            <div class=\"flex text-sm p-4\">\n              <div class=\"w-1/3\">1700</div>\n              <div class=\"w-1/3 font-bold\">1850</div>\n              <div class=\"w-1/3\">2000</div>\n            </div>\n          </h2>\n          <h3 className=\"text-xl\">Calories</h3>\n        </div>\n        <div class=\"w-1/4 p-4 bg-red-500 text-white\">\n          <h2 className=\"text-3xl font-bold\">195\n            <div class=\"flex text-sm p-4\">\n              <div class=\"w-1/3\">150</div>\n              <div class=\"w-1/3 font-bold\">160</div>\n              <div class=\"w-1/3\">170</div>\n            </div>\n          </h2>\n          <h3 className=\"text-xl\">Carbs</h3>\n        </div>\n        <div class=\"w-1/4 p-4 bg-green-500 text-white\">\n          <h2 className=\"text-3xl font-bold\">55\n            <div class=\"flex text-sm p-4\">\n              <div class=\"w-1/3\">50</div>\n              <div class=\"w-1/3 font-bold\">60</div>\n              <div class=\"w-1/3\">70</div>\n            </div>\n          </h2>\n          <h3 className=\"text-xl\">Fat</h3>\n        </div>\n        <div class=\"w-1/4 p-4 bg-blue-500 text-white\">\n          <h2 className=\"text-3xl font-bold\">120\n            <div class=\"flex text-sm p-4\">\n              <div class=\"w-1/3\">145</div>\n              <div class=\"w-1/3 font-bold\">160</div>\n              <div class=\"w-1/3\">175</div>\n            </div>\n          </h2>\n          <h3 className=\"text-xl\">Protein</h3>\n        </div>\n      </div>\n\n      <div className=\"flex\">\n        <div className=\"w-1/3\">\n          <h2 className=\"text-3xl p-4\">Results</h2>\n          <div className=\"p-4\">\n            <label className=\"block\">Calories</label>\n            <input type=\"number\" className=\"bg-gray-200 text-gray-700 border rounded py-3 px-4 mb-3 leading-tight focus:outline-none focus:bg-white\"></      input>\n          </div>\n          <div className=\"p-4\">\n            <label className=\"block\">Carbs</label>\n            <input type=\"number\" className=\"bg-gray-200 text-gray-700 border rounded py-3 px-4 mb-3 leading-tight focus:outline-none focus:bg-white\"></      input>\n          </div>\n          <div className=\"p-4\">\n            <label className=\"block\">Fat</label>\n            <input type=\"number\" className=\"bg-gray-200 text-gray-700 border rounded py-3 px-4 mb-3 leading-tight focus:outline-none focus:bg-white\"></      input>\n          </div>\n          <div className=\"p-4\">\n            <label className=\"block\">Protein</label>\n            <input type=\"number\" className=\"bg-gray-200 text-gray-700 border rounded py-3 px-4 mb-3 leading-tight focus:outline-none focus:bg-white\"></      input>\n          </div>\n          <div className=\"p-4\">\n            <button className=\"bg-blue-500 hover:bg-blue-700 text-white font-bold py-2 px-4 rounded\">\n              Save\n            </button>\n          </div>\n        </div>\n        <div className=\"w-1/3\">\n          <h2 className=\"text-3xl p-4\">Target</h2>\n          <div className=\"p-4\">\n            <label className=\"block\">Calories</label>\n            <input type=\"number\" className=\"bg-gray-200 text-gray-700 border rounded py-3 px-4 mb-3 leading-tight focus:outline-none focus:bg-white\"></      input>\n          </div>\n          <div className=\"p-4\">\n            <label className=\"block\">Carbs</label>\n            <input type=\"number\" className=\"bg-gray-200 text-gray-700 border rounded py-3 px-4 mb-3 leading-tight focus:outline-none focus:bg-white\"></      input>\n          </div>\n          <div className=\"p-4\">\n            <label className=\"block\">Fat</label>\n            <input type=\"number\" className=\"bg-gray-200 text-gray-700 border rounded py-3 px-4 mb-3 leading-tight focus:outline-none focus:bg-white\"></      input>\n          </div>\n          <div className=\"p-4\">\n            <label className=\"block\">Protein</label>\n            <input type=\"number\" className=\"bg-gray-200 text-gray-700 border rounded py-3 px-4 mb-3 leading-tight focus:outline-none focus:bg-white\"></      input>\n          </div>\n          <div className=\"p-4\">\n            <button className=\"bg-blue-500 hover:bg-blue-700 text-white font-bold py-2 px-4 rounded\">\n              Save\n            </button>\n          </div>\n        </div>\n        <div className=\"w-1/3\">\n          <h2 className=\"text-3xl p-4\">Variance</h2>\n          <div className=\"p-4\">\n            <label className=\"block\">Calories</label>\n            <input type=\"number\" className=\"bg-gray-200 text-gray-700 border rounded py-3 px-4 mb-3 leading-tight focus:outline-none focus:bg-white\"></      input>\n          </div>\n          <div className=\"p-4\">\n            <label className=\"block\">Carbs</label>\n            <input type=\"number\" className=\"bg-gray-200 text-gray-700 border rounded py-3 px-4 mb-3 leading-tight focus:outline-none focus:bg-white\"></      input>\n          </div>\n          <div className=\"p-4\">\n            <label className=\"block\">Fat</label>\n            <input type=\"number\" className=\"bg-gray-200 text-gray-700 border rounded py-3 px-4 mb-3 leading-tight focus:outline-none focus:bg-white\"></      input>\n          </div>\n          <div className=\"p-4\">\n            <label className=\"block\">Protein</label>\n            <input type=\"number\" className=\"bg-gray-200 text-gray-700 border rounded py-3 px-4 mb-3 leading-tight focus:outline-none focus:bg-white\"></      input>\n          </div>\n          <div className=\"p-4\">\n            <button className=\"bg-blue-500 hover:bg-blue-700 text-white font-bold py-2 px-4 rounded\">\n              Save\n            </button>\n          </div>\n        </div>\n      </div>\n    </div>\n  </div>\n)\n\nexport default Home\n```\n\nAnd this will result in our UI looking like this:\n\n![MCT App](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/old_images/nextjs/mct-app.png)\n\nThere is a bit to unwind here. So let's take a look at it piece by piece. At the very top we have a simple header that just displays the name of our application. Next, we have our day information and selection options. After that, we have our daily results showing whether we are in compliance or not for the selected day. If we are within the suggested range, the background is green. If we are over the range, meaning we've had too much of a particular macro, the background is red, and if we under-consumed a particular macro, the background is blue. Finally, we have our form which allows us to update our daily results, our target calories and macros, as well as variance for our range.\n\nOur code right now is all in one giant component and fairly static. Next let's break up our giant component into smaller parts and add our front end functionality so we're at least working with non-static data. We'll create our components in the components directory and then import them into our index.js page component. Components we create in the components directory can be used across multiple pages with ease allowing us reusability if we add multiple pages to our application.\n\nThe first component that we'll create is the result component. The result component is the green, red, or blue block that displays our result as well as our target and variance ranges. Our component will look like this:\n\n``` javascript\nimport React, {useState, useEffect} from 'react'\nconst Result = ({results}) => {\n    let [bg, setBg] = useState(\"\");\n\n    useEffect(() => {\n      setBackground()\n    });\n\n    const setBackground = () => {\n      let min = results.target - results.variant;\n      let max = results.target + results.variant;\n\n      if(results.total >= min && results.total <= max) {\n        setBg(\"bg-green-500\");\n      } else if ( results.total < min){\n        setBg(\"bg-blue-500\");\n      } else {\n        setBg(\"bg-red-500\")\n      }\n    }\n\n    return (\n      <div className={bg + \" w-1/4 p-4 text-white\"}>\n        <h2 className=\"text-3xl font-bold\">{results.total}\n          <div className=\"flex text-sm p-4\">\n            <div className=\"w-1/3\">{results.target - results.variant}</div>\n            <div className=\"w-1/3 font-bold\">{results.target}</div>\n            <div className=\"w-1/3\">{results.target + results.variant}</div>\n          </div>\n        </h2>\n        <h3 className=\"text-xl\">{results.label}</h3>\n      </div>\n    )\n  }\n\nexport default Result\n```\n\nThis will allow us to feed this component dynamic data and based on the data provided, we'll display the correct background, as well as target ranges for our macros. We can now simplify our index.js page component by removing all the boilerplate code and replacing it with:\n\n``` xml\n<div className=\"flex mb-4 text-center\">\n  <Result results={results.calories} />\n  <Result results={results.carbs} />\n  <Result results={results.fat} />\n  <Result results={results.protein} />\n</div>\n```\n\nLet's also go ahead and create some dummy data for now. We'll get to retrieving live data from MongoDB soon, but for now let's just create some data in-memory like so:\n\n``` javascript\nconst Home = () => {\n  let data = {\n    calories: {\n      label: \"Calories\",\n      total: 1840,\n      target: 1840,\n      variant: 15\n    },\n    carbs: {\n      label: \"Carbs\",\n      total: 190,\n      target: 160,\n      variant: 15\n    },\n    fat: {\n      label: \"Fat\",\n      total: 55,\n      target: 60,\n      variant: 10\n    },\n    protein: {\n      label: \"Protein\",\n      total: 120,\n      target: 165,\n      variant: 10\n    }\n  }\n\nconst [results, setResults] = useState(data);\n\nreturn ( ... )}\n```\n\nIf we look at our app now, it won't look very different at all. And that's ok. All we've done so far is change how our UI is rendered, moving it from hard coded static values, to an in-memory object. Next let's go ahead and make our form work with this in-memory data. Since our forms are very similar, we can create a component here as well and re-use the same component.\n\nWe will create a new component called MCTForm and in this component we'll pass in our data, a name for the form, and an onChange handler that will update the data dynamically as we change the values in the input boxes. Also, for simplicity, we'll remove the Save button and move it outside of the form. This will allow the user to make changes to their data in the UI, and when the user wants to lock in the changes and save them to the database, then they'll hit the Save button. So our Home component will now look like this:\n\n``` javascript\nconst Home = () => {\n  let data = {\n    calories: {\n      label: \"Calories\",\n      total: 1840,\n      target: 1850,\n      variant: 150\n    },\n    carbs: {\n      label: \"Carbs\",\n      total: 190,\n      target: 160,\n      variant: 15\n    },\n    fat: {\n      label: \"Fat\",\n      total: 55,\n      target: 60,\n      variant: 10\n    },\n    protein: {\n      label: \"Protein\",\n      total: 120,\n      target: 165,\n      variant: 10\n    }\n  }\n\n  const [results, setResults] = useState(data);\n\n  const onChange = (e) => {\n    const data = { ...results };\n\n    let name = e.target.name;\n\n    let resultType = name.split(\" \")[0].toLowerCase();\n    let resultMacro = name.split(\" \")[1].toLowerCase();\n\n    data[resultMacro][resultType] = e.target.value;\n\n    setResults(data);\n  }\n\n  return (\n  <div>\n    <Head>\n      <title>Home</title>\n      <link rel=\"icon\" href=\"/favicon.ico\" />\n      <link href=\"https://unpkg.com/tailwindcss@^1.0/dist/tailwind.min.css\" rel=\"stylesheet\" />\n    </Head>\n\n    <div className=\"container mx-auto\">\n\n      <div className=\"flex text-center\">\n        <div className=\"w-full m-4\">\n          <h1 className=\"text-4xl\">Macro Compliance Tracker</h1>\n        </div>\n      </div>\n\n      <div className=\"flex text-center\">\n        <div className=\"w-1/3 bg-gray-200 p-4\">Previous Day</div>\n        <div className=\"w-1/3 p-4\">1/23/2020</div>\n        <div className=\"w-1/3 bg-gray-200 p-4\">Next Day</div>\n      </div>\n\n      <div className=\"flex mb-4 text-center\">\n        <Result results={results.calories} />\n        <Result results={results.carbs} />\n        <Result results={results.fat} />\n        <Result results={results.protein} />\n      </div>\n\n      <div className=\"flex\">\n        <MCTForm data={results} item=\"Total\" onChange={onChange} />\n        <MCTForm data={results} item=\"Target\" onChange={onChange} />\n        <MCTForm data={results} item=\"Variant\" onChange={onChange} />\n      </div>\n\n      <div className=\"flex text-center\">\n        <div className=\"w-full m-4\">\n          <button className=\"bg-blue-500 hover:bg-blue-700 text-white font-bold py-2 px-4 rounded\">\n              Save\n          </button>\n        </div>\n      </div>\n    </div>\n  </div>\n)}\n\nexport default Home\n```\n\nAside from cleaning up the UI code, we also added an onChange function that will be called every time the value of one of the input boxes changes. The onChange function will determine which box was changed and update the data value accordingly as well as re-render the UI to show the new changes.\n\nNext, let's take a look at our implementation of the `MCTForm` component.\n\n``` javascript\nimport React from 'react'\n\nconst MCTForm = ({data, item, onChange}) => {\n  return(\n    <div className=\"w-1/3\">\n      <h2 className=\"text-3xl p-4\">{item}</h2>\n      <div className=\"p-4\">\n        <label className=\"block\">Calories</label>\n        <input type=\"number\" name={item + \" Calories\"} className=\"bg-gray-200 text-gray-700 border rounded py-3 px-4 mb-3 leading-tight focus:outline-none focus:bg-white\" onChange={(e) => onChange(e)}></input>\n      </div>\n      <div className=\"p-4\">\n        <label className=\"block\">Carbs</label>\n        <input type=\"number\" name={item + \" Carbs\"} className=\"bg-gray-200 text-gray-700 border rounded py-3 px-4 mb-3 leading-tight focus:outline-none focus:bg-white\" onChange={(e) => onChange(e)}></input>\n      </div>\n      <div className=\"p-4\">\n        <label className=\"block\">Fat</label>\n        <input type=\"number\" name={item + \" Fat\"} className=\"bg-gray-200 text-gray-700 border rounded py-3 px-4 mb-3 leading-tight focus:outline-none focus:bg-white\" onChange={(e) => onChange(e)}></input>\n      </div>\n      <div className=\"p-4\">\n        <label className=\"block\">Protein</label>\n        <input type=\"number\" name={item + \" Protein\"} className=\"bg-gray-200 text-gray-700 border rounded py-3 px-4 mb-3 leading-tight focus:outline-none focus:bg-white\" onChange={(e) => onChange(e)}></input>\n      </div>\n    </div>\n  )\n}\n\nexport default MCTForm\n```\n\nAs you can see this component is in charge of rendering our forms. Since the input boxes are the same for all three types of forms, we can reuse the component multiple times and just change the type of data we are working with.\n\nAgain if we look at our application in the browser now, it doesn't look much different. But now the form works. We can replace the values and the application will be dynamically updated showing our new total calories and macros and whether or not we are in compliance with our goals. Go ahead and play around with it for a little bit to make sure it all works.\n\n## Connecting Our Application to MongoDB\n\nOur application is looking good. It also works. But, the data is all in memory. As soon as we refresh our page, all the data is reset to the default values. In this sense, our app is not very useful. So our next step will be to connect our application to a database so that we can start seeing our progress over time. We'll use MongoDB and [MongoDB Atlas](https://www.mongodb.com/cloud/atlas) to accomplish this.\n\n## Setting Up Our MongoDB Database\n\nBefore we can save our data, we'll need a database. For this I'll use MongoDB and MongoDB Atlas to host my database. If you don't already have MongoDB Atlas, you can sign up and use it for [free here](https://www.mongodb.com/atlas), otherwise go into an existing cluster and create a new database. Inside MongoDB Atlas, I will use an existing cluster and set up a new database called MCT. With this new database created, I will create a new collection called daily that will store my daily results, target macros, as well as allowed variants.\n\n![MongoDB Atlas](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/old_images/nextjs/mongodb-atlas.png)\n\nWith my database set up, I will also add a few days worth of data. Feel free to add your own data or if you'd like the dataset I'm using, you can get it here. I will use [MongoDB Compass](https://www.mongodb.com/download-center/compass) to import and view the data, but you can import the data however you want: use the CLI, add in manually, or use Compass.\n\nThanks to MongoDB's document model, I can represent the data exactly as I had it in-memory. The only additional fields I will have in my MongoDB model is an `_id` field that will be a unique identifier for the document and a date field that will represent the data for a specific date. The image below shows the data model for one document in MongoDB Compass.\n\n![MongoDB Compass](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/old_images/nextjs/mongodb-compass.png)\n\nNow that we have some real data to work with, let's go ahead and connect our Next.js application to our MongoDB Database. Since Next.js is a React based framework that's running Node server-side we will use the excellent Mongo Node Driver to facilitate this connection.\n\n## Connecting Next.js to MongoDB Atlas\n\nOur pages and components directory renders both server-side on the initial load as well as client-side on subsequent page changes. The MongoDB Node Driver works only on the server side and assumes we're working on the backend. Not to mention that our credentials to MongoDB need to be secure and not shared to the client ever.\n\nNot to worry though, this is where Next.js shines. In the pages directory, we can create an additional special directory called api. In this API directory, as the name implies, we can create api endpoints that are executed exclusively on the backend. The best way to see how this works is to go and create one, so let's do that next. In the pages directory, create an api directory, and there create a new file called daily.js.\n\nIn the `daily.js` file, add the following code:\n\n``` javascript\nexport default (req, res) => {\n    res.statusCode = 200\n    res.setHeader('Content-Type', 'application/json')\n    res.end(JSON.stringify({ message: 'Hello from the Daily route' }))\n}\n```\n\nSave the file, go to your browser and navigate to `localhost:3000/api/daily`. What you'll see is the JSON response of `{message:'Hello from the Daily route'}`. This code is only ever run server side and the only thing the browser receives is the response we send. This seems like the perfect place to set up our connection to MongoDB.\n\n![API Endpoint Response](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/old_images/nextjs/api-response.png)\n\nWhile we can set the connection in this daily.js file, in a real world application, we are likely to have multiple API endpoints and for that reason, it's probably a better idea to establish our connection to the database in a middleware function that we can pass to all of our api routes. So as a best practice, let's do that here.\n\nCreate a new middleware directory at the root of the project structure alongside pages and components and call it middleware. The middleware name is not reserved so you could technically call it whatever you want, but I'll stick to middleware for the name. In this new directory create a file called database.js. This is where we will set up our connection to MongoDB as well as instantiate the middleware so we can use it in our API routes.\n\nOur `database.js` middleware code will look like this:\n\n``` javascript\nimport { MongoClient } from 'mongodb';\nimport nextConnect from 'next-connect';\n\nconst client = new MongoClient('{YOUR-MONGODB-CONNECTION-STRING}', {\n  useNewUrlParser: true,\n  useUnifiedTopology: true,\n});\n\nasync function database(req, res, next) {\n  if (!client.isConnected()) await client.connect();\n  req.dbClient = client;\n  req.db = client.db('MCT');\n  return next();\n}\n\nconst middleware = nextConnect();\n\nmiddleware.use(database);\n\nexport default middleware;\n```\n\nIf you are following along, be sure to replace the `{YOUR-MONGODB-CONNECTION-STRING}` variable with your connection string, as well as ensure that the client.db matches the name you gave your database. Also be sure to run `npm install --save mongodb next-connect` to ensure you have all the correct dependencies. Database names are case sensitive by the way. Save this file and now open up the daily.js file located in the pages/api directory.\n\nWe will have to update this file. Since now we want to add a piece of middleware to our function, we will no longer be using an anonymous function here. We'll utility next-connect to give us a handler chain as well as allow us to chain middleware to the function. Let's take a look at what this will look like.\n\n``` javascript\nimport nextConnect from 'next-connect';\nimport middleware from '../../middleware/database';\n\nconst handler = nextConnect();\n\nhandler.use(middleware);\n\nhandler.get(async (req, res) => {\n\n    let doc = await req.db.collection('daily').findOne()\n    console.log(doc);\n    res.json(doc);\n});\n\nexport default handler;\n```\n\nAs you can see we now have a handler object that gives us much more flexibility. We can use different HTTP verbs, add our middleware, and more. What the code above does, is that it connects to our MongoDB Atlas cluster and from the MCT database and daily collection, finds and returns one item and then renders it to the screen. If we hit `localhost:3000/api/daily` now in our browser we'll see this:\n\n![Daily API Response](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/old_images/nextjs/daily-api.png)\n\nWoohoo! We have our data and the data model matches our in-memory data model, so our next step will be to use this real data instead of our in-memory sample. To do that, we'll open up the index.js page.\n\nOur main component is currently instantiated with an in-memory data model that the rest of our app acts upon. Let's change this. Next.js gives us a couple of different ways to do this. We can always get the data async from our React component, and if you've used React in the past this should be second nature, but since we're using Next.js I think there is a different and perhaps better way to do it.\n\nEach Next.js page component allows us to fetch data server-side thanks to a function called `getStaticProps`. When this function is called, the initial page load is rendered server-side, which is great for SEO. The page doesn't render until this function completes. In `index.js`, we'll make the following changes:\n\n``` javascript\nimport fetch from 'isomorphic-unfetch'\nconst Home = ({data}) => { ... }\n\nexport async function getStaticProps(context) {\n  const res = await fetch(\"http://localhost:3000/api/daily\");\n  const json = await res.json();\n  return {\n    props: {\n      data: json,\n    },\n  };\n}\n\nexport default Home\n```\n\nInstall the `isomorphic-unfetch` library by running `npm install --save isomorphic-unfetch`, then below your Home component add the `getStaticProps` method. In this method we're just making a fetch call to our daily API endpoint and storing that json data in a prop called data. Since we created a data prop, we then pass it into our Home component, and at this point, we can go and remove our in-memory data variable. Do that, save the file, and refresh your browser.\n\nCongrats! Your data is now coming live from MongoDB. But at the moment, it's only giving us one result. Let's make a few final tweaks so that we can see daily results, as well as update the data and save it in the database.\n\n## View Macro Compliance Tracker Data By Day\n\nThe first thing we'll do is add the ability to hit the Previous Day and Next Day buttons and display the corresponding data. We won't be creating a new endpoint since I think our daily API endpoint can do the job, we'll just have to make a few enhancements. Let's do those first.\n\nOur new daily.js API file will look as such:\n\n``` javascript\nhandler.get(async (req, res) => {\n    const { date } = req.query;\n\n    const dataModel = { \"_id\": new ObjectID(), \"date\": date, \"calories\": { \"label\": \"Calories\", \"total\": 0, \"target\": 0, \"variant\": 0 }, \"carbs\": { \"label\": \"Carbs\", \"total\": 0, \"target\": 0, \"variant\": 0 }, \"fat\": { \"label\" : \"Fat\", \"total\": 0, \"target\": 0, \"variant\": 0 }, \"protein\": { \"label\" : \"Protein\", \"total\": 0, \"target\": 0, \"variant\": 0 }}\n\n    let doc = {}\n\n    if(date){\n        doc = await req.db.collection('daily').findOne({date: new Date(date)})\n    } else {\n        doc = await req.db.collection('daily').findOne()\n    }\n    if(doc == null){\n        doc = dataModel\n    }\n    res.json(doc)\n});\n```\n\nWe made a couple of changes here so let's go through them one by one.  The first thing we did was we are looking for a date query parameter to see if one was passed to us. If a date parameter was not passed, then we'll just pick a random item using the `findOne` method. But, if we did receive a date, then we'll query our MongoDB database against that date and return the data for that specified date.\n\nNext, as our data set is not exhaustive, if we go too far forwards or backwards, we'll eventually run out of data to display, so we'll create an empty in-memory object that serves as our data model. If we don't have data for a specified date in our database, we'll just set everything to 0 and serve that. This way we don't have to do a whole lot of error handling on the front and can always count on our backend to serve some type of data.\n\nNow, open up the `index.js` page and let's add the functionality to see the previous and next days. We'll make use of dayjs to handle our dates, so install it by running `npm install --save dayjs` first. Then make the following changes to your `index.js` page:\n\n``` javascript\n// Other Imports ...\nimport dayjs from 'dayjs'\n\nconst Home = ({data}) => {\n  const [results, setResults] = useState(data);\n\n  const onChange = (e) => {\n  }\n\n  const getDataForPreviousDay = async () => {\n    let currentDate = dayjs(results.date);\n    let newDate = currentDate.subtract(1, 'day').format('YYYY-MM-DDTHH:mm:ss')\n    const res = await fetch('http://localhost:3000/api/daily?date=' + newDate)\n    const json = await res.json()\n\n    setResults(json);\n  }\n\n  const getDataForNextDay = async () => {\n    let currentDate = dayjs(results.date);\n    let newDate = currentDate.add(1, 'day').format('YYYY-MM-DDTHH:mm:ss')\n    const res = await fetch('http://localhost:3000/api/daily?date=' + newDate)\n    const json = await res.json()\n\n    setResults(json);\n  }\n\nreturn (\n      <div className=\"flex text-center\">\n        <div className=\"w-1/3 bg-gray-200 p-4\"><button onClick={getDataForPreviousDay}>Previous Day</button></div>\n        <div className=\"w-1/3 p-4\">{dayjs(results.date).format('MM/DD/YYYY')}</div>\n        <div className=\"w-1/3 bg-gray-200 p-4\"><button onClick={getDataForNextDay}>Next Day</button></div>\n      </div>\n\n)}\n```\n\nWe added two new methods, one to get the data from the previous day and one to get the data from the following day. In our UI we also made the date label dynamic so that it displays and tells us what day we are currently looking at. With these changes go ahead and refresh your browser and you should be able to see the new data for days you have entered in your database. If a particular date does not exist, it will show 0's for everything.\n\n![MCT No Data](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/old_images/nextjs/no-data-for-day.png)\n\n## Saving and Updating Data In MongoDB\n\nFinally, let's close out this tutorial by adding the final piece of functionality to our app, which will be to make updates and save new data into our MongoDB database. Again, I don't think we need a new endpoint for this, so we'll use our existing daily.js API. Since we're using the handler convention and currently just handle the GET verb, let's add onto it by adding logic to handle a POST to the endpoint.\n\n``` javascript\nhandler.post(async (req, res) => {\n  let data = req.body;\n  data = JSON.parse(data);\n  data.date = new Date(data.date);\n  let doc = await req.db.collection('daily').updateOne({date: new Date(data.date)}, {$set:data}, {upsert: true})\n\n  res.json({message: 'ok'});\n})\n```\n\nThe code is pretty straightforward. We'll get our data in the body of the request, parse it, and then save it to our MongoDB daily collection using the `updateOne()` method. Let's take a closer look at the values we're passing into the `updateOne()` method.\n\nThe first value we pass will be what we match against, so in our collection if we find that the specific date already has data, we'll update it. The second value will be the data we are setting and in our case, we're just going to set whatever the front-end client sends us. Finally, we are setting the upsert value to true. What this will do is, if we cannot match on an existing date, meaning we don't have data for that date already, we'll go ahead and create a new record.\n\nWith our backend implementation complete, let's add the functionality on our front end so that when the user hits the Save button, the data gets properly updated. Open up the index.js file and make the following\nchanges:\n\n``` javascript\nconst Home = ({data}) => {\n  const updateMacros = async () => {\n    const res = await fetch('http://localhost:3000/api/daily', {\n      method: 'post',\n      body: JSON.stringify(results)\n    })\n  }\n\n  return (\n      <div className=\"flex text-center\">\n        <div className=\"w-full m-4\">\n          <button className=\"bg-blue-500 hover:bg-blue-700 text-white font-bold py-2 px-4 rounded\" onClick={updateMacros}>\n              Save\n          </button>\n        </div>\n      </div>\n)}\n```\n\nOur new updateMacros method will make a POST request to our daily API endpoint with the new data. Try it now! You should be able to update existing macros or create data for new days that you don't already have any data for. We did it!\n\n## Putting It All Together\n\nWe went through a lot in today's tutorial. Next.js is a powerful framework for building modern web applications and having a flexible database powered by MongoDB made it possible to build a fully fledged application in no time at all. There were a couple of items we omitted for brevity such as error handling and deployment, but feel free to [clone the application from GitHub](https://github.com/kukicado/building-modern-app-with-nextjs-and-mongodb), [sign up for MongoDB Atlas for free](https://www.mongodb.com/atlas), and build on top of this foundation.","originalPublishDate":"2022-01-27T13:41:29.003Z","SEO":"61b80325e454ca0b0d528788","related_content":[],"createdAt":"2021-12-14T02:36:21.590Z","originalUpdatedAt":"2022-01-27T13:41:29.049Z","image":{"_id":"627d219d8891f3001d997e80","name":"*JavaScript Banner_1280x720.png","alternativeText":"","caption":"","hash":"Java_Script_Banner_1280x720_693cc74a1d","ext":".png","mime":"image/png","size":29.79,"width":1280,"height":720,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/Java_Script_Banner_1280x720_693cc74a1d.png","formats":{"thumbnail":{"name":"*thumbnail_JavaScript Banner_1280x720.png","hash":"thumbnail_Java_Script_Banner_1280x720_693cc74a1d","ext":".png","mime":"image/png","width":245,"height":138,"size":12.88,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/thumbnail_Java_Script_Banner_1280x720_693cc74a1d.png"},"large":{"name":"*large_JavaScript Banner_1280x720.png","hash":"large_Java_Script_Banner_1280x720_693cc74a1d","ext":".png","mime":"image/png","width":1000,"height":563,"size":69.95,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/large_Java_Script_Banner_1280x720_693cc74a1d.png"},"medium":{"name":"*medium_JavaScript Banner_1280x720.png","hash":"medium_Java_Script_Banner_1280x720_693cc74a1d","ext":".png","mime":"image/png","width":750,"height":422,"size":48.35,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/medium_Java_Script_Banner_1280x720_693cc74a1d.png"},"small":{"name":"*small_JavaScript Banner_1280x720.png","hash":"small_Java_Script_Banner_1280x720_693cc74a1d","ext":".png","mime":"image/png","width":500,"height":281,"size":28.93,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/small_Java_Script_Banner_1280x720_693cc74a1d.png"}},"provider":"aws-s3","related":["6244b4fd7a304f0ca6c4d9e7","6244b4fd7a304f0ca6c4d9f0","6244b4fd7a304f0ca6c4da87","6244b4fd7a304f0ca6c4da00","6244b4fd7a304f0ca6c4da03","6244b4fd7a304f0ca6c4da05","6244b4fd7a304f0ca6c4da7c","6244b4fd7a304f0ca6c4da08","6244b4fd7a304f0ca6c4d979"],"createdAt":"2022-05-12T15:02:53.632Z","updatedAt":"2022-05-12T16:09:48.058Z","__v":0,"created_by":"60acfb196a6d99001c58c549","updated_by":"60acfb196a6d99001c58c549","id":"627d219d8891f3001d997e80"},"updated_by":"62bc6e657fbd69001dfd486e","description":"Learn how to couple Next.js and MongoDB for your next-generation applications.","__v":3,"other_tags":[{"__component":"other-tag-info.other-tag-info","id":"625849504a0541001d381361"}],"primary_tag":[{"__component":"primary-tag-info.programming-language","id":"625849504a0541001d38135f"}],"updatedAt":"2022-09-23T15:06:15.256Z","calculated_slug":"/languages/javascript/nextjs-building-modern-applications","published_at":"2022-05-09T19:16:15.341Z","expiry_date":"2022-12-14T02:36:21.590Z","id":"6244b4fd7a304f0ca6c4da08"},{"awaiting_editorial_review":false,"awaiting_technical_review":false,"editorial_review_LGTM":true,"technical_review_LGTM":true,"authors":["60ec57b2ac2aef22719767ba"],"_id":"6244b4fd7a304f0ca6c4d9ef","type":"HowTo","name":"*Build a RESTful API with Flask, MongoDB, and Python","slug":"/flask-python-mongodb","content":">This is the first part of a short series of blog posts called \"Rewrite it in Rust (RiiR).\" It's a tongue-in-cheek title for some posts that will investigate the similarities and differences between the same service written in Python with Flask, and Rust with Actix-Web.\n\nThis post will show how I built a RESTful API for a collection of cocktail recipes I just happen to have lying around. The aim is to show an API server with some complexity, so although it's a small example, it will cover important factors such as:\n\n-   Data transformation between the database and a JSON representation.\n-   Data validation.\n-   Pagination.\n-   Error-handling.\n\n## Prerequisites\n\n-   Python 3.8 or above\n-   A MongoDB Atlas cluster. Follow the \"[Get Started with Atlas](https://docs.atlas.mongodb.com/getting-started/)\" guide to create your account and MongoDB cluster. Keep a note of your database username, password, and [connection string](https://docs.atlas.mongodb.com/tutorial/connect-to-your-cluster/#connect-to-your-atlas-cluster) as you will need those later.\n\nThis is an *advanced* guide, so it'll cover a whole bunch of different libraries which can be brought together to build a declarative Restful API server on top of MongoDB. I won't cover repeating patterns in the codebase, so if you want to build the whole thing, I recommend checking out the source code, which is all [on GitHub](https://github.com/mongodb-developer/rewrite-it-in-rust).\n\nIt won't cover the basics of Python, Flask, or MongoDB, so if that's what you're looking for, I recommend checking out the following resources before tackling this post:\n\n-   [Think Python](https://greenteapress.com/wp/think-python-2e/)\n-   [The Python & MongoDB Quickstart Series](https://developer.mongodb.com/quickstart/python-quickstart-crud/)\n-   [Flask Tutorial](https://flask.palletsprojects.com/en/1.1.x/tutorial/)\n-   [Pydantic Documentation](https://pydantic-docs.helpmanual.io/)\n\n## Getting Started\n\nBegin by cloning the sample code source [from GitHub](https://github.com/mongodb-developer/rewrite-it-in-rust). There are four top-level directories:\n\n-   [actix-cocktail-api](https://github.com/mongodb-developer/rewrite-it-in-rust/tree/master/actix-cocktail-api): You can ignore this for now.\n-   [data](https://github.com/mongodb-developer/rewrite-it-in-rust/tree/master/data): This contains an export of my cocktail data. You'll import this into your cluster in a moment.\n-   [flask-cocktail-api](https://github.com/mongodb-developer/rewrite-it-in-rust/tree/master/flask-cocktail-api): The code for this blog post.\n-   [test_scripts](https://github.com/mongodb-developer/rewrite-it-in-rust/tree/master/test_scripts): A few shell scripts that use curl to test the HTTP interface of the API server.\n\nThere are more details in the [GitHub repo](https://github.com/mongodb-developer/rewrite-it-in-rust/tree/master/flask-cocktail-api), but the basics are: Install the project with your virtualenv active:\n\n``` shell\npip install -e .\n```\n\nNext, you should import the data into your cluster. Set the environment variable `$MONGO_URI` to your cluster URI. This environment variable will be used in a moment to import your data, and also by the Flask app. I use `direnv` to configure this, and put the following line in my `.envrc` file in my project's directory:\n\n``` shell\nexport MONGO_URI=\"mongodb+srv://USERNAME:PASSW0RD@cluster0-abcde.azure.mongodb.net/cocktails?retryWrites=true&w=majority\"\n```\n\nNote that your database must be called \"cocktails,\" and the import will create a collection called \"recipes.\" After checking that `$MONGO_URI` is set correctly, run the following command:\n\n``` shell\nmongoimport --uri \"$MONGO_URI\" --file ./recipes.json\n```\n\nNow you should be able to run the Flask app from the\n`flask-cocktail-api` directory:\n\n``` shell\nFLASK_DEBUG=true FLASK_APP=cocktailapi flask run\n```\n\n(You can run `make run` if you prefer.)\n\nCheck the output to ensure it is happy with the configuration, and then in a different terminal window, run the `list_cocktails.sh` script in the `test_scripts` directory. It should print something like this:\n\n``` json\n{\n    \"_links\": {\n        \"last\": {\n            \"href\": \"http://localhost:5000/cocktails/?page=5\"\n        }, \n        \"next\": {\n            \"href\": \"http://localhost:5000/cocktails/?page=5\"\n        }, \n        \"prev\": {\n            \"href\": \"http://localhost:5000/cocktails/?page=3\"\n        }, \n        \"self\": {\n            \"href\": \"http://localhost:5000/cocktails/?page=4\"\n        }\n    }, \n    \"recipes\": [\n        {\n            \"_id\": \"5f7daa198ec9dfb536781b0d\", \n            \"date_added\": null, \n            \"date_updated\": null, \n            \"ingredients\": [\n            {\n                \"name\": \"Light rum\", \n                \"quantity\": {\n                \"unit\": \"oz\", \n                }\n            }, \n            {\n                \"name\": \"Grapefruit juice\", \n                \"quantity\": {\n                \"unit\": \"oz\", \n                }\n            }, \n            {\n                \"name\": \"Bitters\", \n                \"quantity\": {\n                \"unit\": \"dash\", \n                }\n            }\n            ], \n            \"instructions\": [\n            \"Pour all of the ingredients into an old-fashioned glass almost filled with ice cubes\", \n            \"Stir well.\"\n            ], \n            \"name\": \"Monkey Wrench\", \n            \"slug\": \"monkey-wrench\"\n        },\n    ]\n    ...\n```\n\n## Breaking it All Down\n\nThe code is divided into three submodules.\n\n-   `__init__.py` contains all the Flask setup code, and defines all the HTTP routes.\n-   `model.py` contains all the Pydantic model definitions.\n-   `objectid.py` contains a Pydantic field definition that I stole from the [Beanie](https://github.com/roman-right/beanie) object-data mapper for MongoDB.\n\nI mentioned earlier that this code makes use of several libraries:\n\n-   [PyMongo](https://pymongo.readthedocs.io/en/stable/index.html) and [Flask-PyMongo](https://flask-pymongo.readthedocs.io/en/latest/) handle the connection to the database. Flask-PyMongo specifically wraps the database collection object to provide a convenient`find_one_or_404` method.\n-   [Pydantic](https://pydantic-docs.helpmanual.io/usage/exporting_models/) manages data validation, and some aspects of data transformation between the database and a JSON representations.\n-   along with a single function from [FastAPI](https://fastapi.tiangolo.com/).\n\n## Data Validation and Transformation\n\nWhen building a robust API, it's important to validate all the data passing into the system. It would be possible to do this using a stack of `if/else` statements, but it's much more effective to define a schema declaratively, and to allow that to programmatically validate the data being input.\n\nI used a technique that I learned from [Beanie](https://github.com/roman-right/beanie), a new and neat ODM that I unfortunately couldn't practically use on this project, because Beanie is async, and Flask is a blocking framework.\n\nBeanie uses [Pydantic](https://pydantic-docs.helpmanual.io/usage/exporting_models/) to define a schema, and adds a custom Field type for ObjectId.\n\n``` python\n# model.py\n\nclass Cocktail(BaseModel):\n    id: Optional[PydanticObjectId] = Field(None, alias=\"_id\")\n    slug: str\n    name: str\n    ingredients: List[Ingredient]\n    instructions: List[str]\n    date_added: Optional[datetime]\n    date_updated: Optional[datetime]\n\n    def to_json(self):\n        return jsonable_encoder(self, exclude_none=True)\n\n    def to_bson(self):\n        data = self.dict(by_alias=True, exclude_none=True)\n        if data[\"_id\"] is None:\n            data.pop(\"_id\")\n        return data\n```\n\nThis `Cocktail` schema defines the structure of a `Cocktail` instance, which will be validated by Pydantic when instances are created. It includes another embedded schema for `Ingredient`, which is defined in a similar way.\n\nI added convenience functions to export the data in the `Cocktail` instance to either a JSON-compatible `dict` or a BSON-compatible `dict`. The differences are subtle, but BSON supports native `ObjectId` and `datetime` types, for example, whereas when encoding as JSON, it's necessary to encode ObjectId instances in some other way (I prefer a string containing the hex value of the id), and datetime objects are encoded as ISO8601 strings.\n\nThe `to_json` method makes use of a function imported from FastAPI, which recurses through the instance data, encoding all values in a JSON-compatible form. It already handles `datetime` instances correctly, but to get it to handle ObjectId values, I extracted some [custom field](https://github.com/mongodb-developer/rewrite-it-in-rust/blob/master/flask-cocktail-api/src/cocktailapi/objectid.py) code from Beanie, which can be found in `objectid.py`.\n\nThe `to_bson` method doesn't need to pass the `dict` data through `jsonable_encoder`. All the types used in the schema can be directly saved with PyMongo. It's important to set `by_alias` to `True`, so that the key for `_id` is just that, `_id`, and not the schema's `id` without an underscore.\n\n``` python\n# objectid.py\n\nclass PydanticObjectId(ObjectId):\n    \"\"\"\n    ObjectId field. Compatible with Pydantic.\n    \"\"\"\n\n    @classmethod\n    def __get_validators__(cls):\n        yield cls.validate\n\n    @classmethod\n    def validate(cls, v):\n        return PydanticObjectId(v)\n\n    @classmethod\n    def __modify_schema__(cls, field_schema: dict):\n        field_schema.update(\n            type=\"string\",\n            examples=[\"5eb7cf5a86d9755df3a6c593\", \"5eb7cfb05e32e07750a1756a\"],\n        )\n\nENCODERS_BY_TYPE[PydanticObjectId] = str\n```\n\nThis approach is neat for this particular use-case, but I can't help feeling that it would be limiting in a more complex system. There are many [patterns for storing data in MongoDB](https://www.mongodb.com/blog/post/building-with-patterns-a-summary). These often result in storing data in a form that is optimal for writes or reads, but not necessarily the representation you would wish to export in an API.\n\n>**What is a Slug?**\n>\n>Looking at the schema above, you may have wondered what a \"slug\" is ... well, apart from a slimy garden pest.\n>\n>A slug is a unique, URL-safe, mnemonic used for identifying a document. I picked up the terminology as a Django developer, where this term is part of the framework. A slug is usually derived from another field. In this case, the slug is derived from the name of the cocktail, so if a cocktail was called \"Rye Whiskey Old-Fashioned,\" the slug would be \"rye-whiskey-old-fashioned.\"\n>\n>In this API, that cocktail could be accessed by sending a `GET` request to the `/cocktails/rye-whiskey-old-fashioned` endpoint.\n>\n>I've kept the unique `slug` field separate from the auto-assigned `_id` field, but I've provided both because the slug could change if the name of the cocktail was tweaked, in which case the `_id` value would provide a constant identifier to look up an exact document.\n\nIn the Rust version of this code, I was nudged to use a different approach. It's a bit more verbose, but in the end I was convinced that it would be more powerful and flexible as the system grew.\n\n## Creating a New Document\n\nNow I'll show you what a single endpoint looks like, first focusing on the \"Create\" endpoint, that handles a POST request to `/cocktails` and creates a new document in the \"recipes\" collection. It then returns the document that was stored, including the newly unique ID that MongoDB assigned as `_id`, because this is a RESTful API, and that's what RESTful APIs do.\n\n``` python\n@app.route(\"/cocktails/\", methods=[\"POST\"])\ndef new_cocktail():\n    raw_cocktail = request.get_json()\n    raw_cocktail[\"date_added\"] = datetime.utcnow()\n\n    cocktail = Cocktail(**raw_cocktail)\n    insert_result = recipes.insert_one(cocktail.to_bson())\n    cocktail.id = PydanticObjectId(str(insert_result.inserted_id))\n    print(cocktail)\n\n    return cocktail.to_json()\n```\n\nThis endpoint modifies the incoming JSON directly, to add a `date_added` item with the current time. It then passes it to the constructor for our Pydantic schema. At this point, if the schema failed to validate the data, an exception would be raised and displayed to the user.\n\nAfter validating the data, `to_bson()` is called on the `Cocktail` to convert it to a BSON-compatible dict, and this is directly passed to PyMongo's `insert_one` method. There's no way to get PyMongo to return the document that was just inserted in a single operation (although an upsert using `find_one_and_update` is similar to just that).\n\nAfter inserting the data, the code then updates the local object with the newly-assigned `id` and returns it to the client.\n\n## Reading a Single Cocktail\n\nThanks to `Flask-PyMongo`, the endpoint for looking up a single cocktail is even more straightforward:\n\n``` python\n@app.route(\"/cocktails/<string:slug>\", methods=[\"GET\"])\ndef get_cocktail(slug):\n    recipe = recipes.find_one_or_404({\"slug\": slug})\n    return Cocktail(**recipe).to_json()\n```\n\nThis endpoint will abort with a 404 if the slug can't be found in the collection. Otherwise, it simply instantiates a Cocktail with the document from the database, and calls `to_json` to convert it to a dict that Flask will automatically encode correctly as JSON.\n\n## Listing All the Cocktails\n\nThis endpoint is a monster, and it's because of pagination, and the links for pagination. In the sample data above, you probably noticed the `_links` section:\n\n``` json\n\"_links\": {\n    \"last\": {\n        \"href\": \"http://localhost:5000/cocktails/?page=5\"\n    }, \n    \"next\": {\n        \"href\": \"http://localhost:5000/cocktails/?page=5\"\n    }, \n    \"prev\": {\n        \"href\": \"http://localhost:5000/cocktails/?page=3\"\n    }, \n    \"self\": {\n        \"href\": \"http://localhost:5000/cocktails/?page=4\"\n    }\n}, \n```\n\nThis `_links` section is specified as part of the [HAL (Hypertext Application\nLanguage)](https://tools.ietf.org/html/draft-kelly-json-hal-00) specification. It's a good idea to follow a standard for pagination data, and I didn't feel like inventing something myself!\n\nAnd here's the code to generate all this. Don't freak out.\n\n``` python\n@app.route(\"/cocktails/\")\ndef list_cocktails():\n    \"\"\"\n    GET a list of cocktail recipes.\n\n    The results are paginated using the `page` parameter.\n    \"\"\"\n\n    page = int(request.args.get(\"page\", 1))\n    per_page = 10  # A const value.\n\n    # For pagination, it's necessary to sort by name,\n    # then skip the number of docs that earlier pages would have displayed,\n    # and then to limit to the fixed page size, ``per_page``.\n    cursor = recipes.find().sort(\"name\").skip(per_page * (page - 1)).limit(per_page)\n\n    cocktail_count = recipes.count_documents({})\n\n    links = {\n        \"self\": {\"href\": url_for(\".list_cocktails\", page=page, _external=True)},\n        \"last\": {\n            \"href\": url_for(\n                \".list_cocktails\", page=(cocktail_count // per_page) + 1, _external=True\n            )\n        },\n    }\n    # Add a 'prev' link if it's not on the first page:\n    if page > 1:\n        links[\"prev\"] = {\n            \"href\": url_for(\".list_cocktails\", page=page - 1, _external=True)\n        }\n    # Add a 'next' link if it's not on the last page:\n    if page - 1 < cocktail_count // per_page:\n        links[\"next\"] = {\n            \"href\": url_for(\".list_cocktails\", page=page + 1, _external=True)\n        }\n\n    return {\n        \"recipes\": [Cocktail(**doc).to_json() for doc in cursor],\n        \"_links\": links,\n    }\n```\n\nAlthough there's a lot of code there, it's not as complex as it may first appear. Two requests are made to MongoDB: one for a page-worth of cocktail recipes, and the other for the total number of cocktails in the collection. Various calculations are done to work out how many documents to skip, and how many pages of cocktails there are. Finally, some links are added for \"prev\" and \"next\" pages, if appropriate (i.e.: the current page isn't the first or last.) Serialization of the cocktail documents is done in the same way as the previous endpoint, but in a loop this time.\n\nThe update and delete endpoints are mainly repetitions of the code I've already included, so I'm not going to include them here. Check them out in the [GitHub repo](https://github.com/mongodb-developer/rewrite-it-in-rust/blob/master/flask-cocktail-api/src/cocktailapi/__init__.py) if you want to see how they work.\n\n## Error Handling\n\nNothing irritates me more than using a JSON API which returns HTML when an error occurs, so I was keen to put in some reasonable error handling to avoid this happening.\n\nAfter Flask set-up code, and before the endpoint definitions, the code registers two error-handlers:\n\n``` python\n@app.errorhandler(404)\ndef resource_not_found(e):\n    \"\"\"\n    An error-handler to ensure that 404 errors are returned as JSON.\n    \"\"\"\n    return jsonify(error=str(e)), 404\n\n\n@app.errorhandler(DuplicateKeyError)\ndef resource_not_found(e):\n    \"\"\"\n    An error-handler to ensure that MongoDB duplicate key errors are returned as JSON.\n    \"\"\"\n    return jsonify(error=f\"Duplicate key error.\"), 400\n```\n\nThe first error-handler intercepts any endpoint that fails with a 404 status code and ensures that the error is returned as a JSON dict.\n\nThe second error-handler intercepts a `DuplicateKeyError` raised by any endpoint, and does the same thing as the first error-handler, but sets the HTTP status code to \"400 Bad Request.\"\n\nAs I was writing this post, I realised that I've missed an error-handler to deal with invalid Cocktail data. I'll leave implementing that as an exercise for the reader! Indeed, this is one of the difficulties with writing robust Python applications: Because exceptions can be raised from deep in your stack of dependencies, it's very difficult to comprehensively predict what exceptions your application may raise in different circumstances.\n\nThis is something that's very different in Rust, and even though, as you'll see, error-handling in Rust can be verbose and tricky, I've started to love the language for its insistence on correctness.\n\n## Wrapping Up\n\nWhen I started writing this post, I though it would end up being relatively straightforward. As I added the requirement that the code should not just be a toy example, some of the inherent difficulties with building a robust API on top of any database became apparent.\n\nIn this case, Flask may not have been the right tool for the job. I recently wrote a blog post about [building an API with Beanie](https://developer.mongodb.com/article/beanie-odm-fastapi-cocktails/). Beanie and FastAPI are a match made in heaven for this kind of application and will handle validation, transformation, and pagination with much less code. On top of that, they're self-documenting and can provide the data's schema in open formats, including [OpenAPI Spec](https://swagger.io/specification/) and [JSON Schema](https://json-schema.org/)!\n\nIf you're about to build an API from scratch, I strongly recommend you check them out, and you may enjoy reading Aaron Bassett's posts on the [FARM (FastAPI, React, MongoDB) Stack](https://developer.mongodb.com/how-to/FARM-Stack-FastAPI-React-MongoDB/).\n\nI will shortly publish the second post in this series, *Build a Cocktail API with Actix-Web, MongoDB, and Rust*, and then I'll conclude with a third post, *I Rewrote it in Rust—How Did it Go?*, where I'll evaluate the strengths and weaknesses of the two experiments.\n\nThank you for reading. Keep a look out for the upcoming posts!\n\n>If you have questions, please head to our [developer community website](https://community.mongodb.com/) where the MongoDB engineers and the MongoDB community will help you build your next big idea with MongoDB.","originalPublishDate":"2022-01-14T12:56:45.050Z","SEO":"61b7fd84e454ca0b0d5285cd","related_content":[],"createdAt":"2021-12-14T02:12:20.435Z","originalUpdatedAt":"2022-01-14T12:56:45.117Z","image":{"_id":"627d26898891f3001d997e91","name":"*Python Banner_1280x720.png","alternativeText":"","caption":"","hash":"Python_Banner_1280x720_ab74d31ebe","ext":".png","mime":"image/png","size":34.26,"width":1280,"height":720,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/Python_Banner_1280x720_ab74d31ebe.png","formats":{"thumbnail":{"name":"*thumbnail_Python Banner_1280x720.png","hash":"thumbnail_Python_Banner_1280x720_ab74d31ebe","ext":".png","mime":"image/png","width":245,"height":138,"size":11.99,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/thumbnail_Python_Banner_1280x720_ab74d31ebe.png"},"large":{"name":"*large_Python Banner_1280x720.png","hash":"large_Python_Banner_1280x720_ab74d31ebe","ext":".png","mime":"image/png","width":1000,"height":563,"size":67.91,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/large_Python_Banner_1280x720_ab74d31ebe.png"},"medium":{"name":"*medium_Python Banner_1280x720.png","hash":"medium_Python_Banner_1280x720_ab74d31ebe","ext":".png","mime":"image/png","width":750,"height":422,"size":45.36,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/medium_Python_Banner_1280x720_ab74d31ebe.png"},"small":{"name":"*small_Python Banner_1280x720.png","hash":"small_Python_Banner_1280x720_ab74d31ebe","ext":".png","mime":"image/png","width":500,"height":281,"size":27.36,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/small_Python_Banner_1280x720_ab74d31ebe.png"}},"provider":"aws-s3","related":["6244b4fd7a304f0ca6c4d9cd","6244b4fd7a304f0ca6c4d9ce","6244b4fd7a304f0ca6c4da4f","6244b4fd7a304f0ca6c4d9ef","6244b4fd7a304f0ca6c4da01","6244b4fd7a304f0ca6c4d98e","6244b4fd7a304f0ca6c4d9c0","6244b4fd7a304f0ca6c4d9c1","6244b4fd7a304f0ca6c4d9c2","6244b4fd7a304f0ca6c4d9c3","6244b4fd7a304f0ca6c4d9c4","6244b4fd7a304f0ca6c4d9c7","6244b4fd7a304f0ca6c4d9c5","6244b4fd7a304f0ca6c4d9c6","6244b4fd7a304f0ca6c4d9c8"],"createdAt":"2022-05-12T15:23:53.601Z","updatedAt":"2022-05-12T17:03:04.614Z","__v":0,"created_by":"60acfb196a6d99001c58c549","updated_by":"60acfb196a6d99001c58c549","id":"627d26898891f3001d997e91"},"updated_by":"60acfb196a6d99001c58c549","description":"Build a RESTful API with Flask, MongoDB, and Python","__v":3,"other_tags":[{"__component":"other-tag-info.other-tag-info","id":"62585a394a0541001d3813dc"}],"primary_tag":[{"__component":"primary-tag-info.programming-language","id":"62585a394a0541001d3813da"}],"updatedAt":"2022-05-12T16:49:13.884Z","calculated_slug":"/languages/python/flask-python-mongodb","published_at":"2022-05-09T19:15:32.292Z","id":"6244b4fd7a304f0ca6c4d9ef"},{"awaiting_editorial_review":false,"awaiting_technical_review":false,"editorial_review_LGTM":true,"technical_review_LGTM":true,"authors":["61e15b43df707f001cad4aef","62faa9fee50177001c2bf3d1"],"_id":"62fbec9de50177001c2bf3d9","published_at":"2022-09-21T13:42:27.914Z","content":"Kubernetes is now an industry-wide standard when it comes to all things containers, but when it comes to deploying a database, it can be a bit tricky! However, tasks like adding persistence, ensuring redundancy, and database maintenance can be easily handled with [MongoDB Atlas](https://www.mongodb.com/atlas/database). Fortunately, the [MongoDB Atlas Operator](https://www.mongodb.com/kubernetes/atlas-operator) gives you the full benefits of using MongoDB Atlas, while still managing everything from within your Kubernetes cluster. In this tutorial, we’ll deploy a [MERN](https://www.mongodb.com/languages/mern-stack-tutorial) stack application in Kubernetes, install the Atlas operator, and connect our back end to Atlas using a Kubernetes secret.\n\n## Pre-requisites\n* [`kubectl`](https://kubernetes.io/docs/tasks/tools/)\n* [`minikube`](https://minikube.sigs.k8s.io/docs/)\n* [`jq`](https://github.com/stedolan/jq/)\n\nYou can find the complete source code for this application on [Github](https://github.com/mongodb-developer/mern-k8s). It’s a mini travel planner application using MongoDB, Express, React, and Node ([MERN](https://www.mongodb.com/languages/mern-stack-tutorial)). While this tutorial should work for any Kubernetes cluster, we’ll be using Minikube for simplicity and consistency.\n\n## Getting started\n\nWhen it comes to deploying a database on Kubernetes, there’s no simple solution. Apart from persistence and redundancy challenges, you may need to move data to specific geolocated servers to ensure that you comply with GDPR policies. Thus, you’ll need a reliable, scalable, and resilient database once you launch your application into production. \n\nMongoDB Atlas is a full developer data platform that includes the database you love, which takes care of many of the database complexities you’re used to. But, there is a gap between MongoDB Atlas and your Kubernetes cluster. Let’s take a look at the MongoDB Atlas Operator by deploying the example MERN application with a back end and front end.\n\nThis application uses a three-tier application architecture, which will have the following layout within our Kubernetes cluster:\n\n![Kubernetes architecture with the Atlas Operator](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/kubernetes_layout_885ae9b68e.jpg)\n\nTo briefly overview this layout, we’ve got a back end with a deployment that will ensure we have two pods running at any given time, and the same applies for our front end. Traffic is redirected and configured by our ingress, meaning `/api` requests route to our back end and everything else will go to the front end. The back end of our application is responsible for the connection to the database, where we’re using MongoDB Atlas Operator to link to an Atlas instance. \n\n\n## Deploying the application on Kubernetes\n\nTo simplify the installation process of the application, we can use a single `kubectl` command to deploy our demo application on Kubernetes. The single file we’ll use includes all of the deployments and services for the back end and front end of our application, and uses containers created with the Dockerfiles in the folder. \n\nFirst, start by cloning the repository that contains the starting source code.\n\n```\ngit clone https://github.com/mongodb-developer/mern-k8s.git\n\ncd mern-k8s\n```\n\nSecondly, as part of this tutorial, you’ll need to run `minikube tunnel` to access our services at `localhost`.\n\n```\nminikube tunnel\n```\n\nNow, let’s go ahead and deploy everything in our Kubernetes cluster by applying the following `application.yaml` file.\n\n```\nkubectl apply -f k8s/application.yaml\n```\n\nYou can take a look at what you now have running in your cluster by using the `kubectl get` command.\n\n```\nkubectl get all\n```\n\nYou should see multiple pods, services, and deployments for the back end and front end, as well as replicasets. At the moment, they are more likely in a ContainerCreating status. This is because Kubernetes needs to pull the images to its local registry. As soon as the images are ready, the pods will start.\n\nTo see the application in action, simply head to `localhost` in your web browser, and the application should be live!\n\n![Browser view of the demo application](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/initial_demo_b606f20aad.jpg)\n\nHowever, you’ll notice there’s no way to add entries to our application, and this is because we haven’t provided a connection string yet for the back end to connect to a MongoDB instance. For example, if we happen to check the logs for one of the recently created backend pods, we can see that there’s a placeholder for a connection string.\n\n```\nkubectl logs pod/mern-k8s-back-d566cc88f-hhghl\n\nConnecting to database using $ATLAS_CONNECTION_STRING\nServer started on port 3000\nMongoParseError: Invalid scheme, expected connection string to start with \"mongodb://\" or \"mongodb+srv://\"\n```\n\nWe’ve ran into a slight issue, as this demo application is using a placeholder (`$ATLAS_CONNECTION_STRING`) for the MongoDB connection string, which needs to be replaced by a valid connection string from our Atlas cluster. This issue can be taken care of with the MongoDB Atlas Operator, which allows you to manage everything from within Kubernetes and gives you the full advantages of using MongoDB Atlas, including generating a connection string as a Kubernetes secret.\n\n## Using the MongoDB Atlas Operator for Kubernetes\n\nAs there’s currently a gap between your Kubernetes cluster and MongoDB Atlas, let’s use the [Atlas Operator](https://www.mongodb.com/kubernetes/atlas-operator) to remedy this issue. Through the operator, we’ll be able to manage our Atlas projects and clusters from Kubernetes. Specifically, getting your connection string to fix the error we received previously can be done now through Kubernetes secrets, meaning we won’t need to retrieve it from the Atlas UI or CLI.\n\n\n### Why use the Operator?\n\nThe Atlas Operator bridges the gap between Atlas, the MongoDB data platform, and your Kubernetes cluster. By using the operator, you can use `kubectl` and your familiar tooling to manage and set up your Atlas deployments. Particularly, it allows for most of the Atlas functionality and tooling to be performed without having to leave your Kubernetes cluster. Installing the Atlas operator creates the Custom Resource Definitions that will connect to the MongoDB Atlas servers.\n\n\n### Installing the Atlas Operator\n\nThe installation process for the Atlas Operator is as simple as running a `kubectl` command. All of the source code for the operator can be found on the [Github repository](https://github.com/mongodb/mongodb-atlas-kubernetes).\n\n```\nkubectl apply -f https://raw.githubusercontent.com/mongodb/mongodb-atlas-kubernetes/main/deploy/all-in-one.yaml\n```\n\nThis will create new custom resources in your cluster that you can use to create or manage your existing Atlas projects and clusters.\n\n### Creating a MongoDB Atlas cluster \n\nIf you haven't already, head to the [Atlas Registration](https://www.mongodb.com/cloud/atlas/register) page to create your free account. This account will let you create a database on a shared server, and you won't even need a credit card to use it.\n\n### Set up access\n\nIn order for the operator to be able to manage your cluster, you will need to provide it with an API key with the appropriate permissions. Firstly, let’s retrieve the organization ID.\n\nIn the upper left part of the Atlas UI, you will see your organization name in a dropdown. Right next to the dropdown is a gear icon. Clicking on this icon will open up a page called _Organization Settings_. From this page, look for a box labeled _Organization ID_. \n\n![Navigating to the organization settings page](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/organization_settings_home_7c3f0daa0e.jpg)\n\nSave that organization ID somewhere for future use. You can also save it in an environment variable.\n\n```\nexport ORG_ID=60c102....bd\n```\n\n>Note: If using Windows, use:\n\n```\nset ORG_ID=60c102....bd\n```\n\nNext, let’s create an API key. From the same screen, look for the _Access Manager_ option in the left navigation menu. This will bring you to the _Organization Access_ screen. In this screen, follow the [instructions](https://www.mongodb.com/docs/atlas/configure-api-access/#std-label-create-org-api-key) to create a new API key.\n\n![Creating a new API key from the access manager page](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/access_manager_tab_d4bf976fb7.jpg)\n\nThe key will need the **Organization Project Creator** role in order to create new projects and clusters. If you want to manage existing clusters, you will need to provide it with the **Organization Owner** role. Save the API private and public keys. You can also add them to the environment.\n\n![Storing the public and private API key information](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/api_key_credentials_bcc611f1f0.png)\n\n```\nexport ATLAS_PUBLIC_KEY=iwpd...i\nexport ATLAS_PRIVATE_KEY=e13debfb-4f35-4...cb\n```\n\n>Note: If using Windows, use:\n\n```\nset ATLAS_PUBLIC_KEY=iwpd...i\nset ATLAS_PRIVATE_KEY=e13debfb-4f35-4...cb\n```\n\n### Create the Kubernetes secrets\n\nNow that you have created the API key, you can specify those values to the MongoDB Atlas Operator. By creating this secret in our Kubernetes cluster, this will give the operator the necessary permissions to create and manage projects and clusters for our specific Atlas account. \n\nYou can create the secret with `kubectl`, and to keep it simple, let’s name our secret `mongodb-atlas-operator-api-key`. For the operator to be able to find this secret, it needs to be within the namespace `mongodb-atlas-system`.\n\n```\nkubectl create secret generic mongodb-atlas-operator-api-key \\\n    --from-literal=\"orgId=$ORG_ID\" \\\n    --from-literal=\"publicApiKey=$ATLAS_PUBLIC_KEY\" \\\n    --from-literal=\"privateApiKey=$ATLAS_PRIVATE_KEY\" \\\n    -n mongodb-atlas-system\n```\n\nNext, we’ll need to label this secret, which helps the Atlas operator in finding the credentials.\n\n```\nkubectl label secret mongodb-atlas-operator-api-key atlas.mongodb.com/type=credentials -n mongodb-atlas-system\n```\n\n### Create a user password\n\nWe’ll need a password for our database user in order to access our databases, create new databases, etc. However, you won't want to hard code this password into your yaml files. It’s safer to save it as a Kubernetes secret. Just like the API key, this secret will need to be labeled too.\n\n```\nkubectl create secret generic atlaspassword --from-literal=\"password=mernk8s\"\nkubectl label secret atlaspassword atlas.mongodb.com/type=credentials\n```\n\n## Create and manage an Atlas deployment\n\nCongrats! You are now ready to manage your Atlas projects and deployments from Kubernetes. This can be done with the three new CRDs that were added to your cluster. Those CRDs are `AtlasProject` to manage projects, `AtlasDeployment` to manage deployments, and `AtlasDatabaseUser` to manage database users within MongoDB Atlas.\n\n* Projects: Allows you to isolate different database environments (for instance, development/qa/prod environments) from each other, as well as users/teams.\n* Deployments: Instance of MongoDB running on a cloud provider.\n* Users: Database users that have access to MongoDB database deployments.\n\nThe process of creating a project, user, and deployment is demonstrated below, but feel free to skip down to simply apply these files by using the `/atlas` folder.\n### Create a project\n\nStart by creating a new project in which the new cluster will be deployed. In a new file called `/operator/project.yaml`, add the following:\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: mern-k8s-project\nspec:\n  name: \"MERN K8s\"\n  projectIpAccessList:\n    - ipAddress: \"0.0.0.0/0\"\n      comment: \"Allowing access to database from everywhere (only for Demo!)\"\n```\n\nThis will create a new project called \"MERN K8s\" in Atlas. Now, this project will be open to anyone on the web. It’s best practice to only open it to known IP addresses as mentioned in the comment.\n\n### Create a new database user\n\nNow, in order for your application to connect to this database, you will need a database user. To create this user, open a new file called `/operator/user.yaml`, and add the following:\n\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDatabaseUser\nmetadata:\n  name: atlas-user\nspec:\n  roles:\n    - roleName: \"readWriteAnyDatabase\"\n      databaseName: \"admin\"\n  projectRef:\n    name: mern-k8s-project\n  username: mernk8s\n  passwordSecretRef:\n    name: atlaspassword\n```\n\nYou can see how the password uses the secret we created earlier, `atlaspassword`, in the `mern-k8s-project` namespace.\n\n### Create a deployment\n\nFinally, as you have a project setup and user to connect to the database, you can create a new deployment inside this project. In a new file called `/operator/deployment.yaml`, add the following yaml.\n\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDeployment\nmetadata:\n  name: mern-k8s-cluster\nspec:\n  projectRef:\n    name: mern-k8s-project\n  deploymentSpec:\n    name: \"Cluster0\"\n    providerSettings:\n      instanceSizeName: M0\n      providerName: TENANT\n      regionName: US_EAST_1\n      backingProviderName: AWS\n```\n\nThis will create a new M0 (free) deployment on AWS, in the US_EAST_1 region. Here, we’re referencing the `mern-k8s-project` in our Kubernetes namespace, and creating a cluster named `Cluster0`. You can use a similar syntax to deploy in any region on AWS, GCP, or Azure. To create a serverless instance, see the [serverless instance example](https://www.mongodb.com/docs/atlas/reference/atlas-operator/atlasdeployment-custom-resource/#std-label-ak8so-serverless-instance).\n\n\n### Apply the new files\n\nYou now have everything ready to create this new project and cluster. You can apply those new files to your cluster using:\n\n```\nkubectl apply -f ./operator\n```\n\nThis will take a couple of minutes. You can see the status of the cluster and project creation with `kubectl`.\n\n```\nkubectl get atlasprojects\nkubectl get atlasdeployments\n```\n\nIn the meantime, you can go to the Atlas UI. The project should already be created, and you should see that a cluster is in the process of being created.\n\n![Viewing the newly created cluster](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/database_deployments_18fac98898.jpg)\n\n### Get your connection string\n\nGetting your connection string to that newly created database can now be done through Kubernetes. Once your new database has been created, you can use the following command that uses `jq` to view the connection strings, without using the Atlas UI, by converting to JSON from Base64. \n\n```\nkubectl get secret mern-k8s-cluster0-mernk8s -o json | jq -r '.data | with_entries(.value |= @base64d)'\n\n{\n…\n  \"connectionStringStandard\": \"![](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/api_key_credentials_bcc611f1f0.png)\",\n  \"connectionStringStandardSrv\": \"mongodb+srv://mernk8s:mernk8s@cluster0.fb4qw.mongodb.net\",\n  \"password\": \"mernk8s\",\n  \"username\": \"mernk8s\"\n}\n```\n\n## Configure the application back end using the Atlas operator\n\nNow that your project and cluster are created, you can access the various properties from your Atlas instance. You can now access the connection string, and even configure your backend service to use that connection string. We’ll go ahead and connect our back end to our database without actually specifying the connection string, instead using the Kubernetes secret we just created.\n\n### Update the backend deployment\n\nNow that you can find your connection string from within Kubernetes, you can use that as part of your deployment to specify the connection string to your back end.\n\nIn your `/k8s/application.yaml` file, change the `env` section of the containers template to the following:\n\n```\n          env: \n            - name: PORT\n              value: \"3000\"\n            - name: \"CONN_STR\"\n              valueFrom:\n                secretKeyRef:\n                  name: mern-k8s-cluster0-mernk8s\n                  key: connectionStringStandardSrv\n```\n\nThis will use the same connection string you've just seen in your terminal.\n\nSince we’ve changed our deployment, you can apply those changes to your cluster using `kubectl`:\n\n```\n​​kubectl apply -f k8s/application.yaml\n```\n\nNow, if you take a look at your current pods:\n\n```\nkubectl get pods\n```\n\nYou should see that your backend pods have been restarted. You should now be able to test the application with the back end connected to our newly created Atlas cluster. Now, just head to `localhost` to view the updated application once the deployment has restarted. You’ll see the application fully running, using this newly created cluster.  \n\n![Fully functioning demo application, connected to MongoDB Atlas](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/Travel_Demo_3d8885d4a0.gif)\n\nIn addition, as you add items or perhaps clear the entries of the travel planner, you’ll notice the entries added and removed from the “Collections” tab of the `Cluster0` database within the Atlas UI. Let’s take a look at our database using [MongoDB Compass](https://www.mongodb.com/products/compass), with username `mernk8s` and password `mernk8s` as we set previously.\n\n![MongoDB Compass connected to our mern-k8s database](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/compass_entries_c4a8cb98ef.jpg)\n\n### Delete project\n\nLet’s finish off by using `kubectl` to delete the Atlas cluster and project and clean up our workspace. We can delete everything from the current namespace by using `kubectl delete`\n\n \n```\nkubectl delete atlasdeployment mern-k8s-cluster\nkubectl delete atlasproject mern-k8s-project\n```\n\n\n## Summary\n\nYou now know how to leverage the MongoDB Atlas Operator to create and manage clusters from Kubernetes. We’ve only demonstrated a small bit of the functionality the operator provides, but feel free to head to the [documentation](https://docs.atlas.mongodb.com/atlas-operator/) to learn more.\n\nIf you are using MongoDB Enterprise instead of Atlas, there is also an [Operator](https://www.mongodb.com/try/download/enterprise-kubernetes-operator) available, which works in very similar fashion.\n\nTo go through the full lab by Joel Lord, which includes this guide and much more, check out the self-guided [Atlas Operator Workshop](https://joellord.github.io/mern-k8s/).","slug":"/kubernetes-operator-application-deployment","description":"Get started with application deployment into a Kubernetes cluster using the MongoDB Atlas Operator.","name":"*Application Deployment in Kubernetes with the MongoDB Atlas Operator ","SEO":"62fbec9de50177001c2bf3da","related_content":[],"primary_tag":[{"__component":"primary-tag-info.l1-product","id":"62fbedf75e1aa1001c3651b0"}],"other_tags":[{"__component":"other-tag-info.other-tag-info","id":"62fbedf75e1aa1001c3651b2"}],"createdAt":"2022-08-16T19:14:37.800Z","updatedAt":"2022-09-21T13:42:28.000Z","__v":1,"created_by":"62f69525e50177001c2bf394","image":{"_id":"62fbe311e50177001c2bf3d3","name":"*kubernetes-mongodb.png","alternativeText":"Graphic of Kubernetes and MongoDB","caption":"","hash":"kubernetes_a5532846faec9169d6529589c8b882b1_7bb3e4a04b","ext":".png","mime":"image/png","size":75.08,"width":1376,"height":880,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/kubernetes_a5532846faec9169d6529589c8b882b1_7bb3e4a04b.png","formats":{"thumbnail":{"name":"*thumbnail_kubernetes-a5532846faec9169d6529589c8b882b1.png","hash":"thumbnail_kubernetes_a5532846faec9169d6529589c8b882b1_7bb3e4a04b","ext":".png","mime":"image/png","width":244,"height":156,"size":30.18,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/thumbnail_kubernetes_a5532846faec9169d6529589c8b882b1_7bb3e4a04b.png"},"large":{"name":"*large_kubernetes-a5532846faec9169d6529589c8b882b1.png","hash":"large_kubernetes_a5532846faec9169d6529589c8b882b1_7bb3e4a04b","ext":".png","mime":"image/png","width":1000,"height":640,"size":156.48,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/large_kubernetes_a5532846faec9169d6529589c8b882b1_7bb3e4a04b.png"},"medium":{"name":"*medium_kubernetes-a5532846faec9169d6529589c8b882b1.png","hash":"medium_kubernetes_a5532846faec9169d6529589c8b882b1_7bb3e4a04b","ext":".png","mime":"image/png","width":750,"height":480,"size":108.12,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/medium_kubernetes_a5532846faec9169d6529589c8b882b1_7bb3e4a04b.png"},"small":{"name":"*small_kubernetes-a5532846faec9169d6529589c8b882b1.png","hash":"small_kubernetes_a5532846faec9169d6529589c8b882b1_7bb3e4a04b","ext":".png","mime":"image/png","width":500,"height":320,"size":67.38,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/small_kubernetes_a5532846faec9169d6529589c8b882b1_7bb3e4a04b.png"}},"provider":"aws-s3","related":["62fbec9de50177001c2bf3d9"],"createdAt":"2022-08-16T18:33:53.219Z","updatedAt":"2022-08-17T02:33:02.678Z","__v":0,"created_by":"62f69525e50177001c2bf394","updated_by":"62f69525e50177001c2bf394","id":"62fbe311e50177001c2bf3d3"},"updated_by":"60c21cda1ef87b001cc8c98b","calculated_slug":"/products/atlas/kubernetes-operator-application-deployment","expiry_date":"2023-08-16T19:14:37.800Z","originalPublishDate":"2022-08-16T16:00:00.000Z","id":"62fbec9de50177001c2bf3d9"}],"podcasts":[],"videos":[],"events":[],"_id":"6304dc795e1aa1001c365215","__v":0,"content_type":{"_id":"624af00cce7cde001ccae93e","content_type":"Tutorial","published_at":"2022-05-09T18:37:17.435Z","createdAt":"2022-04-04T13:18:04.609Z","updatedAt":"2022-05-09T18:37:17.534Z","__v":0,"created_by":"61f82d1bdf707f001cad52ff","updated_by":"61f82d1bdf707f001cad52ff","calculated_slug":"/tutorials","id":"624af00cce7cde001ccae93e"},"id":"6304dc795e1aa1001c365215"},{"__component":"featured-category.programming-language","articles":[{"awaiting_editorial_review":false,"awaiting_technical_review":false,"editorial_review_LGTM":true,"technical_review_LGTM":true,"authors":["61969d2aa0957d40b0be68bd"],"_id":"6244b4fd7a304f0ca6c4d9aa","type":"Quickstart","name":"*MongoDB & C Sharp: CRUD Operations Tutorial","slug":"/csharp-crud-tutorial","content":"<div>\n    <img style=\"float: right;\n        border-radius: 10px;\n        margin-bottom: 30px;\n        vertical-align: bottom;\n        width: 30%;\"\n        src=\"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/old_images/qs-badges/qs-badge-csharp.png\"\n        alt=\"C# badge\"\n    />\n\nIn this Quick Start post, I'll show how to set up connections between C# and MongoDB. Then I'll walk through the database Create, Read, Update, and Delete (CRUD) operations. As you already know, C# is a general-purpose language and MongoDB is a general-purpose data platform.  Together, C# and MongoDB are a powerful combination.\n\n</div>\n\n## Series Tools & Versions\n\nThe tools and versions I'm using for this series are:\n\n-   MongoDB Atlas with an M0 free cluster,\n-   MongoDB Sample Dataset loaded, specifically the `sample_training` and `grades` dataset,\n-   Windows 10,\n-   Visual Studio Community 2019,\n-   [NuGet](http://bit.ly/nuget-home) packages,\n-   MongoDB [C# Driver](http://bit.ly/mongodb-csharp-driver-github): version 2.9.1,\n-   MongoDB BSON Library: version 2.9.1.\n\n>C# is a popular language when using the .NET framework. If you're going to be developing in .NET and using MongoDB as your data layer, the C# driver makes it easy to do so.\n\n## Setup\n\nTo follow along, I'll be using Visual Studio 2019 on Windows 10 and connecting to a MongoDB Atlas cluster. If you're using a different OS, IDE, or text editor, the walkthrough might be slightly different, but the code itself should be fairly similar. Let's jump in and take a look at how nicely C# and MongoDB work together.\n\n>Get started with an M0 cluster on [MongoDB Atlas](http://bit.ly/mongodb-meetatlas) today. It's free forever and you'll be able to work alongside this blog series.\n\nFor this demonstration, I've chosen a Console App (.NET Core), and I've named it `MongoDBConnectionDemo`. Next, we need to install the MongoDB Driver for C#/.NET for a Solution. We can do that quite easily with [NuGet](http://bit.ly/nuget-home). Inside Visual Studio for Windows, by going to *Tools* -> *NuGet Package Manager* -> Manage NuGet Packages for Solution... We can browse for *MongoDB.Driver*. Then click on our Project and select the driver version we want. In this case, the [latest stable version](http://bit.ly/mongodb-csharp-driver) is 2.9.1. Then click on *Install*. Accept any license agreements that pop up and head into `Program.cs` to get started.\n\n### Putting the Driver to Work\n\nTo use the `MongoDB.Driver` we need to add a directive.\n\n``` csp\nusing MongoDB.Driver;\n```\n\nInside the `Main()` method we'll establish a connection to [MongoDB Atlas](http://bit.ly/mongodb-atlas) with a connection string and to test the connection we'll print out a list of the databases on the server.  The Atlas cluster to which we'll be connecting has the MongoDB Atlas [Sample Dataset](http://bit.ly/atlas-sample-data-blog) installed, so we'll be able to see a nice database list.\n\nThe first step is to pass in the MongoDB Atlas connection string into a MongoClient object, then we can get the list of databases and print them out.\n\n``` csp\nMongoClient dbClient = new MongoClient(<<YOUR ATLAS CONNECTION STRING>>);\n\nvar dbList = dbClient.ListDatabases().ToList();\n\nConsole.WriteLine(\"The list of databases on this server is: \");\nforeach (var db in dbList)\n{\n    Console.WriteLine(db);\n}\n```\n\nWhen we run the program, we get the following out showing the list of databases:\n\n``` bash\nThe list of databases on this server is:\n{ \"name\" : \"sample_airbnb\", \"sizeOnDisk\" : 57466880.0, \"empty\" : false }\n{ \"name\" : \"sample_geospatial\", \"sizeOnDisk\" : 1384448.0, \"empty\" : false }\n{ \"name\" : \"sample_mflix\", \"sizeOnDisk\" : 45084672.0, \"empty\" : false }\n{ \"name\" : \"sample_supplies\", \"sizeOnDisk\" : 1347584.0, \"empty\" : false }\n{ \"name\" : \"sample_training\", \"sizeOnDisk\" : 73191424.0, \"empty\" : false }\n{ \"name\" : \"sample_weatherdata\", \"sizeOnDisk\" : 4427776.0, \"empty\" : false }\n{ \"name\" : \"admin\", \"sizeOnDisk\" : 245760.0, \"empty\" : false }\n{ \"name\" : \"local\", \"sizeOnDisk\" : 1919799296.0, \"empty\" : false }\n```\n\nThe whole program thus far comes in at just over 20 lines of code:\n\n``` csp\nusing System;\nusing MongoDB.Driver;\n\nnamespace test\n{\n    class Program\n    {\n        static void Main(string[] args)\n        {\n            MongoClient dbClient = new MongoClient(<<YOUR ATLAS CONNECTION STRING>>);\n\n            var dbList = dbClient.ListDatabases().ToList();\n\n            Console.WriteLine(\"The list of databases on this server is: \");\n            foreach (var db in dbList)\n            {\n                Console.WriteLine(db);\n            }\n        }\n    }\n}\n```\n\nWith a connection in place, let's move on and start doing CRUD operations inside the MongoDB Atlas database. The first step there is to *Create* some data.\n\n## Create\n\n### Data\n\nMongoDB stores data in JSON Documents. Actually, they are stored as Binary JSON (BSON) objects on disk, but that's another blog post. In our sample dataset, there is a `sample_training` with a `grades` collection.  Here's what a sample document in that collection looks like:\n\n``` json\n{\n  \"_id\":{\"$oid\":\"56d5f7eb604eb380b0d8d8ce\"},\n  \"student_id\":{\"$numberDouble\":\"0\"},\n  \"scores\":[\n    {\"type\":\"exam\",\"score\":{\"$numberDouble\":\"78.40446309504266\"}},\n    {\"type\":\"quiz\",\"score\":{\"$numberDouble\":\"73.36224783231339\"}},\n    {\"type\":\"homework\",\"score\":{\"$numberDouble\":\"46.980982486720535\"}},\n    {\"type\":\"homework\",\"score\":{\"$numberDouble\":\"76.67556138656222\"}}\n  ],\n  \"class_id\":{\"$numberDouble\":\"339\"}\n}\n```\n\n### Connecting to a Specific Collection\n\nThere are 10,000 students in this collection, 0-9,999. Let's add one more by using C#. To do this, we'll need to use another package from NuGet, `MongoDB.Bson`. I'll start a new Solution in Visual Studio and call it `MongoDBCRUDExample`. I'll install the `MongoDB.Bson` and `MongoDB.Driver` packages and use the connection string provided from MongoDB Atlas. Next, I'll access our specific database and collection, `sample_training` and `grades`, respectively.\n\n``` csp\nusing System;\nusing MongoDB.Bson;\nusing MongoDB.Driver;\n\nnamespace MongoDBCRUDExample\n{\n    class Program\n    {\n        static void Main(string[] args)\n        {\n            MongoClient dbClient = new MongoClient(<<YOUR ATLAS CONNECTION STRING>>);\n\n    var database = dbClient.GetDatabase(\"sample_training\");\n            var collection = database.GetCollection<BsonDocument>(\"grades\");\n\n        }\n    }\n}\n```\n\n#### Creating a BSON Document\n\nThe `collection` variable is now our key reference point to our data.  Since we are using a `BsonDocument` when assigning our `collection` variable, I've indicated that I'm not going to be using a pre-defined schema. This utilizes the power and flexibility of MongoDB's document model. I could define a plain-old-C#-object (POCO) to more strictly define a schema. I'll take a look at that option in a future post. For now, I'll create a new `BsonDocument` to insert into the database.\n\n``` csp\nvar document = new BsonDocument\n            {\n                { \"student_id\", 10000 },\n                { \"scores\", new BsonArray\n                    {\n                    new BsonDocument{ {\"type\", \"exam\"}, {\"score\", 88.12334193287023 } },\n                    new BsonDocument{ {\"type\", \"quiz\"}, {\"score\", 74.92381029342834 } },\n                    new BsonDocument{ {\"type\", \"homework\"}, {\"score\", 89.97929384290324 } },\n                    new BsonDocument{ {\"type\", \"homework\"}, {\"score\", 82.12931030513218 } }\n                    }\n                },\n                { \"class_id\", 480}\n            };\n```\n\n### Create Operation\n\nThen to *Create* the document in the `sample_training.grades` collection, we can do an insert operation.\n\n``` csp\ncollection.InsertOne(document);\n```\n\nIf you need to do that insert asynchronously, the MongoDB C# driver is fully async compatible. The same operation could be done with:\n\n``` csp\nawait collection.InsertOneAsync(document);\n```\n\nIf you have a need to insert multiple documents at the same time, MongoDB has you covered there as well with the `InsertMany` or `InsertManyAsync` methods.\n\nWe've seen how to structure a BSON Document in C# and then *Create* it inside a MongoDB database. The MongoDB C# Driver makes it easy to do with the `InsertOne()`, `InsertOneAsync()`, `InsertMany()`, or `InsertManyAsync()` methods. Now that we have *Created* data, we'll want to *Read* it.\n\n## Read\n\nTo *Read* documents in MongoDB, we use the [Find()](https://mongodb.github.io/mongo-csharp-driver/2.6/apidocs/html/Overload_MongoDB_Driver_IMongoCollectionExtensions_Find.htm) method. This method allows us to chain a variety of methods to it, some of which I'll explore in this post. To get the first document in the collection, we can use the `FirstOrDefault` or `FirstOrDefaultAsync` method, and print the result to the console.\n\n``` csp\nvar firstDocument = collection.Find(new BsonDocument()).FirstOrDefault();\nConsole.WriteLine(firstDocument.ToString());\n```\n\nreturns...\n\n``` json\n{ \"_id\" : ObjectId(\"56d5f7eb604eb380b0d8d8ce\"),\n\"student_id\" : 0.0,\n\"scores\" : [\n{ \"type\" : \"exam\", \"score\" : 78.404463095042658 },\n{ \"type\" : \"quiz\", \"score\" : 73.362247832313386 },\n{ \"type\" : \"homework\", \"score\" : 46.980982486720535 },\n{ \"type\" : \"homework\", \"score\" : 76.675561386562222 }\n],\n\"class_id\" : 339.0 }\n```\n\nYou may wonder why we aren't using `Single` as that returns one document too. Well, that has to also ensure the returned document is the only document like that in the collection and that means scanning the whole collection.\n\n### Reading with a Filter\n\nLet's find the [document we created](#created-data) and print it out to the console. The first step is to create a filter to query for our specific document.\n\n``` csp\nvar filter = Builders<BsonDocument>.Filter.Eq(\"student_id\", 10000);\n```\n\nHere we're setting a filter to look for a document where the `student_id` is equal to `10000`. We can pass the filter into the `Find()` method to get the first document that matches the query.\n\n``` csp\nvar studentDocument = collection.Find(filter).FirstOrDefault();\nConsole.WriteLine(studentDocument.ToString());\n```\n\nreturns...\n\n``` json\n{ \"_id\" : ObjectId(\"5d88f88cec6103751b8a0d7f\"),\n\"student_id\" : 10000,\n\"scores\" : [\n{ \"type\" : \"exam\", \"score\" : 88.123341932870233 },\n{ \"type\" : \"quiz\", \"score\" : 74.923810293428346 },\n{ \"type\" : \"homework\", \"score\" : 89.979293842903246 },\n{ \"type\" : \"homework\", \"score\" : 82.129310305132179 }\n],\n\"class_id\" : 480 }\n```\n\nIf a document isn't found that matches the query, the `Find()` method returns null. Finding the first document in a collection, or with a query is a frequent task. However, what about situations when all documents need to be returned, either in a collection or from a query?\n\n### Reading All Documents\n\nFor situations in which the expected result set is small, the `ToList()` or `ToListAsync()` methods can be used to retrieve all documents from a query or in a collection.\n\n``` csp\nvar documents = collection.Find(new BsonDocument()).ToList();\n```\n\nFilters can be passed in here as well, for example, to get documents with exam scores equal or above 95. The filter here looks slightly more complicated, but thanks to the MongoDB driver syntax, it is relatively easy to follow. We're filtering on documents in which inside the `scores` array there is an `exam` subdocument with a `score` value greater than or equal to 95.\n\n``` csp\nvar highExamScoreFilter = Builders<BsonDocument>.Filter.ElemMatch<BsonValue>(\n\"scores\", new BsonDocument { { \"type\", \"exam\" },\n{ \"score\", new BsonDocument { { \"$gte\", 95 } } }\n});\nvar highExamScores = collection.Find(highExamScoreFilter).ToList();\n```\n\nFor situations where it's necessary to iterate over the documents that are returned there are a couple of ways to accomplish that as well. In a synchronous situation, a C# `foreach` statement can be used with the `ToEnumerable` adapter method. In this situation, instead of using the `ToList()` method, we'll use the `ToCursor()` method.\n\n``` csp\nvar cursor = collection.Find(highExamScoreFilter).ToCursor();\nforeach (var document in cursor.ToEnumerable())\n{\n     Console.WriteLine(document);\n}\n```\n\nThis can be accomplished in an asynchronous fashion with the `ForEachAsync` method as well:\n\n``` csp\nawait collection.Find(highExamScoreFilter).ForEachAsync(document => Console.WriteLine(document));\n```\n\n### Sorting\n\nWith many documents coming back in the result set, it is often helpful to sort the results. We can use the [Sort()](https://mongodb.github.io/mongo-csharp-driver/2.6/apidocs/html/M_MongoDB_Driver_IFindFluent_2_Sort.htm) method to accomplish this to see which student had the highest exam score.\n\n``` csp\nvar sort = Builders<BsonDocument>.Sort.Descending(\"student_id\");\n\nvar highestScores = collection.Find(highExamScoreFilter).Sort(sort);\n```\n\nAnd we can append the `First()` method to that to just get the top student.\n\n``` csp\nvar highestScore = collection.Find(highExamScoreFilter).Sort(sort).First();\n\nConsole.WriteLine(highestScore);\n```\n\nBased on the [Atlas Sample Data Set](https://docs.atlas.mongodb.com/sample-data/), the document with a `student_id` of 9997 should be returned with an exam score of 95.441609472871946.\n\nYou can see the full code for both the *Create* and *Read* operations I've shown in the [gist here](https://gist.github.com/kenwalger/37299af2b43cfe548e4d3a3154a31e6d).\n\nThe C# Driver for MongoDB provides many ways to *Read* data from the database and supports both synchronous and asynchronous methods for querying the data. By passing a filter into the `Find()` method, we are able to query for specific records. The syntax to build filters and query the database is straightforward and easy to read, making this step of CRUD operations in C# and MongoDB simple to use.\n\nWith the data created and being able to be read, let's take a look at how we can perform *Update* operations.\n\n## Update\n\nSo far in this C# Quick Start for MongoDB CRUD operations, we have explored how to *Create* and *Read* data into a MongoDB database using C#. We saw how to add filters to our query and how to sort the data. This section is about the *Update* operation and how C# and MongoDB work together to accomplish this important task.\n\nRecall that we've been working with this `BsonDocument` version of a student record:\n\n``` csp\nvar document = new BsonDocument\n            {\n                { \"student_id\", 10000 },\n                { \"scores\", new BsonArray\n                    {\n                    new BsonDocument{ {\"type\", \"exam\"}, {\"score\", 88.12334193287023 } },\n                    new BsonDocument{ {\"type\", \"quiz\"}, {\"score\", 74.92381029342834 } },\n                    new BsonDocument{ {\"type\", \"homework\"}, {\"score\", 89.97929384290324 } },\n                    new BsonDocument{ {\"type\", \"homework\"}, {\"score\", 82.12931030513218 } }\n                    }\n                },\n                { \"class_id\", 480}\n            };\n```\n\nAfter getting part way through the grading term, our sample student's instructor notices that he's been attending the wrong class section. Due to this error the school administration has to change, or *update*, the `class_id` associated with his record. He'll be moving into section 483.\n\n### Updating Data\n\nTo update a document we need two bits to pass into an `Update` command.  We need a filter to determine *which* documents will be updated. Second, we need what we're wanting to update.\n\n### Update Filter\n\nFor our example, we want to filter based on the document with `student_id` equaling 10000.\n\n``` csp\nvar filter = Builders<BsonDocument>.Filter.Eq(\"student_id\", 10000)\n```\n\n### Data to be Changed\n\nNext, we want to make the change to the `class_id`. We can do that with `Set()` on the `Update()` method.\n\n``` csp\nvar update = Builders<BsonDocument>.Update.Set(\"class_id\", 483);\n```\n\nThen we use the `UpdateOne()` method to make the changes. Note here that MongoDB will update at most one document using the `UpdateOne()` method.  If no documents match the filter, no documents will be updated.\n\n``` csp\ncollection.UpdateOne(filter, update);\n```\n\n### Array Changes\n\nNot all changes are as simple as changing a single field. Let's use a different filter, one that selects a document with a particular score type for quizes:\n\n``` csp\nvar arrayFilter = Builders<BsonDocument>.Filter.Eq(\"student_id\", 10000) & Builders<BsonDocument>\n                  .Filter.Eq(\"scores.type\", \"quiz\");\n```\n\nNow if we want to make the change to the quiz score we can do that with `Set()` too, but to identify which particular element should be changed is a little different. We can use the [positional $ operator](https://docs.mongodb.com/manual/reference/operator/update/positional/) to access the quiz `score` in the array. The $ operator on its own says \"change the array element that we matched within the query\" - the filter matches with `scores.type` equal to `quiz` and that's the element will get updated with the set.\n\n``` csp\nvar arrayUpdate = Builders<BsonDocument>.Update.Set(\"scores.$.score\", 84.92381029342834);\n```\n\nAnd again we use the `UpdateOne()` method to make the changes.\n\n``` csp\ncollection.UpdateOne(arrayFilter , arrayUpdate);\n```\n\n### Additional Update Methods\n\nIf you've been reading along in this blog series I've mentioned that the C# driver supports both sync and async interactions with MongoDB.  Performing data *Updates* is no different. There is also an `UpdateOneAsync()` method available. Additionally, for those cases in which multiple documents need to be updated at once, there are `UpdateMany()` or `UpdateManyAsync()` options. The `UpdateMany()` and `UpdateManyAsync()` methods match the documents in the `Filter` and will update *all* documents that match the filter requirements.\n\n`Update` is an important operator in the CRUD world. Not being able to update things as they change would make programming incredibly difficult. Fortunately, C# and MongoDB continue to work well together to make the operations possible and easy to use. Whether it's updating a student's grade or updating a user's address, *Update* is here to handle the changes. The code for the *Create*, *Read*, and *Update* operations can be found in [this gist](https://gist.github.com/kenwalger/f5cf317aa85aad2aa0f9d627d7a8095c).\n\nWe're winding down this MongoDB C# Quick Start CRUD operation series with only one operation left to explore, *Delete*.\n\n>Remember, you can get started with an M0 cluster on [MongoDB Atlas](http://bit.ly/mongodb-atlas) today. It's free forever and you'll be able to work alongside this blog series.\n\n## Delete\n\nTo continue along with the student story, let's take a look at how what would happen if the student dropped the course and had to have their grades deleted. Once again, the MongoDB driver for C# makes it a breeze. And, it provides both sync and async options for the operations.\n\n### Deleting Data\n\nThe first step in the deletion process is to create a filter for the document(s) that need to be deleted. In the example for this series, I've been using a document with a `student_id` value of `10000` to work with. Since I'll only be deleting that single record, I'll use the `DeleteOne()` method (for async situations the `DeleteOneAsync()` method is available). However, when a filter matches more than a single document and all of them need to be deleted, the `DeleteMany()` or `DeleteManyAsync` method can be used.\n\nHere's the record I want to delete.\n\n``` json\n{\n    { \"student_id\", 10000 },\n    { \"scores\", new BsonArray\n        {\n        new BsonDocument{ {\"type\", \"exam\"}, {\"score\", 88.12334193287023 } },\n        new BsonDocument{ {\"type\", \"quiz\"}, {\"score\", 84.92381029342834 } },\n        new BsonDocument{ {\"type\", \"homework\"}, {\"score\", 89.97929384290324 } },\n        new BsonDocument{ {\"type\", \"homework\"}, {\"score\", 82.12931030513218 } }\n        }\n    },\n    { \"class_id\", 483}\n};\n```\n\nI'll define the filter to match the `student_id` equal to `10000` document:\n\n``` csp\nvar deleteFilter = Builders<BsonDocument>.Filter.Eq(\"student_id\", 10000);\n```\n\nAssuming that we have a `collection` variable assigned to for the `grades` collection, we next pass the filter into the `DeleteOne()` method.\n\n``` csp\ncollection.DeleteOne(deleteFilter);\n```\n\nIf that command is run on the `grades` collection, the document with `student_id` equal to `10000` would be gone. Note here that `DeleteOne()` will delete the first document in the collection that matches the filter. In our example dataset, since there is only a single student with a `student_id` equal to `10000`, we get the desired results.\n\nFor the sake of argument, let's imagine that the rules for the educational institution are incredibly strict. If you get below a score of 60 on the first exam, you are automatically dropped from the course.  We could use a `for` loop with `DeleteOne()` to loop through the entire collection, find a single document that matches an exam score of less than 60, delete it, and repeat. Recall that `DeleteOne()` only deletes the first document it finds that matches the filter. While this could work, it isn't very efficient as multiple calls to the database are made. How do we handle situations that require deleting multiple records then? We can use `DeleteMany()`.\n\n### Multiple Deletes\n\nLet's define a new filter to match the exam score being less than 60:\n\n``` csp\nvar deleteLowExamFilter = Builders<BsonDocument>.Filter.ElemMatch<BsonValue>(\"scores\",\n     new BsonDocument { { \"type\", \"exam\" }, {\"score\", new BsonDocument { { \"$lt\", 60 }}}\n});\n```\n\nWith the filter defined, we pass it into the `DeleteMany()` method:\n\n``` csp\ncollection.DeleteMany(deleteLowExamFilter);\n```\n\nWith that command being run, all of the student record documents with low exam scores would be deleted from the collection.\n\nCheck out the [gist for all of the CRUD commands](https://gist.github.com/kenwalger/4a3da771b8471c43d190327556ebc3ab) wrapped into a single file.\n\n## Wrap Up\n\nThis C# Quick Start series has covered the various CRUD Operations (Create, Read, Update, and Delete) operations in MongoDB using basic BSON Documents. We've seen how to use filters to match specific documents that we want to read, update, or delete. This series has, thus far, been a gentle introduction to C Sharp and MongoDB.\n\nBSON Documents are not, however, the only way to be able to use MongoDB with C Sharp. In our applications, we often have classes defining objects. We can map our classes to BSON Documents to work with data as we would in code. I'll take a look at mapping in a future post.","originalPublishDate":"2022-02-01T15:24:52.433Z","SEO":"61b7fb33e454ca0b0d52811e","related_content":[],"createdAt":"2021-12-14T02:02:27.085Z","originalUpdatedAt":"2022-02-01T15:24:52.530Z","image":{"_id":"61b7fb2ee454ca0b0d52811a","name":"*csharp.png","hash":"csharp_7bf43c7da0","ext":".png","mime":"image/png","size":47.32,"width":360,"height":360,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/csharp_7bf43c7da0.png","formats":{"thumbnail":{"name":"*thumbnail_csharp.png","hash":"thumbnail_csharp_7bf43c7da0","ext":".png","mime":"image/png","width":156,"height":156,"size":26.37,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/thumbnail_csharp_7bf43c7da0.png"}},"provider":"aws-s3","related":["61b7fb33e454ca0b0d52811d"],"createdAt":"2021-12-14T02:02:22.368Z","updatedAt":"2021-12-14T02:02:28.624Z","__v":0,"id":"61b7fb2ee454ca0b0d52811a"},"updated_by":"62bc6e657fbd69001dfd486e","description":"Learn how to perform CRUD operations using C Sharp for MongoDB databases.","__v":3,"other_tags":[{"__component":"other-tag-info.other-tag-info","id":"625840774a0541001d38130f"}],"primary_tag":[{"__component":"primary-tag-info.programming-language","id":"625840774a0541001d38130d"}],"updatedAt":"2022-09-23T13:28:22.387Z","calculated_slug":"/languages/csharp/csharp-crud-tutorial","published_at":"2022-05-10T20:12:44.333Z","expiry_date":"2022-12-14T02:02:27.085Z","id":"6244b4fd7a304f0ca6c4d9aa"},{"awaiting_editorial_review":false,"awaiting_technical_review":false,"editorial_review_LGTM":true,"technical_review_LGTM":true,"authors":["60e72bddfc83f05689cd2b73"],"_id":"6244b4fd7a304f0ca6c4da81","type":"HowTo","name":"*Build Your First .NET Core Application with MongoDB Atlas","slug":"/build-first-dotnet-core-application-mongodb-atlas","content":"So you're a .NET Core developer or you're trying to become one and you'd like to get a database included into the mix. MongoDB is a great choice and is quite easy to get started with for your .NET Core projects.\n\nIn this tutorial, we're going to explore simple CRUD operations in a .NET Core application, something that will make you feel comfortable in no time!\n\n## The Requirements\n\nTo be successful with this tutorial, you'll need to have a few things ready to go.\n\n- .NET Core installed and configured.\n- MongoDB Atlas cluster, M0 or better, deployed and configured.\n\nBoth are out of the scope of this particular tutorial, but you can refer to [this tutorial](https://www.mongodb.com/developer/article/5-different-ways-deploy-free-database-mongodb-atlas/) for more specific instructions around MongoDB Atlas deployments. You can validate that .NET Core is ready to go by executing the following command:\n\n```bash\ndotnet new console --output MongoExample\n```\n\nWe're going to be building a console application, but we'll explore API development in a later tutorial. The \"MongoExample\" project is what we'll use for the remainder of this tutorial.\n\n## Installing and Configuring the MongoDB Driver for .NET Core Development\n\nWhen building C# applications, the common package manager to use is NuGet, something that is readily available in Visual Studio. If you're using Visual Studio, you can add the following:\n\n```bash\nInstall-Package MongoDB.Driver -Version 2.14.1\n```\n\nHowever, I'm on a Mac, use a variety of programming languages, and have chosen Visual Studio Code to be the IDE for me. There is no official NuGet extension for Visual Studio Code, but that doesn't mean we're stuck.\n\nExecute the following from a CLI while within your project directory:\n\n```bash\ndotnet add package MongoDB.Driver\n```\n\nThe above command will add an entry to your project's \"MongoExample.csproj\" file and download the dependencies that we need. This is valuable whether you're using Visual Studio Code or not.\n\nIf you generated the .NET Core project with the CLI like I did, you'll have a \"Program.cs\" file to work with. Open it and add the following code:\n\n```csharp\nusing MongoDB.Driver;\nusing MongoDB.Bson;\n\nMongoClient client = new MongoClient(\"ATLAS_URI_HERE\");\n\nList<string> databases = client.ListDatabaseNames().ToList();\n\nforeach(string database in databases) {\n    Console.WriteLine(database);\n}\n```\n\nThe above code will connect to a MongoDB Atlas cluster and then print out the names of the databases that the particular user has access to. The printing of databases is optional, but it could be a good way to make sure everything is working correctly.\n\nIf you're wondering where to get your `ATLAS_URI_HERE` string, you can find it in your MongoDB Atlas dashboard and by clicking the connect button on your cluster.\n\n![MongoDB Atlas Connection String](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/mongodb_atlas_connection_string_801c3bdc01.jpg \"MongoDB Atlas Connection String\")\n\nThe above image should help when looking for the Atlas URI.\n\n## Building a POCO Class for the MongoDB Document Model\n\nWhen using .NET Core to work with MongoDB documents, you can make use of the `BsonDocument` class, but depending on what you're trying to do, it could complicate your .NET Core application. Instead, I like to work with classes that are directly mapped to document fields. This allows me to use the class naturally in C#, but know that everything will work out on its own for MongoDB documents.\n\nCreate a \"playlist.cs\" file within your project and include the following C# code:\n\n```csharp\nusing MongoDB.Bson;\n\npublic class Playlist {\n\n    public ObjectId _id { get; set; }\n    public string username { get; set; } = null!;\n    public List<string> items { get; set; } = null!;\n\n    public Playlist(string username, List<string> movieIds) {\n        this.username = username;\n        this.items = movieIds;\n    }\n\n}\n```\n\nIn the above `Playlist` class, we have three fields. If you want each of those fields to map perfectly to a field in a MongoDB document, you don't have to do anything further. To be clear, the above class would map to a document that looks like the following:\n\n```json\n{\n    \"_id\": ObjectId(\"61d8bb5e2d5fe0c2b8a1007d\"),\n    \"username\": \"nraboy\",\n    \"items\": [ \"1234\", \"5678\" ]\n}\n```\n\nHowever, if you wanted your C# class field to be different than the field it should map to in a MongoDB document, you'd have to make a slight change. The `Playlist` class would look something like this:\n\n```csharp\nusing MongoDB.Bson;\nusing MongoDB.Bson.Serialization.Attributes;\n\npublic class Playlist {\n\n    public ObjectId _id { get; set; }\n\n    [BsonElement(\"username\")]\n    public string user { get; set; } = null!;\n\n    public List<string> items { get; set; } = null!;\n\n    public Playlist(string username, List<string> movieIds) {\n        this.user = username;\n        this.items = movieIds;\n    }\n\n}\n```\n\nNotice the new import and the use of `BsonElement` to map a remote document field to a local .NET Core class field.\n\nThere are a lot of other things you can do in terms of document mapping, but they are out of the scope of this particular tutorial. If you're curious about other mapping techniques, check out the [documentation](https://mongodb.github.io/mongo-csharp-driver/2.14/reference/bson/mapping/) on the subject.\n\n## Implementing Basic CRUD in .NET Core with MongoDB\n\nSince we're able to connect to Atlas from our .NET Core application and we have some understanding of what our data model will look like for the rest of the example, we can now work towards creating, reading, updating, and deleting (CRUD) documents.\n\nWe'll start by creating some data. Within the project's \"Program.cs\" file, make it look like the following:\n\n```csharp\nusing MongoDB.Driver;\n\nMongoClient client = new MongoClient(\"ATLAS_URI_HERE\");\n\nvar playlistCollection = client.GetDatabase(\"sample_mflix\").GetCollection<Playlist>(\"playlist\");\n\nList<string> movieList = new List<string>();\nmovieList.Add(\"1234\");\n\nplaylistCollection.InsertOne(new Playlist(\"nraboy\", movieList));\n```\n\nIn the above example, we're connecting to MongoDB Atlas, getting a reference to our \"playlist\" collection while noting that it is related to our `Playlist` class, and then making use of the `InsertOne` function on the collection.\n\nIf you ran the above code, you should see a new document in your collection with matching information.\n\nSo let's read from that collection using our C# code:\n\n```csharp\n// Previous code here ...\n\nFilterDefinition<Playlist> filter = Builders<Playlist>.Filter.Eq(\"username\", \"nraboy\");\n\nList<Playlist> results = playlistCollection.Find(filter).ToList();\n\nforeach(Playlist result in results) {\n    Console.WriteLine(string.Join(\", \", result.items));\n}\n```\n\nIn the above code, we are creating a new `FilterDefinition` filter to determine which data we want returned from our `Find` operation. In particular, our filter will give us all documents that have \"nraboy\" as the `username` field, which may be more than one because we never specified if the field should be unique.\n\nUsing the filter, we can do a `Find` on the collection and convert it to a `List` of our `Playlist` class. If you don't want to use a `List`, you can work with your data using a cursor. You can learn more about cursors in the [documentation](https://mongodb.github.io/mongo-csharp-driver/2.14/apidocs/html/T_MongoDB_Driver_IFindFluent_2.htm).\n\nWith a `Find` out of the way, let's move onto updating our documents within MongoDB.\n\nWe're going to add to our \"Program.cs\" file with the following code:\n\n```csharp\n// Previous code here ...\n\nFilterDefinition<Playlist> filter = Builders<Playlist>.Filter.Eq(\"username\", \"nraboy\");\n\n// Previous code here ...\n\nUpdateDefinition<Playlist> update = Builders<Playlist>.Update.AddToSet<string>(\"items\", \"5678\");\n\nplaylistCollection.UpdateOne(filter, update);\n\nresults = playlistCollection.Find(filter).ToList();\n\nforeach(Playlist result in results) {\n    Console.WriteLine(string.Join(\", \", result.items));\n}\n```\n\nIn the above code, we are creating two definitions, one being the `FilterDefinition` that we had created in the previous step. We're going to keep the same filter, but we're adding a definition of what should be updated when there was a match based on the filter.\n\nTo clear things up, we're going to match on all documents where \"nraboy\" is the `username` field. When matched, we want to add \"5678\" to the `items` array within our document. Using both definitions, we can use the `UpdateOne` method to make it happen.\n\nThere are more update operations than just the `AddToSet` function. It is worth checking out the [documentation](https://docs.mongodb.com/manual/reference/operator/update/) to see what you can accomplish.\n\nThis brings us to our final basic CRUD operation. We're going to delete the document that we've been working with.\n\nWithin the \"Program.cs\" file, add the following C# code:\n\n```csharp\n// Previous code here ...\n\nFilterDefinition<Playlist> filter = Builders<Playlist>.Filter.Eq(\"username\", \"nraboy\");\n\n// Previous code here ...\n\nplaylistCollection.DeleteOne(filter);\n```\n\nWe're going to make use of the same filter we've been using, but this time in the `DeleteOne` function. While we could have more than one document returned from our filter, the `DeleteOne` function will only delete the first one. You can make use of the `DeleteMany` function if you want to delete all of them.\n\nNeed to see it all together? Check this out:\n\n```csharp\nusing MongoDB.Driver;\n\nMongoClient client = new MongoClient(\"ATLAS_URI_HERE\");\n\nvar playlistCollection = client.GetDatabase(\"sample_mflix\").GetCollection<Playlist>(\"playlist\");\n\nList<string> movieList = new List<string>();\nmovieList.Add(\"1234\");\n\nplaylistCollection.InsertOne(new Playlist(\"nraboy\", movieList));\n\nFilterDefinition<Playlist> filter = Builders<Playlist>.Filter.Eq(\"username\", \"nraboy\");\n\nList<Playlist> results = playlistCollection.Find(filter).ToList();\n\nforeach(Playlist result in results) {\n    Console.WriteLine(string.Join(\", \", result.items));\n}\n\nUpdateDefinition<Playlist> update = Builders<Playlist>.Update.AddToSet<string>(\"items\", \"5678\");\n\nplaylistCollection.UpdateOne(filter, update);\n\nresults = playlistCollection.Find(filter).ToList();\n\nforeach(Playlist result in results) {\n    Console.WriteLine(string.Join(\", \", result.items));\n}\n\nplaylistCollection.DeleteOne(filter);\n```\n\nThe above code is everything that we did. If you swapped out the Atlas URI string with your own, it would create a document, read from it, update it, and then finally delete it.\n\n## Conclusion\n\nYou just saw how to quickly get up and running with MongoDB in your .NET Core application! While we only brushed upon the surface of what is possible in terms of MongoDB, it should put you on a better path for accomplishing your project needs.\n\nIf you're looking for more help, check out the [MongoDB Community Forums](https://community.mongodb.com) and get involved.","originalPublishDate":"2022-01-31T17:06:39.072Z","SEO":"61f4644edf707f001cad5258","related_content":[],"createdAt":"2022-01-28T21:46:54.456Z","originalUpdatedAt":"2022-01-31T17:06:39.098Z","created_by":"60958898b4522964e193dbcb","image":{"_id":"61bcc4afdf707f001cad41e2","name":"*green.png","alternativeText":"","caption":"","hash":"green_20502a3a50","ext":".png","mime":"image/png","size":62.47,"width":360,"height":360,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/green_20502a3a50.png","formats":{"thumbnail":{"name":"*thumbnail_green.png","hash":"thumbnail_green_20502a3a50","ext":".png","mime":"image/png","width":156,"height":156,"size":32.82,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/thumbnail_green_20502a3a50.png"}},"provider":"aws-s3","related":["61b8d973df707f001cad3f6f","61f4644edf707f001cad5257"],"createdAt":"2021-12-17T17:11:11.096Z","updatedAt":"2022-01-28T21:49:03.800Z","__v":0,"created_by":"60958898b4522964e193dbcb","updated_by":"60958898b4522964e193dbcb","id":"61bcc4afdf707f001cad41e2"},"updated_by":"61f82d1bdf707f001cad52ff","description":"Learn how to quickly and easily start building .NET Core applications that interact with MongoDB Atlas for create, read, update, and delete (CRUD) operations.","__v":3,"other_tags":[{"__component":"other-tag-info.other-tag-info","id":"626ab8990aa9510022c13b2a"}],"primary_tag":[{"__component":"primary-tag-info.programming-language","id":"626ab8990aa9510022c13b28"}],"updatedAt":"2023-02-03T16:11:51.130Z","calculated_slug":"/languages/csharp/build-first-dotnet-core-application-mongodb-atlas","published_at":"2022-05-09T19:15:10.584Z","id":"6244b4fd7a304f0ca6c4da81"},{"awaiting_editorial_review":false,"awaiting_technical_review":false,"editorial_review_LGTM":true,"technical_review_LGTM":true,"authors":["61280f9207aa9d001cc1de5d"],"_id":"6244b4fd7a304f0ca6c4da77","type":"Article","name":"*Introducing the MongoDB Analyzer for .NET","slug":"/introducing-mongodb-analyzer-dotnet","content":"# Introducing the MongoDB Analyzer for .NET\nCorrect code culprits at compile time!\n\nAs C# and .NET developers, we know that it can sometimes be frustrating to work idiomatically with MongoDB queries and aggregations. Without a way to see if your LINQ query or Builder expression corresponds to the [MongoDB Query API](https://www.mongodb.com/mongodb-query-api) (formerly known as MQL) during development, you previously had to wait for runtime errors in order to troubleshoot your queries. We knew there had to be a way to work more seamlessly with C# and MongoDB.\n\nThat’s why we’ve built the [MongoDB Analyzer for .NET](https://docs.mongodb.com/mongodb-analyzer/current/)! Instead of mentally mapping the idiomatic version of your query in C# to the MongoDB Query API, the MongoDB Analyzer can do it for you - and even provide the generated Query API expression right in your IDE. The MongoDB Analyzer even surfaces useful information and helpful warnings on invalid expressions at compile time, bringing greater visibility to the root causes of bugs. And when used together with the recently released [LINQ3](https://mongodb.github.io/mongo-csharp-driver/2.14/reference/driver/crud/linq3/) provider (now supported in [MongoDB C#/.NET Driver](https://docs.mongodb.com/drivers/csharp/) 2.14.0 and higher), you can compose and understand queries in a much more manageable way.\n\nLet’s take a look at how to install and use the new MongoDB Analyzer as a NuGet package. We’ll follow with some code samples so you can see why this is a must-have tool for Visual Studio!\n\n## Install MongoDB Analyzer as a NuGet Package\nIn Visual Studio, install the `MongoDB.Analyzer` [NuGet package](https://www.nuget.org/packages/MongoDB.Analyzer/1.0.0):\n\n*Package Manager*\n\n```\nInstall-Package MongoDB.Analyzer -Version 1.0.0\n```\n\n*.NET CLI*\n\n```\ndotnet add package MongoDB.Analyzer --version 1.0.0\n```\n\nOnce installed, it will be added to your project’s Dependencies list, under Analyzers:\n![MongoDB.Analyzer shown within the Dependencies/Analyzers folder](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/mongodb_analyzer_dependencies_c12f40e5e3.png)\n\nAfter installing and once the analyzer has run, you’ll find all of the diagnostic warnings output to the Error List panel. As you start to inspect your code, you’ll also see that any unsupported expressions will be highlighted.\n\n## Inspecting Information Messages and Warnings\nAs you write LINQ or Builders expressions, an information tooltip can be accessed by hovering over the three grey dots under your expression:\n\n*Accessing the tooltip for a LINQ expression*\n![Accessing the tooltip for a LINQ expression](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/mdb_analyzer_linq_tooltip_0c75054f92.gif)\n\nThis tooltip displays the corresponding Query API language to the expression you are writing and updates in real-time! With the translated query at your tooltips, you can confirm the query being generated (and executed!) is the one you expect. \n\nThis is a far more efficient process of composing and testing queries—focus on the invalid expressions instead of wasting time translating your code for the Query API! And if you ever need to copy the resulting queries generated, you can do so right from your IDE (from the Error List panel).\n\nAnother common issue the MongoDB Analyzer solves is surfacing unsupported expressions and invalid queries at compile time. You’ll find all of these issues listed as warnings:\n\n*Unsupported expressions shown as warnings in Visual Studio’s Error List*\n![Unsupported expressions shown as warnings in Visual Studio’s Error List](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/error_list_warnings_2b5ab48b2a.png)\n\nThis is quite useful as not all LINQ expressions are supported by the MongoDB C#/.NET driver. Similarly, supported expressions will differ depending on which version of LINQ you use.\n\n## Code Samples—See the MongoDB Analyzer for .NET in Action\nNow that we know what the MongoDB Analyzer can do for us, let’s see it live!\n\n### Builder Expressions\nThese are a few examples that show how Builder expressions are analyzed. As you’ll see, the MongoDB Analyzer provides immediate feedback through the tooltip. Hovering over your code shows you the supported Query API language that corresponds to the query/expression you are writing.\n\n*Builder Filter Definition - Filter movies by matching genre, score that is greater than or equal to minimum score, and a match on the title search term.*\n![GIF showing a builder filter being implemented. Alternates between hovering over expression to show the tooltip and corresponding MongoDB Query API expression generated and adding to the builder filter.](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/mdb_analyzer_builder_filter_2f9735637d.gif)\n\n*Builder Sort Definition - Sort movies by score (lowest to highest) and title (from Z to A).*\n![GIF showing a builder sort definition being implemented. Tooltip is then shown with genereated MongoDB Query API expression.](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/mdb_analyzer_builder_sort_9754e9c33b.gif)\n\n*Unsupported Builder Expression - Highlighted and shown as warning in Error List.*\n![GIF showing unsupported builder expression being implemented. After being written, unsupported code is correctly highlighted; tooltip is shown warning developer of the unsupported expression and the warning is added to the Error List panel of the IDE.](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/mdb_analyzer_builder_unsupported_85c6967ea9.gif)\n\n### LINQ Queries\nThe MongoDB Analyzer uses the default LINQ provider of the C#/.NET driver (LINQ2). Expressions that aren’t supported in LINQ2 but are supported in LINQ3 will show the appropriate warnings, as you’ll see in one of the following examples. If you’d like to switch the LINQ provider the MongoDB Analyzer uses, set` “DefaultLinqVersion”: “V3” `in the `mongodb.analyzer.json` file.\n\n*LINQ Filter Query - Aggregation pipeline.*\n![GIF showing a LINQ query being implemented with multiple conditions. Afterward, a tooltip with the corresponding MongoDB Query API expression is shown.](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/mdb_analyzer_linq_aggregation_79fa4031ee.gif)\n\n*LINQ Query - Get movie genre statistics; uses aggregation pipeline to group by and select a dynamic object.*\n![GIF showing a LINQ query being implemented that uses a group by statement and selection of a dynamic object. Afterward, a tooltip with the corresponding MongoDB Query API expression is shown.](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/mdb_analyzer_linq_groupby_select_f4711d32cd.gif)\n\n*Unsupported LINQ Expression - GetHashCode() method unsupported.*\n ![GIF showing unsupported LINQ expression being implemented. After being written, unsupported code is correctly highlighted; tooltip is shown warning developer of the unsupported expression and the warning is added to the Error List panel of the IDE.](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/mdb_analyzer_linq_unsupported_bbd62a00fc.gif)\n\n*Unsupported LINQ Expression - Method referencing a lambda parameter unsupported.*\n![GIF showing unsupported LINQ expression being implemented. After being written, unsupported code is correctly highlighted; tooltip is shown warning developer of the unsupported expression and the warning is added to the Error List panel of the IDE.](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/mdb_analyzer_linq_unsupported_2_ea584e3fac.gif)\n\n*Unsupported LINQ2, but supported LINQ3 Expression - Trim() is not supported in LINQ2, but is supported in LINQ3.*\n![GIF showing an expression that is unsupported in LINQ2, but supported in LINQ3, being implemented. After being written, unsupported code is correctly highlighted; tooltip warns developer of the unsupported expression in LINQ2 but not LINQ3 and the warning is added to the Error List panel of the IDE.](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/mdb_analyzer_only_linq3_bc033bd4f1.gif)\n\n## MongoDB Analyzer + New LINQ3 Provider = 💚\nIf you’d rather not see those “unsupported in LINQ2, but supported in LINQ3” warnings, now is also a good time to update to the [latest MongoDB C#/.NET driver](https://www.nuget.org/packages/mongodb.driver) (2.14.1) which has LINQ3 support! While the full transition from LINQ2 to LINQ3 continues, you can explicitly configure your [MongoClient](https://mongodb.github.io/mongo-csharp-driver/2.14/getting_started/quick_tour/#mongoclient) to use the new LINQ provider like so:\n\n```csharp\nvar connectionString = \"mongodb://localhost\";\nvar clientSettings = MongoClientSettings.FromConnectionString(connectionString);\nclientSettings.LinqProvider = LinqProvider.V3;\nvar client = new MongoClient(clientSettings);\n```\n\n## Integrate MongoDB Analyzer for .NET into Your Pipelines\nThe MongoDB Analyzer can also be used from the CLI which means integrating this static analysis tool into your continuous integration and continuous deployment pipelines is seamless! For example, running `dotnet build` from the command line will output MongoDB Analyzer warnings to the terminal:\n\n*Running dotnet build command outputs warnings from the MongoDB Analyzer*\n![*Running dotnet build command outputs warnings from the MongoDB Analyzer*](https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/mdb_analyzer_build_output_terminal_52965c0a24.gif)\n\nAdding this as a step in your build pipeline can be a valuable gate check for your build. You’ll save yourself a potential headache and catch unsupported expressions and invalid queries much earlier.\n\nAnother idea: Output a Static Analysis Results Interchange Format ([SARIF](https://github.com/microsoft/sarif-tutorials/blob/main/docs/1-Introduction.md#:%7E:text=What%20is%20SARIF%3F,for%20use%20by%20simpler%20tools)) file and use it to generate explain plans for all of your queries. SARIF is a standard, JSON-based format for the output of static analysis tools, making a SARIF file an ideal place to grab the supported queries generated by the MongoDB Analyzer. \n\nTo output a SARIF file for your project, you’ll need to add the `ErrorLog` option to your `.csproj` file. You’ll be able to find it at the root of your project (unless you’ve specified otherwise) the next time you build your project.\n\nWith this file, you can load it via a [mongosh](https://docs.mongodb.com/mongodb-shell/) script, process the file to find and “clean” the found MongoDB Query API expressions, and generate [explain plans](https://docs.mongodb.com/manual/reference/method/db.collection.explain/#mongodb-method-db.collection.explain) for the list of queries. What can you do with this? A great example would be to output a build warning (or outright fail the build) if you catch any missing indexes! Adding steps like these to your build and using the information from the expain plans, you can prevent potential performance issues from ever making it to production.\n\n## We Want to Hear From You!\nWith the release of the MongoDB Analyzer for .NET, we hope to speed up your development cycle and increase your productivity in three ways: 1) by making it easier for you to see how your idiomatic queries map to the MongoDB Query API, 2) by helping you spot unsupported expressions and invalid queries faster (at compile time, baby), and 3) by streamlining your development process by enabling static analysis for your MongoDB queries in your CI/CD pipelines!\n\nWe’re quite eager to see the .NET and C# communities use this tool and are even more eager to hear your feedback. The MongoDB Analyzer is ready for you to install as a [NuGet package](https://www.nuget.org/packages/MongoDB.Analyzer/1.0.0) and can be added to any existing project that uses the MongoDB .NET driver. We want to continue improving this tool and that can only be done with your help. If you find any issues, are missing critical functionality, or have an edge case that the MongoDB Analyzer doesn’t fulfill, [please let us know](https://feedback.mongodb.com/forums/940188-mongodb-analyzer-for-net)! You can alsopost in our [Community Forums](https://www.mongodb.com/community/forums/).\n\n**Additional Resources**\n\n* [MongoDB Analyzer Docs](https://docs.mongodb.com/mongodb-analyzer/current/)","originalPublishDate":"2022-01-11T17:30:00.228Z","SEO":"61d8e58cdf707f001cad47ff","related_content":[],"createdAt":"2022-01-08T00:21:44.065Z","originalUpdatedAt":"2022-01-11T17:30:01.206Z","created_by":"60e74c643ab9df001dc051b2","image":{"_id":"627d0c488891f3001d997e04","name":"*C# Banner_1280x720.png","alternativeText":"","caption":"","hash":"C_Banner_1280x720_271ab1b858","ext":".png","mime":"image/png","size":29.67,"width":1280,"height":720,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/C_Banner_1280x720_271ab1b858.png","formats":{"thumbnail":{"name":"*thumbnail_C# Banner_1280x720.png","hash":"thumbnail_C_Banner_1280x720_271ab1b858","ext":".png","mime":"image/png","width":245,"height":138,"size":12.35,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/thumbnail_C_Banner_1280x720_271ab1b858.png"},"large":{"name":"*large_C# Banner_1280x720.png","hash":"large_C_Banner_1280x720_271ab1b858","ext":".png","mime":"image/png","width":1000,"height":563,"size":67.46,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/large_C_Banner_1280x720_271ab1b858.png"},"medium":{"name":"*medium_C# Banner_1280x720.png","hash":"medium_C_Banner_1280x720_271ab1b858","ext":".png","mime":"image/png","width":750,"height":422,"size":46.42,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/medium_C_Banner_1280x720_271ab1b858.png"},"small":{"name":"*small_C# Banner_1280x720.png","hash":"small_C_Banner_1280x720_271ab1b858","ext":".png","mime":"image/png","width":500,"height":281,"size":28.01,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/small_C_Banner_1280x720_271ab1b858.png"}},"provider":"aws-s3","related":["6244b4fd7a304f0ca6c4d9eb","6244b4fd7a304f0ca6c4d9f4","6244b4fd7a304f0ca6c4da77","6244b4fd7a304f0ca6c4da9b","6244b4fd7a304f0ca6c4da83","6244b4fd7a304f0ca6c4da8d","6244b4fd7a304f0ca6c4da82","6244b4fd7a304f0ca6c4da1f","6244b4fd7a304f0ca6c4da2a","6244b4fd7a304f0ca6c4da74","6244b4fd7a304f0ca6c4daa7"],"createdAt":"2022-05-12T13:31:52.940Z","updatedAt":"2022-05-12T14:19:20.543Z","__v":0,"created_by":"60acfb196a6d99001c58c549","updated_by":"60acfb196a6d99001c58c549","id":"627d0c488891f3001d997e04"},"updated_by":"60acfb196a6d99001c58c549","description":"Say hello to the MongoDB Analyzer for .NET. This tool translates your C# queries to their MongoDB Query API equivalent and warns you of unsupported expressions and invalid queries at compile time, right in Visual Studio.","__v":3,"other_tags":[{"__component":"other-tag-info.other-tag-info","id":"626ab4840aa9510022c13b16"}],"primary_tag":[{"__component":"primary-tag-info.programming-language","id":"626ab4840aa9510022c13b14"}],"updatedAt":"2022-05-12T13:46:35.017Z","calculated_slug":"/languages/csharp/introducing-mongodb-analyzer-dotnet","published_at":"2022-05-09T19:27:48.444Z","id":"6244b4fd7a304f0ca6c4da77"}],"podcasts":[],"videos":[],"events":[],"_id":"6399ea260d8731001cf71bea","__v":0,"programming_language":{"_id":"62471c05ce7cde001ccae8fc","name":"*CSharp","published_at":"2022-04-28T23:09:23.809Z","createdAt":"2022-04-01T15:36:37.246Z","updatedAt":"2022-06-11T11:54:15.688Z","__v":0,"created_by":"61f82d1bdf707f001cad52ff","updated_by":"61f82d1bdf707f001cad52ff","calculated_slug":"/languages/csharp","description":"A general-purpose, multi-paradigm programming language. C# is a particularly useful language to learn for developing apps based on the .NET framework","icon":{"_id":"62795f15413697001c652b3e","name":"*c_sharp.svg","alternativeText":"","caption":"","hash":"c_sharp_565791f12f","ext":".svg","mime":"image/svg+xml","size":2.25,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/c_sharp_565791f12f.svg","provider":"aws-s3","width":45,"height":50,"related":["62471c05ce7cde001ccae8fc"],"createdAt":"2022-05-09T18:36:05.791Z","updatedAt":"2022-05-09T18:42:30.140Z","__v":0,"created_by":"60acfb196a6d99001c58c549","updated_by":"60acfb196a6d99001c58c549","id":"62795f15413697001c652b3e"},"documentation_link":"https://www.mongodb.com/docs/drivers/csharp/","id":"62471c05ce7cde001ccae8fc"},"id":"6399ea260d8731001cf71bea"},{"__component":"featured-category.programming-language","articles":[{"awaiting_editorial_review":false,"awaiting_technical_review":false,"editorial_review_LGTM":false,"technical_review_LGTM":false,"authors":["61969cc0a0957d40b0be6803"],"_id":"62a498f03790de001c896d87","name":"*Using Rust Web Development Frameworks with MongoDB","slug":"/rust-mongodb-frameworks","content":"##  Introduction\nSo, you've decided to write a Rust application with MongoDB, and you're wondering which of the top web development frameworks to use. Below, we give some suggestions and resources for how to:\n\n1. Use MongoDB with Actix and Rust.\n2. Use MongoDB with Rocket.rs and Rust.\n\nThe TLDR is that any of the popular Rust frameworks can be used with MongoDB, and we have code examples, tutorials, and other resources to guide you.\n\n### Building MongoDB Rust apps with Actix\n\n[Actix](https://github.com/actix/actix-web) is a powerful and performant web framework for building Rust applications, with a long list of supported features. \n\nYou can [find a working example](https://github.com/actix/examples/tree/master/databases/mongodb) of using MongoDB with Actix in the `databases` directory under Actix's github, but otherwise, if you're looking to build a REST API with Rust and MongoDB, using Actix along the way, [this tutorial](https://dev.to/hackmamba/build-a-rest-api-with-rust-and-mongodb-actix-web-version-ei1) is one of the better ones we've seen.\n\n### Building MongoDB Rust apps with Rocket.rs\n\nPrefer [Rocket](https://rocket.rs/)? Rocket is a fast, secure, and type safe framework that is low on boilerplate. It's easy to use MongoDB with Rocket to build Rust applications. There's a [tutorial on Medium we particularly like](https://medium.com/geekculture/build-a-rest-api-with-rust-and-mongodb-rocket-version-7ea90ebd9fe7) on building a REST API with Rust, MongoDB, and Rocket. \n\nIf all you want is to see a code example on github, we recommend [this one.](https://github.com/TaeyoonKwon/rust-rocket-sample)\n\n\n\n\n\n","description":"Which Rust frameworks work best with MongoDB?","published_at":"2022-06-11T13:47:16.033Z","SEO":"62a49ce23790de001c896d9a","related_content":[],"primary_tag":[{"__component":"primary-tag-info.programming-language","id":"62a498f03790de001c896d88"}],"other_tags":[{"__component":"other-tag-info.other-tag-info","id":"62a498f03790de001c896d8a"}],"createdAt":"2022-06-11T13:30:24.490Z","updatedAt":"2022-08-30T18:24:04.343Z","__v":2,"created_by":"61f82d1bdf707f001cad52ff","updated_by":"60958855b4522964e193dbc8","calculated_slug":"/languages/rust/rust-mongodb-frameworks","image":{"_id":"62a499f33790de001c896d91","name":"*rustacean-flat-happy (1).png","alternativeText":"","caption":"","hash":"rustacean_flat_happy_1_202da34422","ext":".png","mime":"image/png","size":30.83,"width":1200,"height":800,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/rustacean_flat_happy_1_202da34422.png","formats":{"thumbnail":{"name":"*thumbnail_rustacean-flat-happy (1).png","hash":"thumbnail_rustacean_flat_happy_1_202da34422","ext":".png","mime":"image/png","width":234,"height":156,"size":13.37,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/thumbnail_rustacean_flat_happy_1_202da34422.png"},"large":{"name":"*large_rustacean-flat-happy (1).png","hash":"large_rustacean_flat_happy_1_202da34422","ext":".png","mime":"image/png","width":1000,"height":667,"size":74.22,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/large_rustacean_flat_happy_1_202da34422.png"},"medium":{"name":"*medium_rustacean-flat-happy (1).png","hash":"medium_rustacean_flat_happy_1_202da34422","ext":".png","mime":"image/png","width":750,"height":500,"size":52.27,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/medium_rustacean_flat_happy_1_202da34422.png"},"small":{"name":"*small_rustacean-flat-happy (1).png","hash":"small_rustacean_flat_happy_1_202da34422","ext":".png","mime":"image/png","width":500,"height":333,"size":31.82,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/small_rustacean_flat_happy_1_202da34422.png"}},"provider":"aws-s3","related":["62a498f03790de001c896d87"],"createdAt":"2022-06-11T13:34:43.748Z","updatedAt":"2022-06-11T13:48:56.759Z","__v":0,"created_by":"61f82d1bdf707f001cad52ff","updated_by":"61f82d1bdf707f001cad52ff","id":"62a499f33790de001c896d91"},"expiry_date":"2023-06-11T13:30:24.490Z","id":"62a498f03790de001c896d87"},{"awaiting_editorial_review":false,"awaiting_technical_review":false,"editorial_review_LGTM":false,"technical_review_LGTM":false,"authors":["61969cc0a0957d40b0be6803"],"_id":"63ceb40e647b0a001da71899","published_at":"2023-01-24T02:41:46.258Z","content":"We have some exciting news to announce for Rust developers. Our 2.4.1 release of the MongoDB Rust driver brings a raft of new, innovative features for developers building Rust applications. \n\n## Field Level Encryption for Rust Applications\nThis one has been a long time coming. The 2.4.1 version of the MongoDB Rust driver contains field level encryption capabilities - both client side field level encryption and queryable encryption. Starting with MongoDB 4.2, client-side field level encryption allows an application to encrypt specific data fields in addition to pre-existing MongoDB encryption features such as Encryption at Rest and TLS/SSL (Transport Encryption).\n\nWith field level encryption, applications can encrypt fields in documents prior to transmitting data over the wire to the server. Client-side field level encryption supports workloads where applications must guarantee that unauthorized parties, including server administrators, cannot read the encrypted data.\n\nFor more information, see the [Encryption](https://mongodb.github.io/mongo-rust-driver/manual/encryption.html) section of the Rust driver documentation.\n\n## GridFS Rust Support\nThe 2.4.1 release of the MongoDB Rust driver also (finally!) added support for GridFS, allowing storage and retrieval of files that exceed the BSON document size limit. \n\n\n## Tracing Support \nThis release had one other noteworthy item in it - the driver now emits tracing events at points of interest. Note that this API is considered unstable as the tracing crate has not reached 1.0 yet; future minor versions of the driver may upgrade the tracing dependency to a new version which is not backwards-compatible with Subscribers that depend on older versions of tracing. You can read more about tracing from the crates.io documentation [here.](https://crates.io/crates/tracing)\n\n\n## Install the MongoDB Rust Driver\nTo check out these new features, you'll need to install the MongoDB Rust driver, which is available on crates.io. To use the driver in your application, simply add it to your project's Cargo.toml.\n\n```\n[dependencies]\nmongodb = \"2.4.0-beta\"\n```","SEO":"63ced7b04b1234001d4cc6ba","related_content":[],"primary_tag":[{"__component":"primary-tag-info.programming-language","id":"63ceb40e647b0a001da7189a"}],"other_tags":[{"__component":"other-tag-info.other-tag-info","id":"63cf45683454f5001d0adf72"}],"createdAt":"2023-01-23T16:21:34.525Z","updatedAt":"2023-01-24T02:41:46.357Z","__v":2,"created_by":"63bd93c4ebdd6d001c0b9b95","updated_by":"61f82d1bdf707f001cad52ff","expiry_date":"2024-01-23T16:21:34.525Z","calculated_slug":"/languages/rust/rust-field-level-encryption","description":"MongoDB now support field level encryption for Rust applications","name":"*MongoDB Field Level Encryption is now Available for Rust applications","slug":"/rust-field-level-encryption","image":{"_id":"627d40ea8891f3001d997fb6","name":"*Rust Banner_1280x720.png","alternativeText":"","caption":"","hash":"Rust_Banner_1280x720_1b55c28d7b","ext":".png","mime":"image/png","size":32.12,"width":1280,"height":720,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/Rust_Banner_1280x720_1b55c28d7b.png","formats":{"thumbnail":{"name":"*thumbnail_Rust Banner_1280x720.png","hash":"thumbnail_Rust_Banner_1280x720_1b55c28d7b","ext":".png","mime":"image/png","width":245,"height":138,"size":11.08,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/thumbnail_Rust_Banner_1280x720_1b55c28d7b.png"},"large":{"name":"*large_Rust Banner_1280x720.png","hash":"large_Rust_Banner_1280x720_1b55c28d7b","ext":".png","mime":"image/png","width":1000,"height":563,"size":60.67,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/large_Rust_Banner_1280x720_1b55c28d7b.png"},"medium":{"name":"*medium_Rust Banner_1280x720.png","hash":"medium_Rust_Banner_1280x720_1b55c28d7b","ext":".png","mime":"image/png","width":750,"height":422,"size":41.53,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/medium_Rust_Banner_1280x720_1b55c28d7b.png"},"small":{"name":"*small_Rust Banner_1280x720.png","hash":"small_Rust_Banner_1280x720_1b55c28d7b","ext":".png","mime":"image/png","width":500,"height":281,"size":25.09,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/small_Rust_Banner_1280x720_1b55c28d7b.png"}},"provider":"aws-s3","related":["6244b4fd7a304f0ca6c4da7d","6244b4fd7a304f0ca6c4d9ca","6244b4fd7a304f0ca6c4d9cb","6244b4fd7a304f0ca6c4da3e","63ceb40e647b0a001da71899"],"createdAt":"2022-05-12T17:16:26.725Z","updatedAt":"2023-01-24T02:41:35.887Z","__v":0,"created_by":"60acfb196a6d99001c58c549","updated_by":"60acfb196a6d99001c58c549","id":"627d40ea8891f3001d997fb6"},"id":"63ceb40e647b0a001da71899"}],"podcasts":[],"videos":[],"events":[],"_id":"63cf45cd3454f5001d0adf79","__v":0,"programming_language":{"_id":"62471b5cce7cde001ccae8f7","name":"*Rust","published_at":"2022-05-09T18:48:53.726Z","createdAt":"2022-04-01T15:33:48.357Z","updatedAt":"2022-06-11T11:56:06.222Z","__v":0,"created_by":"61f82d1bdf707f001cad52ff","updated_by":"61f82d1bdf707f001cad52ff","calculated_slug":"/languages/rust","icon":{"_id":"627bd6e68891f3001d997de5","name":"*Rust icon 64x64.png","alternativeText":"","caption":"","hash":"Rust_icon_64x64_d26f43a8e5","ext":".png","mime":"image/png","size":1.89,"width":64,"height":64,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/Rust_icon_64x64_d26f43a8e5.png","provider":"aws-s3","related":["62471b5cce7cde001ccae8f7"],"createdAt":"2022-05-11T15:31:50.089Z","updatedAt":"2022-05-11T15:43:02.387Z","__v":0,"created_by":"60acfb196a6d99001c58c549","updated_by":"60acfb196a6d99001c58c549","id":"627bd6e68891f3001d997de5"},"description":"A multi-paradigm, general-purpose programming language designed for performance and safety.  Rust is a low-level programming language with high performance and can be used to write operating systems, game engines, and embedded applications.","documentation_link":"https://www.mongodb.com/docs/drivers/rust/","id":"62471b5cce7cde001ccae8f7"},"id":"63cf45cd3454f5001d0adf79"},{"__component":"featured-category.content-type","articles":[],"podcasts":[],"videos":[],"events":[{"type":"InPerson","authors":["61e15b43df707f001cad4aef"],"_id":"63d908e86061ee001d05db3c","content":"Meet with our team at iJS London\n\n## Sessions by MongoDB\n\n| Date | Session Title | Speaker |\n|---|---|---|\n|April 25|JavaScript Full Stack Day| Joel Lord|\n|April 26|Remix: Next Best Thing Or Yet Another Framework?| Joel Lord|","title":"*International JavaScript Conference London","start_time":"2023-04-25T16:00:00.000Z","end_time":"2023-04-27T16:00:00.000Z","slug":"/ijs-london-23","published_at":"2023-01-31T12:28:12.371Z","other_tags":"63d90924a30b53001d1bc2c4","related_content":null,"address":"63d92b6ea30b53001d1bc2ca","createdAt":"2023-01-31T12:26:16.460Z","updatedAt":"2023-02-01T13:44:54.185Z","__v":0,"created_by":"60c21cda1ef87b001cc8c98b","updated_by":"60c21cda1ef87b001cc8c98b","calculated_slug":"/events/ijs-london-23","registration_url":"https://javascript-conference.com/london/","image":{"_id":"63d90911a30b53001d1bc2c3","name":"*iJS_NY22_Website_Logo_desktop-1.png","alternativeText":"","caption":"","hash":"i_JS_NY_22_Website_Logo_desktop_1_55bfa32f9f","ext":".png","mime":"image/png","size":26.13,"width":413,"height":179,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/i_JS_NY_22_Website_Logo_desktop_1_55bfa32f9f.png","formats":{"thumbnail":{"name":"*thumbnail_iJS_NY22_Website_Logo_desktop-1.png","hash":"thumbnail_i_JS_NY_22_Website_Logo_desktop_1_55bfa32f9f","ext":".png","mime":"image/png","width":245,"height":106,"size":27.4,"path":null,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/thumbnail_i_JS_NY_22_Website_Logo_desktop_1_55bfa32f9f.png"}},"provider":"aws-s3","related":["63d908e86061ee001d05db3c"],"createdAt":"2023-01-31T12:26:57.295Z","updatedAt":"2023-01-31T12:27:16.979Z","__v":0,"created_by":"60c21cda1ef87b001cc8c98b","updated_by":"60c21cda1ef87b001cc8c98b","id":"63d90911a30b53001d1bc2c3"},"description":"From Angular and React to WebAssembly; from Progressive Web Apps to JAMstack – international experts share insights on the present and future JavaScript. Join us to broaden your knowledge and network with other JS enthusiasts.","id":"63d908e86061ee001d05db3c"},{"type":"InPerson","authors":["61e15b43df707f001cad4aef"],"_id":"63d905dfa30b53001d1bc2bc","registration_url":"https://orlandocodecamp.com/","start_time":"2023-03-25T12:00:00.000Z","slug":"/orlando-code-camp","end_time":"2023-03-25T21:00:00.000Z","title":"*Orlando Code Camp","content":"Meet with our team at Orlando Code Camp, a free event open to any attendees. \n\n## Sessions by MongoDB\n\n| Date | Session Title | Speaker |\n|---|---|---|\n|March 25|IoT, JavaScript, and Beer Brewing. Cheers To That| Joel Lord","description":"Orlando Codecamp 2023 is organized by Orlando .NET User Group (ONETUG) and hosted by Seminole State College. The event will start at 8am and end at 5pm. The event entry is FREE to all attendees, thanks to our generous sponsors. We will feature multiple tracks of hard core technical and tech industry-adjacent talks of 50 minutes each.","published_at":"2023-01-31T12:14:13.219Z","other_tags":"63d905dfa30b53001d1bc2bd","related_content":null,"address":"63d940b86061ee001d05db4a","createdAt":"2023-01-31T12:13:19.755Z","updatedAt":"2023-02-01T13:45:03.124Z","__v":1,"created_by":"60c21cda1ef87b001cc8c98b","updated_by":"60c21cda1ef87b001cc8c98b","calculated_slug":"/events/orlando-code-camp","id":"63d905dfa30b53001d1bc2bc"},{"type":"InPerson","authors":["61e15b43df707f001cad4aef"],"_id":"63da6c536061ee001d05dc0b","registration_url":"https://confoo.ca","start_time":"2023-02-20T17:00:00.000Z","end_time":"2023-02-24T17:00:00.000Z","title":"*Confoo","content":"Come meet our team at Confoo\n\n\n## Sessions by MongoDB\nDate|Topic|Speaker\n---|---|---\nFeb 20th, 2023|Serverless Application Development with MongoDB Atlas (Full day workshop)|Joel Lord\nFeb 21th, 2023|Serverless Application Development with MongoDB Atlas (Full day workshop - French version)|Joel Lord\nFeb 22th, 2023|IoT, JavaScript and Beer Brewing: Cheers to that!|Joel Lord\nFeb 23th, 2023|Your JavaScript Is So 2015|Joel Lord\n\n## Code and Slides\n\n* [Serverless workshop](https://docs.google.com/presentation/d/1IaCSa5tH121IEDVgyoUep05tn7o1AHP9JeCKy6Eaj4w/edit?usp=sharing)\n* [IoT, JS, and Beer Brewing](https://github.com/joellord/iot-js-beer)\n* [Your JS Is So 2015](https://docs.google.com/presentation/d/1YOvj7xPO20j-8RqWxRuVrwuQgAOaw7kxE2OJL3RWshI/edit?usp=sharing)\n\n## More information\n### MongoDB Atlas\nCreate your free MongoDB Atlas account right \n[here](https://mdb.link/workshop)\n\n### Additional Resources\nLearn more on the topic with the following resources\n* [Building a REST API with Express, Node, and MongoDB](https://www.mongodb.com/languages/express-mongodb-rest-api-tutorial)\n\n\n## Reach out\nFeedback on the talk? Got some question about the topic? Reach out! The easiest way to get in touch with me is always through \nTwitter","description":"ConFoo Montreal is a multi-technology conference for developers.\n155 presentations by popular international speakers.\nFocused on pragmatic solutions for developers.\nGreat content and amazing experience.","published_at":"2023-02-01T13:46:01.441Z","other_tags":"63da6c536061ee001d05dc0c","related_content":null,"address":"63da6c536061ee001d05dc0e","createdAt":"2023-02-01T13:42:43.005Z","updatedAt":"2023-02-19T16:22:27.057Z","__v":2,"created_by":"60c21cda1ef87b001cc8c98b","image":{"_id":"63da6c36a30b53001d1bc382","name":"*logo.gif","alternativeText":"","caption":"","hash":"logo_96b2cdc2a4","ext":".gif","mime":"image/gif","size":1.34,"url":"https://mongodb-devhub-cms.s3.us-west-1.amazonaws.com/logo_96b2cdc2a4.gif","provider":"aws-s3","width":190,"height":29,"related":["63da6c536061ee001d05dc0b"],"createdAt":"2023-02-01T13:42:14.892Z","updatedAt":"2023-02-01T13:42:43.051Z","__v":0,"created_by":"60c21cda1ef87b001cc8c98b","updated_by":"60c21cda1ef87b001cc8c98b","id":"63da6c36a30b53001d1bc382"},"updated_by":"60c21cda1ef87b001cc8c98b","calculated_slug":"/events/confoo-23","slug":"/confoo-23","id":"63da6c536061ee001d05dc0b"}],"_id":"63dc1e376061ee001d05dc84","__v":0,"content_type":{"_id":"624af03cce7cde001ccae943","content_type":"Event","published_at":"2022-05-09T18:36:28.061Z","createdAt":"2022-04-04T13:18:52.702Z","updatedAt":"2023-01-30T19:14:34.029Z","__v":0,"created_by":"61f82d1bdf707f001cad52ff","updated_by":"632c6d50494dd3001e036faa","calculated_slug":"/events","id":"624af03cce7cde001ccae943"},"id":"63dc1e376061ee001d05dc84"}],"createdAt":"2022-06-17T16:23:35.591Z","updatedAt":"2023-02-02T20:33:59.873Z","__v":1,"created_by":{"isActive":true,"blocked":false,"roles":["5fbe7cfdfae41ff1f2d5c6e0"],"_id":"60b944ea35b8b2001c526d02","username":null,"registrationToken":null,"firstname":"Harika","lastname":"Kotipalli","email":"harika.kotipalli@mongodb.com","__v":0,"password":"$2a$10$XzdLedvZVt9C8909I7by2OmDpcCs2VWM/JdiofOol8hZ0gjVDYj0O","resetPasswordToken":"1e31483c904552b286c7bfd5fa08b56e8202647b","id":"60b944ea35b8b2001c526d02"},"updated_by":{"isActive":true,"blocked":false,"roles":["5fbe7cfdfae41ff1f2d5c6e0"],"_id":"61f82d1bdf707f001cad52ff","username":null,"registrationToken":null,"firstname":"Rachelle","lastname":"Palmer","email":"rachelle.palmer@mongodb.com","__v":0,"password":"$2a$10$.kfSaOE1V.5oaIjgMiNHK.meskh5u3N9xzP5dYWaRTYuIkPRTPVoq","resetPasswordToken":null,"id":"61f82d1bdf707f001cad52ff"},"id":"62acaa8763f6f6001c80fa26"}